[
  {
    "objectID": "evaluacion.html",
    "href": "evaluacion.html",
    "title": "Evaluaciones",
    "section": "",
    "text": "La evaluación del curso se basa en la aplicación práctica de las técnicas estadísticas aprendidas. Se privilegia la comprensión conceptual y la correcta interpretación de resultados por sobre la memorización de fórmulas."
  },
  {
    "objectID": "evaluacion.html#sistema-de-evaluación",
    "href": "evaluacion.html#sistema-de-evaluación",
    "title": "Evaluaciones",
    "section": "",
    "text": "La evaluación del curso se basa en la aplicación práctica de las técnicas estadísticas aprendidas. Se privilegia la comprensión conceptual y la correcta interpretación de resultados por sobre la memorización de fórmulas."
  },
  {
    "objectID": "evaluacion.html#componentes-de-evaluación",
    "href": "evaluacion.html#componentes-de-evaluación",
    "title": "Evaluaciones",
    "section": "Componentes de Evaluación",
    "text": "Componentes de Evaluación\n\n\n\n\n\n\n\n\nComponente\nPorcentaje\nFecha de entrega\n\n\n\n\nTrabajo práctico\n40%\nPauta 17 de octubre. Entrega 3 de noviembre\n\n\nTrabajo final\n60%\nPauta 10 de noviembre. Entrega 8 de diciembre\n\n\nTOTAL\n100%\n\n\n\n\n\n1. Trabajo práctico (40%)\n[AÚN NO DEFINIDO.]\nFormato de entrega: - Script de R, RProject, Carpetas, etc., en un zip - PDF con el texto, incluyendo lo que se solicite en la pauta (incluido en el zip) - Si se quiere, deseable también el archivo .qmd o .Rmd con código y respuestas. Pero no es necesario hacer los trabajos en Quarto o RMarkdown si no quieren o no saben. - Debe incluir código comentado y narrativa explicativa - Se evaluará: código funcional, interpretación correcta, claridad de presentación\n\n\n\n\n\n\nConsejo\n\n\n\nComenta tu código y explica tu razonamiento. No basta con obtener el resultado correcto, sino que debes demostrar comprensión de lo que estás haciendo.\n\n\n\n\n\n2. Trabajo final (60%)\nFecha de entrega: [Fecha]\nModalidad: [No definido]\n\n\n\n\n\n\nPautas\n\n\n\nRúbrica detallada: [Se compartirá con anticipación y las ayudantías también abrirán espacio para preguntas personales sobre los avances de sus trabajos personales]."
  },
  {
    "objectID": "evaluacion.html#criterios-generales-de-evaluación",
    "href": "evaluacion.html#criterios-generales-de-evaluación",
    "title": "Evaluaciones",
    "section": "Criterios Generales de Evaluación",
    "text": "Criterios Generales de Evaluación\n\nReproducibilidad\nTodo el código debe ser completamente reproducible. Esto significa que:\n\nIncluir comandos para cargar librerías necesarias\nUsar rutas relativas (nunca C:/Mi Computador/...)\nDocumentar la sesión de R (sessionInfo())\nComentar el código adecuadamente\n\n\n\nPresentación de Resultados\nSe valorará:\n\nTablas bien formateadas\nGráficos con títulos, etiquetas de ejes claros\nInterpretación en lenguaje claro, no solo técnico\nOrtografía y redacción cuidada\n\n\n\nUso de Recursos\nEstá permitido y es recomendado:\n\nConsultar documentación de R y paquetes\nBuscar ayuda en foros (Stack Overflow, etc.)\nDiscutir ideas con compañeros/as\n\nNo está permitido: - Copiar código de compañeros/as u otros/as sin citarlo - Presentar trabajo ajeno como propio\n\n\n\n\n\n\nPlagio\n\n\n\nCualquier forma de plagio resultará en nota mínima (1.0) y será reportado según reglamento universitario."
  },
  {
    "objectID": "evaluacion.html#escala-de-calificaciones",
    "href": "evaluacion.html#escala-de-calificaciones",
    "title": "Evaluaciones",
    "section": "Escala de Calificaciones",
    "text": "Escala de Calificaciones\nSe utiliza la escala de 1.0 a 7.0, con nota mínima de aprobación 4.0."
  },
  {
    "objectID": "evaluacion.html#entrega-de-evaluaciones",
    "href": "evaluacion.html#entrega-de-evaluaciones",
    "title": "Evaluaciones",
    "section": "Entrega de Evaluaciones",
    "text": "Entrega de Evaluaciones\nTodas las entregas se realizan vía [A DEFINIR]:\n\nFormato: Archivo .R y .pdf, o .qmd-.Rmd +\nNombre de archivo: apellido_nombre_evaluacion.qmd\nHora límite: 23:59 de la fecha indicada"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Taller de Métodos y Técnicas de Investigación I",
    "section": "",
    "text": "Este es el sitio web del curso Taller de Métodos y Técnicas de Investigación I de la Universidad Alberto Hurtado, enfocado en la aplicación práctica de técnicas estadísticas usando R. En este sitio, se irá subiendo el material de apoyo para las sesiones de ayudantía del curso."
  },
  {
    "objectID": "index.html#bienvenides",
    "href": "index.html#bienvenides",
    "title": "Taller de Métodos y Técnicas de Investigación I",
    "section": "",
    "text": "Este es el sitio web del curso Taller de Métodos y Técnicas de Investigación I de la Universidad Alberto Hurtado, enfocado en la aplicación práctica de técnicas estadísticas usando R. En este sitio, se irá subiendo el material de apoyo para las sesiones de ayudantía del curso."
  },
  {
    "objectID": "index.html#descripción-del-curso",
    "href": "index.html#descripción-del-curso",
    "title": "Taller de Métodos y Técnicas de Investigación I",
    "section": "Descripción del curso",
    "text": "Descripción del curso\nEl curso pretende ofrecer una breve introducción a las técnicas de investigación y análisis cuantitativo más utilizadas en sociología. Para ello se comenzará haciendo una revisión general de los principales conceptos, supuestos y aplicaciones de técnicas básicas de análisis estadístico descriptivo e inferencial (prueba de hipótesis). Luego de ello, se introducen los aspectos básicos de técnicas estadísticas avanzadas—particularmente de modelos de regresión multivariados—. Finalmente, se discuten los usos de estos modelos: cómo comprender su interpretación, y cómo usarlos para trabajar preguntas de investigación concretas. A lo largo del curso, se espera que los estudiantes entiendan la lógica de investigación cuantitativa, su aplicación a través del uso del software estadístico R, así como la interpretación de resultados a través de la lectura de artículos científicos.\nEn suma, este taller está diseñado para que estudiantes del Magíster en Sociología desarrollen habilidades prácticas en análisis estadístico utilizando el lenguaje de programación R. En esta página web, a través de 5 sesiones (las de ayudantía), cubriremos desde lo básico de R hasta análisis de regresión lineal múltiple. Además, dejaremos recursos para que puedan utilizarlo en sus investigaciones de Magíster.\n\nObjetivos de aprendizaje\nObjetivo general:\n\nIntroducir a los/as estudiantes en el uso, aplicación e interpretación de técnicas estadísticas descriptivas e inferenciales utilizadas comúnmente en la investigación sociológica\n\nObjetivos específicos:\n\nIntroducir los/as estudiantes en el uso de conceptos básicos del análisis estadístico (variable, muestra/población, distribución muestral, estimación de parámetros, etc.)\nIntroducir a los/as estudiantes en la aplicación de técnicas estadísticas univariadas, bivariadas y multivariadas\nFamiliarizar a los/as estudiantes con el uso base de datos y de paquetes estadísticos (particularmente R)\nFamiliarizar a los/as estudiantes con la lectura de artículos sociológicos cuantitativos, y con la formulación de modelos estadísticos para resolver problemas sociológicos"
  },
  {
    "objectID": "index.html#estructura-del-curso",
    "href": "index.html#estructura-del-curso",
    "title": "Taller de Métodos y Técnicas de Investigación I",
    "section": "Estructura del curso",
    "text": "Estructura del curso\nEl curso consta de 5 sesiones prácticas:\n\nSesión 1: Introducción a R + Estadística descriptiva (I)\nSesión 2: Estadística descriptiva (II) + Prueba de hipótesis (I)\nSesión 3: Prueba de hipótesis (II) + ANOVA\nSesión 4: Correlación bivariada + Regresión lineal simple\nSesión 5: Regresión lineal múltiple"
  },
  {
    "objectID": "index.html#información-del-curso",
    "href": "index.html#información-del-curso",
    "title": "Taller de Métodos y Técnicas de Investigación I",
    "section": "Información del curso",
    "text": "Información del curso\n\n\n\n\n\n\nDetalles\n\n\n\n\nProfesora: Carollina Aguilera\nAyudante: Fran Sofía Núñez\nHorario de Ayudantía: Martes a las 19.00 hrs\nModalidad: Online via Teams"
  },
  {
    "objectID": "index.html#antes-de-comenzar",
    "href": "index.html#antes-de-comenzar",
    "title": "Taller de Métodos y Técnicas de Investigación I",
    "section": "Antes de comenzar",
    "text": "Antes de comenzar\nPara seguir este curso necesitarás:\n\nInstalar R\nInstalar RStudio\nConocimientos básicos de estadística\n\nRevisa la sección Recursos para guías de instalación y materiales complementarios.\n\n\n\n\n\n\n\nContacto\n\n\n\nPara consultas del curso, puedes contactarme por fransofia.nr@gmail.com."
  },
  {
    "objectID": "lectures/05-regression.html",
    "href": "lectures/05-regression.html",
    "title": "Sesión 5: Regresión Lineal Múltiple",
    "section": "",
    "text": "En construcción\n\n\n\nContenido en desarrollo. Disponible próximamente."
  },
  {
    "objectID": "lectures/05-regression.html#objetivos-de-la-sesión",
    "href": "lectures/05-regression.html#objetivos-de-la-sesión",
    "title": "Sesión 5: Regresión Lineal Múltiple",
    "section": "Objetivos de la sesión",
    "text": "Objetivos de la sesión\n\nAjustar modelos de regresión múltiple\nInterpretar coeficientes con múltiples predictores\nTrabajar con variables dummy\nDiagnosticar problemas en regresión\n\n\nÚltima actualización: [Fecha]"
  },
  {
    "objectID": "lectures/03-inferential-statistics.html",
    "href": "lectures/03-inferential-statistics.html",
    "title": "Sesión 3: Prueba de Hipótesis (II) y ANOVA",
    "section": "",
    "text": "En construcción\n\n\n\nContenido en desarrollo. Disponible próximamente."
  },
  {
    "objectID": "lectures/03-inferential-statistics.html#objetivos-de-la-sesión",
    "href": "lectures/03-inferential-statistics.html#objetivos-de-la-sesión",
    "title": "Sesión 3: Prueba de Hipótesis (II) y ANOVA",
    "section": "Objetivos de la sesión",
    "text": "Objetivos de la sesión\n\nRealizar pruebas t pareadas\nAplicar pruebas no paramétricas\nEjecutar ANOVA de un factor\nRealizar comparaciones post-hoc\n\n\nÚltima actualización: [Fecha]"
  },
  {
    "objectID": "lectures/02-statistics.html",
    "href": "lectures/02-statistics.html",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "",
    "text": "En esta sesión entraremos de lleno en estadística descriptiva, retomando desde contenidos de la sesión pasada, pero con un enfoque más riguroso. Sumado a esto, nos enfocaremos más en esto desde una perspectiva más estadística y usando R aplicadamente, sin deternos tanto en R mismo. Aunque también aprovecharé de mostrarle como crear funciones de usuario para hacer estadísticas descriptivas con una sola función."
  },
  {
    "objectID": "lectures/02-statistics.html#objetivos-de-la-sesión",
    "href": "lectures/02-statistics.html#objetivos-de-la-sesión",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "Objetivos de la sesión",
    "text": "Objetivos de la sesión\n\nComprender la estadística descriptiva\nConocer medidas de la estadística descriptiva\nCrear visualizaciones avanzadas.\nIntroducción a test de hipótesis y estadística inferencial\n\nPero antes de comenzar, carguemos los paquetes que utilizaremos, donde además les muestro mi forma favorita de cargar y traer paquetes en un solo paso (con pacman).\n\n#Forma 1 (Forma clásica)\ninstall.packages(\"tidyverse\") # colección de paquetes, dplyr entre ellos\ninstall.packages(\"dplyr\") # manipular datos\ninstall.packages(\"sjmisc\") # explorar datos\n\n#Forma 2 (Mejor para reproductibilidad)\ninvisible(lapply(c(\"tidyverse\", # colección de paquetes, dplyr entre ellos\n                   \"dplyr\", # manipular datos\n                   \"sjmisc\"), # explorar datos\n                 function(p) \n  if (!requireNamespace(p, quietly = TRUE)) install.packages(p)))\n\n# Llamar librería \nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(sjmisc)\n\n# Forma 3 (Mi favorita. Es `install.packages()` -si no está bajado- más `library`)\n\nif (!requireNamespace(\"pacman\", quietly = TRUE))\n  install.packages(\"pacman\")\npacman::p_load(tidyverse, # colección de paquetes, dplyr entre ellos, pero también haven\n               dplyr, # manipular datos\n               psych, # para estadísticas descriptivas\n               sjmisc, # explorar datos\n               ggplot2, # para visualizar gráficos\n               scales) # para ajustar gráficos"
  },
  {
    "objectID": "lectures/02-statistics.html#datos",
    "href": "lectures/02-statistics.html#datos",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "Datos",
    "text": "Datos\nPara comprender que son las estadísticas descriptivas, y para que las usaremos como futurxs sociólogxs, partamos viendo qué son los datos. Los datos son valores (o mediciones) de variables que han sido recolectados y organizados para su análisis. La palabra datos se define como información factual (como mediciones o estadísticas) utilizada como base para el razonamiento, para la discusión o para cálculos (Merrian-Webster). Existen tres tipos de estrucutas de datos:\n\nDatos de corte transversal: son mediciones de un conjunto de variables para un gurpo de unidades (personas, hogares, empresas, países, etc.) en un mismo momento del tiempo. Un ejemplo de esto puede ser los puntajes PSU de un año dado. Una base de datos de datos de corte transversal, e.g., es la CASEN, la ENUT, la ENE, etc.\nDatos de series de tiempo: sucesión de registros de una o varias variables de una única unidad, que son medidos en determinados momento del tiempo en un orden cronológico claro. Es importante resaltar que registra una única entidad/unidad a lo largo del tiempo. Un ejemplo podría ser el IMACEC o el PIB de tal a tal periodo.\nDatos de panel o longitudinales: sucesión de registros de un conjunto de variables para un grupo de unidades medidas en varios momentos del tiempo. Los datos de panel/longitudinales combinan las dimensiones de corte transversal y series de tiempo de los datos, pues es una sucesión de registros de un conjunto de variables para un grupo de unidades, medidas en varios momentos del tiempo con un orden cronológico claro. Un ejemplo de esto podría ser la tasa de crecimiento anual del PIB real para un grupo de países de tal a cual periodo.\n\nA su vez, existen dos tipos de recolección de datos:\n\nEstudios observacionales: los datos se recopilan por medio de la observación de los valores de las variables de interés sin intervención o influencia en ellos; o\nExperimentos: tras una exposición de ciertas unidades a una intervención, se observan los valores de las variables de interés presentes en los resultados."
  },
  {
    "objectID": "lectures/02-statistics.html#tipos-de-variables",
    "href": "lectures/02-statistics.html#tipos-de-variables",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "Tipos de variables",
    "text": "Tipos de variables\nUna variable es una característica o atributo que puede tomar valores diferentes para distintas unidades. Las variables tienen dos categorías principales que las distinguen:\n\nVariables categóricas: puede tomar un número limitado de valores definido sobre la base de alguna característica cualitativa. A su vez, dentro de las variables categóricas se encuentran\n\n\nVariable categórica nominal: es una variable categórica/cualitativa sin ningún orden o jerarquía clara. Por ejemplo, una variable que registre nombres de un curso, comunas, países, etc. Dentro de las variables categóricas nominales, se encuentran las variables dummy, las que poseen solo dos valores a los que se les puede asignar un número, generalmente \\(0\\) o \\(1\\), donde \\(1\\) indica presencia del atributo y \\(0\\) ausencia.\nVarible categórica ordinal: es una variable categórica/cualitativa que tiene un orden o jerarquí establecida entre sus categorías. Por ejemplo, el nivel educacional o las variables en “Escala Likert”\n\nEn R, para crear una variable cualitativa, deben escribirse entre comillas sus categorías, como ya vimos la sesión pasada. Por ejemplo,\n\n# Variables categóricas\n\nvar_nominal &lt;- c(\"Karl Marx\", \"Rosa Luxemburgo\", \"Wooldrigde\")\n\nclass(var_nominal) # Comprobar naturaleza de la variable\n## [1] \"character\"\n\nvar_ordinal_educ&lt;- c(\"Secundaria Incompleta\", \"Secundaria Completa\",\n                     \"Educación Superior Incompleta\", \"Educación Superior Completa\")\nvar_ordinal_likert &lt;- c(\"Muy malo\", \"Malo\", \"Maomeno\",\n                        \"Bueno\", \"Muy bueno\")\n\nclass(var_ordinal_educ) # Comprobar naturaleza de la variable\n## [1] \"character\"\nclass(var_ordinal_likert) # Comprobar naturaleza de la variable\n## [1] \"character\"\n\nSuele ser útil, en R, asignarles números a las variables cualitativas para un análisis estadísticos posteriores. Por ejemplo, podríamos tomar var_ordinal_likert y, además de que tenga sus categorías asociadas, también tengan un número. Por ejemplo, que \"Muy malo\" sea 1 y \"Muy bueno\" sea 5. Esto podemos hacerlo de dos maneras que mostramos de inmediato. Por cierto, la segunda la hacemos con haven que es un paquete dentro de tidyverse, y que usualmente usaremos ese paquete para cargar bases de datos, pero que también sirve para recodificar:\n\n# 1) Versión con un factor ordenado (tienes la categoría y su código interno)\nvar_ordinal_likert &lt;- factor(\n  var_ordinal_likert,\n  levels  = c(\"Muy malo\", \"Malo\", \"Maomeno\", \"Bueno\", \"Muy bueno\"),\n  ordered = TRUE\n)\n# Para ver el código numérico (1=Muy malo … 5=Muy bueno):\nas.integer(var_ordinal_likert)\n## [1] 1 2 3 4 5\n\n\n# 2) Si prefieres un vector numérico “double” con etiquetas (dos niveles),\n#    puedes usar haven::labelled\n\nvar_ordinal_likert &lt;- haven::labelled(\n  as.integer(factor(\n    var_ordinal_likert,\n    levels  = c(\"Muy malo\", \"Malo\", \"Maomeno\", \"Bueno\", \"Muy bueno\"),\n    ordered = TRUE\n  )),\n  labels = c(\n    \"Muy malo\"  = 1,\n    \"Malo\"      = 2,\n    \"Maomeno\"   = 3,\n    \"Bueno\"     = 4,\n    \"Muy bueno\" = 5\n  )\n)\n\n# Comprobamos:\nvar_ordinal_likert\n## &lt;labelled&lt;integer&gt;[5]&gt;\n## [1] 1 2 3 4 5\n## \n## Labels:\n##  value     label\n##      1  Muy malo\n##      2      Malo\n##      3   Maomeno\n##      4     Bueno\n##      5 Muy bueno\n\n\nVariables cuantitativas: son variables medidas en una escala númerica, como la edad, temperatura, estatura, etc. Y, por lo tanto, que el número mismo indica ordinalidad y jerarquía entre los valores (\\(x&lt;x+1\\)). También hay dos tipos de variables cuantitativas\n\n\nVariable cuantitativa discreta: es aquella que solo puede tomar números específicos como valores, sin poder tomar un valor intermedio entre dos valores específicos. Es decir, que se expresan en números enteros. Matemáticamente, simplemente son variables en que sus valores \\(x \\in \\mathbb{N}\\). Un ejemplo, puede ser el número de ventas (no se puede vender -100), la edad de las personas encuestadas (no se puede tener -2), etc.\nVariable cuantiativa continua: puede tomar como valores un número infinito de posibilidades dentro de un rango de números, por lo que se expresa en números reales: \\(x\\in \\mathbb{R}\\). Un ejemplo de esto puede ser una cuenta corriente, el peso de las personas, la temperatura, etc.\n\nEn R, las variables cuantitativas tienen por categorías números, sin “…”. Además, si se quiere dejar como variable cuantitativa discreta (integer), se le puede añadir una L después del número. Esto es porque en R cualquier literal numérico sin sufijo se interpreta por defecto como tipo numeric (variable cuantitativa). Al añadir la L se le indica a R que es un integer (número entero). No obstante, generalmente para el análisis estadístico no afectará mucho.\n\n# Variables cuantitativas discretas\nvar_discreta_hijos &lt;- c(0L, 1L, 2L, 3L, 4L)\nvar_discreta_autos &lt;- c(1L, 0L, 2L, 1L, 3L)\nclass(var_discreta_hijos)   \n## [1] \"integer\"\nclass(var_discreta_autos)   \n## [1] \"integer\"\n\n# Variables cuantitativas continuas\nvar_continua_altura &lt;- c(1.65, 1.72, 1.58, 1.80, 1.75)\nvar_continua_peso   &lt;- c(65.4, 70.2, 58.9, 80.0, 72.5)\nclass(var_continua_altura)  # numeric\n## [1] \"numeric\"\nclass(var_continua_peso)    # numeric\n## [1] \"numeric\""
  },
  {
    "objectID": "lectures/02-statistics.html#estadísticas-descriptivas",
    "href": "lectures/02-statistics.html#estadísticas-descriptivas",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "Estadísticas descriptivas",
    "text": "Estadísticas descriptivas\nLas estadísticas descriptivas son valores fácilmente interpretables y que entregan un “resumen” de las características más importantes de un conjunto de datos, además de que utilizan para su cálculo operaciones aritméticas simples. Las estadísticas descriptivas son el primer paso en el análisis exploratorio de datos. Antes del análisis estadístico más riguroso de los datos, es esencial examinar las estadísticas descriptivas de todas las variables para:\n\nDetectar errores de medición o valores atípicos (outliers) en los datos.\nDetectar patrones y tendencias en los datos.\nEvaluar la plausibilidad de los supuestos de trabajo.\nEstablecer hipótesis de trabajo.\n\nA su vez, las estadísticas descriptivas se pueden clasificar en tres grupos:\n\nMedidas de localización o tendencia central: Se calculan para describir un valor central alrededor del cual se ubican (distribuyen) los datos. En otras palabras, estas medidas determinan el valor donde se ubican mayoritariamente las observaciones\nMedidas de dispersión o variabilidad: Proporcionan una descripción de la “dispersión de los datos” o qué tan lejos están las observaciones de la tendencia central.\nMedidas de posición: Resumen la posición relativa de valores específicos en los datos.\n\nAntes de seguir profundizando esto, utilizaremos bases de datos reales y conocidas para ir ejemplificando el contenido con datos observacionales. Partamos con la Encuesta de Caracterización Socioeconómica Nacional (CASEN) más actual, la CASEN 2022. Esta se puede obtener en el siguiente link, que cuenta con 202.231 casos (encuestados) y 918 variables.\n\n## Obtener ruta \n\ngetwd() # Para obtener nuestro directorio (en este casode nuestro RProject)\n## [1] \"C:/Users/Fran/OneDrive/Escritorio/UAH/MAGISTER ECONOMIA UCH/Ayudantías/Taller métodos/metodos-mgsocio-uah/lectures\"\n\n# Cargar formato sav (SPSS)\ncasen2022&lt;-haven::read_sav(\"data-sesiones/CASEN 2022.sav\")\n\ndim(casen2022)\n## [1] 202231    918\n\n# Cargar formato dta (STATA)\n\n# casen2022&lt;-haven::read_dta(\".../CASEN 2022.dta\")\n\nContinuemos. Antes de pasar a estos tres grupos de estadísticas descriptivas, conviene tener en claro el concepto de estadísticos de orden. Los estadísticos de orden es la ordenación de un conjunto de datos u obsrvaciones, dond \\(y_k\\) es el \\(k-\\)ésimo menor valor del conjunto de observaciones. Por ejemplo, si tenemos estos cuatro datos: \\[\nx_1 =9; x_2=3, x_3 = 12; x_3 =1 ; x_5=2\n\\] Los estadísticos de orden, \\(y_i\\), corresponderían a \\[\ny_1=1; y_2=2; y_3=3; y_4=9; y_5=12\n\\] Es decir, la ordenación de \\(x_i\\) de menor a mayor. Dicho esto, pasemos, en primer lugar, a las medidas de localización o tendencia central."
  },
  {
    "objectID": "lectures/02-statistics.html#medidas-de-localización-o-tendencia-central",
    "href": "lectures/02-statistics.html#medidas-de-localización-o-tendencia-central",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "1.1. Medidas de localización o tendencia central",
    "text": "1.1. Medidas de localización o tendencia central\n\nMedia o promedio\nLa media de \\(n\\) observaciones de una variable, (x_1, , x_n), que denotaremos por ({x}), está definida por la suma de los valores de todas las observaciones, dividida por el número de observaciones: \\[\n\\bar{x} = \\frac{x_1 + x_2 + \\dots + x_n}{n} = \\frac{1}{n} \\sum_{i=1}^{n} x_i.\n\\] Por ejemplo, supongamos que los datos son: \\[\nx_1 = 0.7; \\quad x_2 = 1.2; \\quad x_3 = 0.9; \\quad x_4 = 0.6; \\quad x_5 = 1.4; \\quad x_6 = 1.8; \\quad x_7 = 2.5.\n\\] La media en este caso viene dada por: \\[\n\\bar{x} = \\frac{0.7 + 1.2 + 0.9 + 0.6 + 1.4 + 1.8 + 2.5}{7} = 1.3.\n\\] En R, la media se obtiene simplemente con el comando mean(). Veamos como obtener la media de alguna variable de interés en la CASEN 2022.\n\n# Obtener media mediante mean()\nmean(casen2022$ytrabajocor) # Ingreso del trabajo corregido\n## [1] NA\n                            # Ups! \nmean(casen2022$ytrabajocor,\n     na.rm = TRUE) # ahora si :)\n## [1] 667690.9\n\nComo se ve, el salario promedio de los encuestados de la CASEN 2022 es de 667.690CLP. El comando na.rm = TRUE es para sacar las observaciones NA de la variable, las cuales registran los casos\n\n\nMediana\nLa mediana es el valor medio de un conjunto de observaciones cuando se les ordena de menor a mayor. Si el número de observaciones es par, entonces la mediana es la suma de los dos valores medios, dividida por 2. Si ordenamos las observaciones del ejemplo anterior de menor a mayor obtenemos los estadísticos de orden del conjunto de observaciones: \\[\ny_1 = 0.6, \\quad y_2 = 0.7, \\quad y_3 = 0.9, \\quad y_4 = 1.2, \\quad y_5 = 1.4, \\quad y_6 = 1.8, \\quad y_7 = 2.5.\n\\] Notar que los estadísticos de orden cumplen con \\[\ny_1 = \\min(x_1, x_2, \\dots, x_7), \\quad y_7 = \\max(x_1, x_2, \\dots, x_7), \\quad y_1 \\leq y_2 \\leq \\dots \\leq y_7.\n\\] Entonces, para calcular la mediana se tiene que ordenar primero la muestra de datos de menor a mayor, tal que se cumpla con los estadísticos de orden. Así, la mediana en este ejemplo, que denotamos por \\(\\tilde{x}\\), viene dada por: \\[\n\\tilde{x} = y_4 = 1.2.\n\\] Ahora bien, en este caso, tenemos un \\(n\\) impar. Luego, es más fácil establecer la mediana. Supongamos ahora que tenemos un número par de cantidad de datos, un \\(n=6\\), por ejemplo. \\[\nx_1 = 0.7, \\quad x_2 = 1.2, \\quad x_3 = 0.9, \\quad x_4 = 0.6, \\quad x_5 = 1.4, \\quad x_6 = 1.8.\n\\] Es decir, los mismos datos que antes, salvo que hemos excluido el valor más grande. Entonces los estadísticos de orden son: \\[\ny_1 = 0.6, \\quad y_2 = 0.7, \\quad y_3 = 0.9, \\quad y_4 = 1.2, \\quad y_5 = 1.4, \\quad y_6 = 1.8.\n\\] Y la mediana es: \\[\n\\tilde{x} = \\frac{y_3 + y_4}{2} = \\frac{0.9 + 1.2}{2} = 1.05.\n\\] Por lo tanto, la mediana en este caso es el promedio simple entre los dos números ``al medio’’ del conjunto de datos. Si tenemos que \\(n=6\\), entonces la mediana es el promedio entre \\(x_3\\) y \\(x_4\\), arrojando un valor nuevo. En suma, la mediana es un valor que puede o no puede estar en el conjunto de datos. Si el conjunto de dato es par, entonces será el promedio simple entre los 2 datos del medio y si es impar simplemente será el valor del medio.\nEn R esto se obtiene con median():\n\n# Obtener mediana a través de median()\nmedian(casen2022$ytrabajocor,\n     na.rm = TRUE) # Ingreso del trabajo corregido\n## [1] 480000\n\nComo vemos, la mediana de los ingresos del trabajo (salario), es 480.000 CLP. Lo cual habla bastante de la dispersión de los ingresos, pues el promedio es de 667.690 CLP. Siguiendo la lógica de los estadísticos de orden, lo que tenemos es que el \\(50\\%\\) de los encuestados gana 480.000 CLP o menos. Y, sin embargo, el promedio es de 667.690 CLP, i.e., de 187.690 CLP más. Esto se debe a que hay ingresos muy altos, que elevan el promedio. Y la media es una medida sensible a los valores extremos. En breve, profundizaremos sobre esto, pero tiene que ver con robustez de las medidas de localización, lo cual será clave más adelante para para realizas estimaciones con estas medidas.\n\n\nModa\nLa moda es el valor más frecuente de un conjunto de observaciones. Un conjunto de valores puede tener más de una moda. Por ejemplo, supongamos que los datos son: \\[\nx_1 = 0.7; \\quad x_2 = 1.2; \\quad x_3 = 1.2; \\quad x_4 = 0.6; \\quad x_5 = 1.4; \\quad x_6 = 1.8; \\quad x_7 = 2.5.\n\\] Entonces la moda, que denotaremos por \\(\\tilde{\\tilde{x}}\\)1, viene dada por: \\[\n\\tilde{\\tilde{x}}= 1.2.\n\\] Para un conjunto de valores puede haber más de una moda.\nEn R, no hay un “paquete base” para extraer la moda. Pero si se puede hacer una función, o bien, usar paquetes. Veamos\n\n# Moda en el caso de datos unimodales discretos\nx &lt;- c(1, 5, 1, 6, 2, 1, 6, 7, 1)\n\n#Función para calcular la moda\nmode &lt;- function(x) {\n   return(as.numeric(names(which.max(table(x)))))\n}\n\nmode(x)\n## [1] 1\n\noptions(scipen = 999) # Para desactivar notación cientifica\n\nmode(casen2022$ytrabajocor)\n## [1] 400000\n\n# Moda con mfv() de modeest\npacman::p_load(modeest)\n\nmodeest::mfv(casen2022$ytrabajocor, na_rm = TRUE)\n## [1] 400000\n\nComo se puede observar, la moda de los ingresos del trabajo es de 400.000 CLP. Es decir, que el valor que más se repite entre los salarios de los encuestados es de 400 lucas.\n\n\n1.1.1. Robustez de las medidas de localización\nAhora bien, ¿cuán robustas son las medidas de localización? Un tema a considerar es cuál es el impacto de observaciones aberrantes en las medidas de localización, es decir, qué impacto tiene la presencia de una fracción pequeña de observaciones con errores muy grandes en su registro o que son atípicas por otro motivo en el valor de las medidas de localización.\nHablaremos indistintamente de observaciones aberrantes, observaciones extrañas y outliers. Si el número de observaciones es pequeño, se puede investigar uno por uno los valores aberrantes y corregir, reemplazar o eliminar las observaciones en cuestión. Sin embargo, cuando el número de observaciones es más grande, uno quisiera medidas de localización que sean insensibles a la presencia de una fracción moderada de observaciones extrañas y que, al mismo tiempo, sean un buen resumen numérico de la tendencia central de los datos. Analicemos, pues, cuán robusta son estas medidas.\n\nRobustez de la media\nSupongamos que los datos son \\[\nx_1 = 0.7;\\ x_2 = 1.2;\\ x_3 = 0.9;\\ x_4 = 0.6;\\ x_5 = 1.4;\\ x_6 = 1.8;\\ x_7 = 2.5.\n\\] Como vimos la media viene dada por \\(\\bar{x} = 1.3\\). Intuitivamente la media no es robusta, pues un solo outlier puede tener un efecto devastador sobre su valor. En efecto, si una de las observaciones, digamos la primera, es reportada con un error de medición \\(e\\), de modo que \\[\nx_1 = 0.7 + e\n\\] entonces la media, como función del error \\(e\\), será: \\[\n\\bar{x}(e) = 1.3 + \\frac{e}{7}\n\\] y tenemos que \\[\n\\lim_{e \\to \\infty} \\bar{x}(e) = \\infty, \\quad \\lim_{e \\to -\\infty} \\bar{x}(e) = -\\infty.\n\\] En el caso más general tenemos \\(\\bar{x}(e) = \\bar{x}(0) + \\frac{e}{n}\\), de modo que esta expresión tiende a \\(\\pm\\infty\\) cuando \\(e\\) tiende a \\(\\pm\\infty\\).\nEn suma, la media es una medida de localización central muy sensible a valores atípicos/outliers. En este sentido, a pesar de que indica información, hay que tener cuidado y en general suele ser complementada con otras medidas, tal como vimos con la mediana.\n\n\nRobustez de la mediana\nComo vimos, los estadísticos de orden de las observaciones anteriores están dadas por: \\[\ny_1 = 0.6, \\quad y_2 = 0.7, \\quad y_3 = 0.9, \\quad y_4 = 1.2, \\quad y_5 = 1.4, \\quad y_6 = 1.8, \\quad y_7 = 2.5.\n\\] Vimos también que la mediana, que denotamos por \\(\\tilde{x}\\), viene dada por: \\[\n\\tilde{x} = y_4 = 1.2.\n\\] Ahora, suponiendo nuevamente que la primera observación se midió con error \\(e\\), de modo que \\(x_1 = 0.7 + e\\), y denotando por \\(\\tilde{x}(e)\\) la mediana cuando \\(x_1\\) se reemplaza por \\(x_1 + e\\), tenemos \\[\n\\tilde{x}(e) =\n\\begin{cases}\n    1.2 & \\text{si } e \\leq 0.5, \\\\\n    0.7 + e & \\text{si } 0.5 &lt; e \\leq 0.7, \\\\\n    1.4 & \\text{si } e &gt; 0.7.\n\\end{cases}\n\\] En el caso general con \\(n = 2m+1\\) observaciones, donde elegimos tamaño impar solo para simplificar las expresiones, tendremos que \\(\\tilde{x}(e) \\in [y_m, y_{m+2}]\\). Por tanto, la influencia de un valor aberrante en la mediana está acotada. Es decir, la mediana es una medida robusta.\n\n\nRobustez de la moda\nSupongamos que los datos están dados por: \\[\nx_1 = 0.7, \\quad x_2 = 1.2, \\quad x_3 = 1.2, \\quad x_4 = 0.6, \\quad x_5 = 1.4, \\quad x_6 = 1.8, \\quad x_7 = 99.9.\n\\] Entonces la moda viene dada por \\(\\tilde{\\tilde{x}} = 1.2\\).\nSuponiendo nuevamente que la primera observación se midió con error \\(e\\), de modo que \\(x_1 = 0.7 + e\\), y denotando por \\(\\tilde{\\tilde{x}}(e)\\) la moda cuando \\(x_1\\) se reemplaza por \\(x_1 + e\\), tenemos que: \\[\n\\lim_{e \\to \\infty} \\tilde{\\tilde{x}}(e) = 1.2, \\quad \\lim_{e \\to -\\infty} \\tilde{\\tilde{x}}(e) = 1.2.\n\\] En cambio, si la observación con error es la segunda observación, de modo que se midió \\(x_2 = 1.2 + e\\), para \\(e = 0.6\\), la moda será \\(1.8\\). El cambio en la moda puede ser mucho mayor, existen valores de \\(e\\) para los cuales la moda es \\(99.9\\). En contraste, no existen valores de \\(e\\) para los cuales la mediana cambie tanto.En suma, la moda es muy sensible a la presencia de outliers, no obstante va depende en qué localización de los datos se encuentre. Entonces, no siempre es muy sensible, pero a veces sí.\n\n\nSintesis\nComo se desprende de las expresiones derivadas en los apartados anteriores, el impacto de valores extremos o atípicos es acotado tanto para la mediana como para la moda, mientras que para la media crece sin límite cuando \\(|e|\\) tiende a infinito.Al mismo tiempo, la mediana pareciera ser más robusta que la moda, pues la influencia de errores de medición es menor. La moda pareciera estar entremedio, el impacto de outliers es acotado pero puede ser mucho más grande que su impacto en la mediana. Entonces, ¿media, mediana o moda?\nEn general, la moda se usa poco para resumir en una cifra la localización de los datos. Probablemente, porque es “demasiado localizada”. Por ejemplo, puede que la moda esté en 0, porque un 10% de las observaciones son iguales a cero, pero la mayoría de los datos sean mayores que 100. En casos como este la moda captura muy mal la localización de los datos, pues uno quisiera algún número mayor que 100, no cero. La media es la medida de localización más utilizada en la práctica, seguida de la mediana. Esto nos lleva a considerar las siguientes ventajas y desventajas\n\nMediana: más robusta.\nMedia: usa toda la información. Al menos intuitivamente, la robustez de la mediana tiene como contraparte que usa poco la información disponible.\n\nEntonces, la media entrega más información, pero es menos robusta, en cambio la mediana sufre la ventaja/desventaja opuesta. La digresión anterior motiva considerar medidas de localización más robustas que la media y que usan más información que la mediana. Con ese objetivo consideramos a continuación las medias podadas.\n\n\n\nMedias podadas\nSupongamos que los datos están dado por: \\[\nx_1 = 0.7, \\; x_2 = 1.2, \\; x_3 = 0.9, \\; x_4 = 0.6, \\; x_5 = 1.4, \\; x_6 = 1.8, \\; x_7 = 2.5,\n\\] Como vimos, sus estadísticos de orden correspondientes son: \\[\ny_1 = 0.6, \\; y_2 = 0.7, \\; y_3 = 0.9, \\; y_4 = 1.2, \\; y_5 = 1.4, \\; y_6 = 1.8, \\; y_7 = 2.5.\n\\]\nDefinimos la siguiente medida de localización: \\[\n\\bar{x}^p = \\frac{1}{5}(y_2 + y_3 + \\dots + y_6).\n\\] Es decir, primero podamos los datos de la muestra ordenada de menor a mayor, removiendo un valor de cada extremo y luego calculamos el promedio de las observaciones podadas. El estadístico descriptivo que resulta se conoce como media podada, de nivel \\(k=1\\) porque removimos una observación de cada extremo. Lo denominamos por \\(\\bar{x}^p\\). Para las observaciones en cuestión tenemos que la media podada de nivel 1 es 1,2.\nEn síntesis, se eliminan los valores extremos, el más pequeño y el más grande en este caso. Y después calculamos el promedio. Con ello, se le agrega mayor robustez y estaremos usando más información que usando la mediana. Veamos el caso general, no solo para \\(k=1\\)\n\nMedias podadas: Caso General\n\nSean \\(x_1, \\dots, x_n\\) las observaciones y \\(y_1, \\dots, y_n\\) los estadísticos de orden correspondientes. Entonces, para \\(k &lt; n/2\\) definimos la media podada de nivel \\(k\\) mediante: \\[\n    \\bar{x}^p = \\frac{1}{n - 2k} \\sum_{i = k+1}^{n-k} y_i.\n\\]\n\nEn palabras: dadas observaciones \\(x_1, \\dots, x_n\\), la media podada de nivel \\(k\\) será el promedio de los valores que se obtiene luego de remover \\(k\\) observaciones de cada uno de sus extremos (las \\(k\\) más grandes y las \\(k\\) más pequeñas). Las medias podadas de nivel \\(k = 1\\) —se remueve el mínimo y máximo— se utilizan para pasar de las evaluaciones individuales de los jurados en varios deportes, entre ellos nado sincronizado y gimnasia, a la evaluación agregada.\nEn R, esto se puede hacer de dos formas, con una función o con mean() y especificaciones:\n\n# Datos de ejemplo\nx &lt;- c(0.7, 1.2, 0.9, 0.6, 1.4, 1.8, 2.5)\n\n# 1) Función manual para media podada de nivel k\nmedia_podada &lt;- function(x, k) {\n  n &lt;- length(x)\n  if (2*k &gt;= n) stop(\"k debe ser menor que n/2\")\n  y &lt;- sort(x)\n  mean(y[(k + 1):(n - k)])\n}\n\n# Cálculo de la media podada para k = 1\nmedia_podada(x, 1)\n## [1] 1.2\n\n# 2) Usando la función base mean() con el argumento trim\n#    trim espera la fracción a recortar por cada extremo: k/n\nk &lt;- 1\nn &lt;- length(x)\nmean(x, trim = k / n)\n## [1] 1.2\n\n# Media podada de los ingresos del trabajo\nmean(casen2022$ytrabajocor, \n     trim = k/n,\n     na.rm=TRUE)\n## [1] 521452.3\n\n\n\n\nMedias Windorizadas (opcional)\nEsto es una medición opcional en el sentido de que no se usa mucho. Pero puede ser útil. Supongamos que los datos están dado por: \\[\nx_1 = 0.7; \\, x_2 = 1.2; \\, x_3 = 0.9; \\, x_4 = 0.6; \\, x_5 = 1.4; \\, x_6 = 1.8; \\, x_7 = 2.5.\n\\] Como vimos, sus estadísticos de orden correspondientes son: \\[\ny_1 = 0.6, \\, y_2 = 0.7, \\, y_3 = 0.9, \\, y_4 = 1.2, \\, y_5 = 1.4, \\, y_6 = 1.8, \\, y_7 = 2.5.\n\\] Definimos la siguiente medida de localización: \\[\n\\bar{x}^p = \\frac{1}{7} [y_2 + y_2 + y_3 + y_4 + y_5 + y_6 + y_6].\n\\]\nEs decir, ordenadas las observaciones de menor a mayor, sustituimos un valor de cada extremo por el valor inmediatamente anterior o posterior y luego calculamos el promedio de todos los valores. El estadístico descriptivo que resulta se conoce como media winsorizada, de nivel \\(k = 1\\) porque sustituimos una observación de cada extremo. Lo denotamos por \\(\\bar{x}^w\\). Para las observaciones en cuestión tenemos que la media winsorizada de nivel 1 es 1,21 (aproximadamente).\n\nMedias Winsorizadas: Caso General\nSean \\(x_1, \\dots, x_n\\) las observaciones y \\(y_1, \\dots, y_n\\) los estadísticos de orden correspondientes. Entonces, para \\(k &lt; n/2\\) definimos la media winsorizada de nivel \\(k\\) mediante: \\[\n  \\bar{x}^w = \\frac{k y_{k+1} + \\sum_{i=k+1}^{n-k} y_i + k y_{n-k}}{n}.\n\\]\n\nEn palabras: dadas observaciones \\(x_1, \\dots, x_n\\), la media winsorizada de nivel \\(k\\) será el promedio de los valores que se obtiene luego de sustituir \\(k\\) observaciones de cada uno de sus extremos (las \\(k\\) más grandes y las \\(k\\) más pequeñas) por el valor inmediatamente anterior o posterior. En R, se puede hacer con funciones nuevamente, o con el paquete DescTools.\n\n# Datos de ejemplo\nx &lt;- c(0.7, 1.2, 0.9, 0.6, 1.4, 1.8, 2.5)\n\n# 1) Función winsorizada + argumento na.rm\nmedia_winsorizada &lt;- function(x, k, na.rm = FALSE) {\n  if (na.rm) x &lt;- x[!is.na(x)]\n  n &lt;- length(x)\n  if (2*k &gt;= n) stop(\"k debe ser menor que n/2\")\n  y &lt;- sort(x)\n  # sustituir k extremos\n  y[1:k]           &lt;- y[k + 1]\n  y[(n - k + 1):n] &lt;- y[n - k]\n  mean(y)\n}\n\n# Cálculo de la media winsorizada para k = 1\nmedia_winsorizada(x, 1)\n## [1] 1.214286\n\nmedia_winsorizada(casen2022$ytrabajocor, 1,\n                  na.rm=TRUE)\n## [1] 667567.7\n\n\n# 2) Usando la función Winsorize() del paquete DescTools\npacman::p_load(DescTools)\n\n#  Vector limpio de NAs\nx &lt;- na.omit(casen2022$ytrabajocor)\n\n# 3) Definimos k y calculamos n\nk &lt;- 1\nn &lt;- length(x)\n\n# 4) Calculamos los cuantiles que usarán de umbrales\numbrales &lt;- quantile(x, probs = c(k/n, 1 - k/n), na.rm = TRUE)\n\n# 5) Winsorizamos usando 'val = umbrales'\nx_wins &lt;- Winsorize(x, val = umbrales)\n\n# 6) Y finalmente sacamos la media\nmean(x_wins)\n## [1] 667567.7\n\n\nSíntesis\n¿Qué hacemos en la práctica?\n\nSi se desea resumir la localización de los datos, parta por calcular la media, mediana y moda, así como también las medias podadas para algunos valores de \\(k\\) (por ejemplo, \\(k/n \\simeq 0,05\\) y \\(k/n \\simeq 0,1\\))\nSi obtiene valores similares, reportar la media y mediana\nSi hay diferencias importantes, mire los datos con cuidado, entienda de dónde vienen las diferencias y luego decida qué hacer."
  },
  {
    "objectID": "lectures/02-statistics.html#medidas-de-dispersión",
    "href": "lectures/02-statistics.html#medidas-de-dispersión",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "1.2. Medidas de dispersión",
    "text": "1.2. Medidas de dispersión\n\nLa varianza\nLas medidas de dispersión lo que buscan es determinar cuán dispersos están los datos con respectos a una medida de tendencia central. Una de ellas es la varianza. La varianza es una medida que resume la dispersión de las observaciones con respecto a su media.\n\nDadas \\(n\\) observaciones, \\(x_1, \\ldots, x_n\\), la varianza de este conjunto de datos, que denotaremos por \\(\\hat{\\sigma}^2\\), está dada por: \\[\n\\begin{aligned}\n\\hat{\\sigma}^2 &= \\frac{(x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 + \\dots + (x_n - \\bar{x})^2}{n}\\\\\n&= \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\\\\n&= \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 - \\bar{x}^2.\n\\end{aligned}\n\\]\n\nPor ejemplo, si tuvieramos que \\[\nx_1 = 0.7; \\quad x_2 = 1.2; \\quad x_3 = 0.9; \\quad x_4 = 0.6; \\quad x_5 = 1.4; \\quad x_6 = 1.8; \\quad x_7 = 2.5,\n\\] entonces, la varianza de estos datos sería \\[\n\\begin{aligned}\n  \\hat{\\sigma}^2 = \\frac{(0.7 - 1.3)^2 + (1.2 - 1.3)^2 + (0.9 - 1.3)^2}{7} \\\\\n  + \\frac{(0.6 - 1.3)^2 + (1.4 - 1.3)^2 + (1.8 - 1.3)^2 + (2.5 - 1.3)^2}{7} = 0.39.\n\\end{aligned}\n\\]\nOjo,cuando hay muchos datos, la fórmula más simple es el promedio de las observaciones al cuadrado, menos la media al cuadrado. O sea, la última igualdad que pusimos anteriormente, es decir,\n\\[\n  \\hat{\\sigma}^2 =\\frac{1}{n} \\sum_{i=1}^{n} x_i^2 - \\bar{x}^2.\n\\] Esta, sin embargo, es una demostración de la primera sumatoria, aunque bastante trivial.\n\nProof. Si \\[\n\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2 = \\frac{1}{n} \\sum_{i=1}^n x_i^2 - \\bar{x}^2\n\\] En efecto, \\[\n\\begin{aligned}\n\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2 &= \\frac{1}{n} \\sum_{i=1}^n \\left( x_i^2 - 2x_i \\bar{x} + \\bar{x}^2 \\right)\\\\\n&= \\frac{1}{n} \\sum_{i=1}^n x_i^2 - 2 \\bar{x} \\frac{1}{n} \\sum_{i=1}^n x_i + \\frac{1}{n} \\sum_{i=1}^n \\bar{x}^2\\\\\n&= \\frac{1}{n} \\sum_{i=1}^n x_i^2 - 2 \\bar{x}^2 + \\bar{x}^2\\\\\n&= \\frac{1}{n} \\sum_{i=1}^n x_i^2 - \\bar{x}^2.\n\\end{aligned}\n\\]\n\nEn R es mucho más fácil que estos cálculos tediosos. Esto se hace con el comando de R Base var(). No obstante, hay que tener en cuenta que var() es por defecto la varianaza muestra. Asumiendo que tenemos datos poblaciales podemos hacer dos cosas2. Veamos cómo:\n\n# Datos de ejemplo\nx &lt;- c(0.7, 1.2, 0.9, 0.6, 1.4, 1.8, 2.5)\n\n# Varianza poblacional\nvar_poblacional &lt;- mean((x - mean(x))^2)\n\n# Varianza simplificada\nvar_pobl_simplificada &lt;- mean(x^2) - mean(x)^2\n\n# Varianza muestral\nvar_muestral &lt;- var(x)\n\n# Varianza muestral de casen2022$ytrabajocor\nvar_casen_muestral &lt;- var(casen2022$ytrabajocor, na.rm = TRUE)\n\n# Mostrar resultados\nvar_poblacional\n## [1] 0.3885714\nvar_pobl_simplificada\n## [1] 0.3885714\nvar_muestral\n## [1] 0.4533333\nvar_casen_muestral\n## [1] 665844368478\n\n\n\nLa desviación estándar\nUna vez se tiene la varianza, la desviación estándar es muy fácil de calcular, pues es simplemente la raíz cuadrada de la varianza. La desviación estándar también es una medida de dispersión de los elementos del conjunto de observaciones con respecto a su media.\nDadas \\(n\\) observaciones, $x_1, , x_n $, la desviación estándar de este conjunto de datos, que denotaremos por \\(\\hat{\\sigma}\\), está dada por la raíz cuadrada de la varianza: \\[\n\\hat{\\sigma} = \\sqrt{\\hat{\\sigma}^2} = \\sqrt{\\frac{(x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 + \\ldots + (x_n - \\bar{x})^2}{n}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}.\n\\] Por ejemplo, si \\[\nx_1 = 0.7; \\, x_2 = 1.2; \\, x_3 = 0.9; \\, x_4 = 0.6; \\, x_5 = 1.4; \\, x_6 = 1.8; \\, x_7 = 2.5,\n\\] entonces, la desviación estándar de estos datos es: \\(\\hat{\\sigma} = 0.62\\). A diferencia de lo que ocurre con la varianza, la desviación estándar está medida en las mismas unidades que el conjunto de observaciones bajo análisis. Como veremos más adelante, esto hace que su interpretación sea más fácil y explica por qué se usa más que la varianza como medida de dispersión. Por lo tanto, la ventaja principal es esa. La desviación estándar está medida en las mismas unidades que las observaciones que estamos trabajando, y no así la varianza. En R es muy simple de hacer, con sd(). Al igual que con var(), sd() calcula por defecto al desviación estándar muestral.\n\n# Datos de ejemplo\nx &lt;- c(0.7, 1.2, 0.9, 0.6, 1.4, 1.8, 2.5)\n\n# Desviación estándar poblacional\nsd_poblacional &lt;- sqrt(mean((x - mean(x))^2))\n\n# Desviación estándar simplificada\nsd_simplificada &lt;- sqrt(mean(x^2) - mean(x)^2)\n\n# Desviación estándar muestral\nsd_muestral &lt;- sd(x)\n\n# Desviación estándar muestral de casen2022$ytrabajocor\nsd_casen_muestral &lt;- sd(casen2022$ytrabajocor, na.rm = TRUE)\n\n\n# Mostrar resultados\nsd_poblacional\n## [1] 0.623355\nsd_simplificada\n## [1] 0.623355\nsd_muestral\n## [1] 0.6733003\nsd_casen_muestral\n## [1] 815992.9\n\nConsiderando la desviación estándar es una medida de dispersión que describe la descripción de los datos en las mismas unidades que el conjunto de observaciones nos sirve para comparar ahora var_casen_muestral con sd_casen_muestral. En el primer caso, var_casen_muestral = 665844368478, significa simplemente que la varianza de los datos es de ese valor, esa es su varianza. En cambio, sd_casen_muestral = 815992.9 implica que la variación de los datos es de 815.992 CLP, pues la variable ytrabajocor mide pesos chilenos. En el caso de la varianza, nos dice cuán dispersos están los datos respecto a la media. En el caso de la desviación estándar, es también una medida de dispersión de los elementos del conjunto de observaciones con respecto a su media, pero que está en las unidades de la variable en cuestión, es decir, que hay una dispersión de los datos de 815.992 CLP respecto de la media (667.690 CLP, como habíamos visto). Por cierto, los valores elevados de dispersión son típicos en los ingresos, pues dada la desigualdad en estos, suelen tener una alta dispersión los datos de ingresos.\n\n\n1.2.1. Robustez en las medidas de dispersión\nAhora bien, ¿cuál es más robusta? La desviación estándar muestral y la varianza muestral no son medidas robustas de la dispersión de los datos. Aunque el álgebra es un poco más complejo, el problema es similar al que vimos con la media muestral.\nPor ejemplo, denotando por \\(\\hat{\\sigma}^2(e)\\) la varianza muestral cuando \\(x_1\\) se mide con error \\(e\\), se tiene que, usando el resultado de que la varianza muestral es igual a la media muestral de los cuadrados menos el cuadrado de la media muestral:\n\nProof. \\[\n\\begin{aligned}\n\\hat{\\sigma}^2(e) &= \\frac{1}{n} \\left[ (x_1 + e)^2 + \\sum_{i=2}^{n} x_i^2 \\right] - \\left( \\frac{1}{n} \\left[ (x_1 + e) + x_2 + \\ldots + x_n \\right] \\right)^2 \\\\\n&= \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 + \\frac{x_1 e}{n} + \\frac{e^2}{n} - \\left( \\bar{x} + \\frac{e}{n} \\right)^2 \\\\\n&= \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 + \\frac{x_1 e}{n} + \\frac{e^2}{n} - \\bar{x}^2 - 2 \\bar{x} \\frac{e}{n} - \\frac{e^2}{n^2} \\\\\n&= \\hat{\\sigma}^2(0) + \\frac{2}{n}(x_1 - \\bar{x})e + \\frac{n-1}{n^2}e^2.\n\\end{aligned}\n\\] De donde se concluye que \\[\n\\lim_{e \\to \\pm \\infty} \\hat{\\sigma}^2(e) = +\\infty,\n\\] y, por lo tanto, también que \\[\n\\lim_{e \\to \\pm \\infty} \\hat{\\sigma}(e) = +\\infty.\n\\]\n\nEn simple, las dos medidas de dispersión, la varianza y la desviación estándar, tienden a infinito positivo cuando el término de error tiende - o + infinito. Por lo tanto, ambas son medidas que no son robustas y, por lo tanto, sensibles a la presencia de valores extremos, de outliers.\n\n\nEl rango\nEl rango es la diferencia entre los valores más grande y más pequeño de un conjunto de observaciones de una variable. Al tomar el valor máximo y mínimo de los datos, permite obtener una idea de la dispersión de los datos. Así, cuanto mayor es el rango, aún más dispersos están los datos. Por ejemplo, si \\[\nx_1 = 0.7; \\quad x_2 = 1.2; \\quad x_3 = 0.9; \\quad x_4 = 0.6; \\quad x_5 = 1.4; \\quad x_6 = 1.8; \\quad x_7 = 2.5,\n\\] entonces, como ya vimos: \\[\ny_1 = 0.6, \\quad y_2 = 0.7, \\quad y_3 = 0.9, \\quad y_4 = 1.2, \\quad y_5 = 1.4, \\quad y_6 = 1.8, \\quad y_7 = 2.5.\n\\] Entonces el rango está dado por: \\[\ny_7 - y_1 = 2.5 - 0.6 = 1.9.\n\\]\nComo ya se puede intuir a estas alturas, el rango tampoco es una medida de dispersión robusta, pues basta un outlier en los valores mínimos o máximos para que el rango se distorsiones. Así, aunque el rango de un conjunto de datos es simple de calcular, su valor no es muy útil porque depende fuertemente de valores extremos y, por tanto, no es robusto a la presencia de outliers. Formalmente, si tomamos el ejemplo anterior, tendríamos que \\[\n\\begin{aligned}\ny_1 = 0.6, \\quad y_2 = 0.7, \\quad y_3 = 0.9, &\\quad y_4 = 1.2, \\quad y_5 = 1.4, \\quad y_6 = 1.8, \\quad y_7 = 2.5.\\\\\ny_7 - y_1 = &2.5 - 0.6 = 1.9.\n\\end{aligned}\n\\] Ahora bien, suponiendo nuevamente que la primera observación se midió con error \\(e\\), de modo que \\(x_1 = 0.7 + e\\), y denotando por \\(y_7(e)\\) y \\(y_1(e)\\) al valor máximo y mínimo cuando \\(x_1\\) se reemplaza por \\(x_1 + e\\), respectivamente, tenemos que: \\[\n\\lim_{e \\to -\\infty}(y_7(e) - y_1(e)) = \\infty, \\quad \\lim_{e \\to +\\infty}(y_7(e) - y_1(e)) = \\infty.\n\\] Por lo que valores aberrantes o outliers tienen efectos brutales en el rango. En R es muy fácil de hacer, se puede “manualmente” o con range() y diff(). Lo mostramos y luego pasamos a la primera medida de dispersión robusta: el rango intercuartil.\n\n\n# Para obtener el rango (max–min) usa diff(range(x, na.rm=TRUE))\nx &lt;- c(0.7, 1.2, 0.9, 0.6, 1.4, 1.8, 2.5)\n\n# Rango con max–min\nr1 &lt;- max(x) - min(x)\n\n# Rango con diff(range())\nr2 &lt;- diff(range(x, na.rm = TRUE)) # range(x, na.rm=TRUE) devuelve c(min, max), no la diferencia\n\n# En tu variable de casen2022\nr_casen_1 &lt;- max(casen2022$ytrabajocor, na.rm = TRUE) - \n             min(casen2022$ytrabajocor, na.rm = TRUE)\nr_casen_2 &lt;- diff(range(casen2022$ytrabajocor, na.rm = TRUE))\n\n# Mostrar resultados\nr1\n## [1] 1.9\nr2\n## [1] 1.9\nr_casen_1\n## [1] 50966585\nr_casen_2\n## [1] 50966585\n\n\n\nEl rango intercuartil\nEl primer cuartil de un conjunto de observaciones de una variable, que denotaremos por \\(q_1\\), es el valor para el cual el 25% de las observaciones son más pequeñas y el 75% son más grandes. En otras palabras, el primer cuartil es la mediana del 50% más pequeño de los datos.\nEl segundo cuartil, \\(q_2\\), es el mismo valor que aquel de la mediana (50% son más pequeños, 50% son más grandes).\nEl tercer cuartil, \\(q_3\\), es el valor para el cual el 25% de las observaciones son más grandes y el 75% son más pequeñas. En otras palabras, el tercer cuartil es la mediana del 50% más grande de los datos.\nEl rango intercuartil, que denotaremos , está dado por: \\(q_3 - q_1\\).\nNotar que el RIC es el rango del conjunto de observaciones con los cuartos más pequeño y más grande eliminados (podados), similar en espíritu a las observaciones que se consideran para calcular la media podada.Entonces, formalicemos su robustez.\nPor ejemplo, supongamos que las observaciones (ordenadas de menor a mayor) son: \\[\n43, 48, 50, 50, 52, 53, 56, 58, 59, 60, 62, 65, 66, 68, 70, 71, 74, 76, 78, 80,\n\\] entonces los cuartiles de este conjunto de observaciones son: \\[\nq_1 = 52.5, \\quad q_2 = 61, \\quad q_3 = 70.5\n\\] y el RIC viene dado por \\(q_3 - q_1 = 18\\)\nAhora bien, suponiendo que el valor 43 se midió con un error \\(e\\), de modo que su valor es \\(43 + e\\), y denotando por \\(RIC(e)\\) el valor del rango intercuartil cuando el valor 43 se reemplaza por \\(43 + e\\), tenemos que: \\[\nRIC(e) \\in [16,18]\n\\] De modo que el RIC es una medida de dispersión de los datos robusta a la presencia de outliers. Para calcular cuartiles en R se usa quantile(). Lo importante es especificar adecuadamente el cuantil de interés (50%, 75%, etc.) A su vez, entre los paquete de R base, específicamente en stats, se tiene IQR() nos permite calcular rangos intercuartiles.\n\n# Datos de ejemplo\nx &lt;- c(43, 48, 50, 50, 52, 53, 56, 58, 59, 60, 62, 65, 66, 68, 70, 71, 74, 76, 78, 80)\n\n# Calcular cuartiles\nq1   &lt;- quantile(x, 0.25)\nq2   &lt;- median(x)\nq3   &lt;- quantile(x, 0.75)\n\n# Rango intercuartil\nric  &lt;- q3 - q1\n\n# Para casen2022$ytrabajocor\nx_casen    &lt;- casen2022$ytrabajocor\nq1_casen   &lt;- quantile(x_casen, 0.25, na.rm = TRUE)\nq2_casen   &lt;- median(x_casen, na.rm = TRUE)\nq3_casen   &lt;- quantile(x_casen, 0.75, na.rm = TRUE)\nric_casen  &lt;- q3_casen - q1_casen\n\n# Alternativa con función base\nric_casen2 &lt;- IQR(x_casen, na.rm = TRUE)\n\n# Mostrar resultados\nq1; q2; q3; ric\n##   25% \n## 52.75\n## [1] 61\n##   75% \n## 70.25\n##  75% \n## 17.5\nq1_casen; q2_casen; q3_casen; ric_casen; ric_casen2\n##    25% \n## 337500\n## [1] 480000\n##    75% \n## 763333\n##    75% \n## 425833\n## [1] 425833"
  },
  {
    "objectID": "lectures/02-statistics.html#medidas-de-posición",
    "href": "lectures/02-statistics.html#medidas-de-posición",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "1.3. Medidas de posición",
    "text": "1.3. Medidas de posición\n\nLos percentiles\nEl percentil de un conjunto de observaciones es una medida de posición que indica, una vez ordenados los datos de menor a mayor, el valor por debajo del cual se encuentra un porcentaje dado de observaciones. En general, el percentil \\(k\\)-ésimo, que denotaremos por \\(p_k\\), es un valor para el cual un \\(k\\%\\) por ciento de las observaciones son menores que ella.\nLa definición anterior es un tanto vaga: ¿menor o igual?, ¿qué pasa si no hay valores que cumplan?, ¿qué pasa si hay varios? Se pueden adoptar varios criterios, todos los cuales arrojan resultados parecidos cuando se aplican con conjuntos grandes de observaciones.\nNotar que, en general, \\(p_{25} = q_1\\), \\(p_{50}\\) es la mediana y \\(p_{75} = q_3\\). Por ejemplo, si las observaciones (ordenadas de menor a mayor) son: \\[\n43, 48, 50, 50, 52, 53, 56, 58, 59, 60, 62, 65, 66, 68, 70, 71, 74, 76, 78, 80,\n\\] y exigimos que los percentiles sean observaciones y la definición es con “menor o igual”, tenemos: \\[\np_{10} = 48, \\quad p_{25} = 52, \\quad p_{50} = 60, \\quad p_{75} = 68, \\quad p_{100} = 76.\n\\] En R no hay una distinción entre cuantiles y percentiles a nivel de comando. Ahora bien, para obtener los percentiles en la posición que nos interesan podemos hacer lo siguiente:\n\n# Datos de ejemplo\nx &lt;- c(43, 48, 50, 50, 52, 53, 56, 58, 59, 60, 62, 65, 66, 68, 70, 71, 74, 76, 78, 80)\n\n# Definimos percentiles deseados\np &lt;- c(0.10, 0.25, 0.50, 0.75, 1.00)\n\n# Calculamos percentiles como observaciones (type = 1)\npercentiles &lt;- quantile(x, probs = p, na.rm = TRUE, type = 1)\np10   &lt;- percentiles[1]\np25   &lt;- percentiles[2]\np50   &lt;- percentiles[3]\np75   &lt;- percentiles[4]\np100  &lt;- percentiles[5]\n\n# Para casen2022$ytrabajocor\nx_casen &lt;- casen2022$ytrabajocor\npercentiles_casen &lt;- quantile(x_casen, probs = p, na.rm = TRUE, type = 1)\np10_casen  &lt;- percentiles_casen[1]\np25_casen  &lt;- percentiles_casen[2]\np50_casen  &lt;- percentiles_casen[3]\np75_casen  &lt;- percentiles_casen[4]\np100_casen &lt;- percentiles_casen[5]\n\n# Mostrar resultados\npercentiles\n##  10%  25%  50%  75% 100% \n##   48   52   60   70   80\npercentiles_casen\n##      10%      25%      50%      75%     100% \n##   150000   337500   480000   763333 50966668"
  },
  {
    "objectID": "lectures/02-statistics.html#transformaciones-lineales-de-los-datos-descriptivos",
    "href": "lectures/02-statistics.html#transformaciones-lineales-de-los-datos-descriptivos",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "1.4. Transformaciones lineales de los datos descriptivos",
    "text": "1.4. Transformaciones lineales de los datos descriptivos\nUna transformación lineal de un conjunto de datos es aquella en la que cada observación se multiplica por una constante y se le suma otra constante. Concretamente, dadas \\(n\\) observaciones, \\(x_1, x_2, \\dots, x_n\\), una transformación lineal de ellas está dada por \\[\nax_1 + b, ax_2 + b, \\dots, ax_n + b,\n\\] con \\(a\\) y \\(b\\) constantes cualesquiera.\nDe tal modo, las transformaciones lineales permiten transformar los datos de las estadísticas descriptivas transformadas linealmente con las estadísticas descriptivas originales. Un ejemplo de esto, podría ser la transformación de los datos de precios a los mismos precios en UF de algún día dado. Con ello, podríamos ver, e.g., el ingreso en pesos y queremos verlo en UF. De tal modo, podríamos comprar el ingreso original en pesos con el ingreso en UF sin distorsionar la proporción mediante esta multiplicación con constantes (ponderar en la misma cantidad básicamente). En nuestro ejemplo, de CLP \\(\\to\\) UF tendríamos que la constante \\(a\\) sería el valor de la UF y la constante \\(b\\) simplemente sería 0.\nLo que se sigue de esto, es determinar la relación entre las medidas que hemos visto hasta hora, en sus estadísticas descriptivas originales, y compararlas con sus respectivas transformaciones lineales.\n\nSi denotamos por \\(\\bar{x}\\) a la media de los valores de las observaciones originales y por \\(\\bar{x}_t\\) a la media de los datos después de aplicarles la transformación lineal, tenemos que \\[\n\\bar{x}_t = \\frac{ax_1 + b + ax_2 + b + \\dots + ax_n + b}{n} = a\\bar{x} + b.\n\\]\nSi denotamos por \\(\\hat{\\sigma}^2\\) a la varianza de los valores de las observaciones originales y por \\(\\hat{\\sigma}^2_t\\) a la varianza de los datos después de aplicarles la transformación lineal, tenemos que \\[\n\\hat{\\sigma}^2_t = \\frac{(ax_1 + b - \\bar{x}_t)^2 + (ax_2 + b - \\bar{x}_t)^2 + \\dots + (ax_n + b - \\bar{x}_t)^2}{n} = a^2 \\hat{\\sigma}^2.\n\\]\nDe modo que para el caso de la desviación estándar, tenemos que: \\[\n\\hat{\\sigma}_t = |a| \\hat{\\sigma}.\n\\]\nSi denotamos por \\(\\tilde{\\tilde{x}}\\) a la moda de los valores originales y por \\(\\tilde{\\tilde{x}}_t\\) a la moda de los datos transformados, tenemos que: \\[\n\\tilde{\\tilde{x}}_t = a \\tilde{\\tilde{x}} + b.\n\\]\nSi denotamos por \\(y_1, y_2, \\dots, y_n\\) a los estadísticos de orden de los valores originales de los datos, tenemos que los estadísticos de orden de los datos transformados linealmente están dados por \\(a y_1 + b, a y_2 + b, \\dots, a y_n + b\\) si \\(a \\geq 0\\), o por \\(a y_n + b, a y_{n-1} + b, \\dots, a y_1 + b\\) si \\(a &lt; 0\\).\nSi denotamos por \\(\\bar{x}\\) a la mediana de las observaciones originales y por \\(\\tilde{x}_t\\) a la mediana de los datos después de aplicarles la transformación lineal, tenemos que: \\[\n\\tilde{x}_t = a \\tilde{x} + b.\n\\]\nEl rango de los datos transformados está dado por \\(\\left| a \\right| (y_n - y_1)\\).\nEl rango intercuartil de los datos después de aplicarles la transformación lineal está dado por \\(\\left| a \\right| (q_3 - q_1)\\), donde \\(q_3\\) y \\(q_1\\) son los cuartiles 3 y 1 de los datos originales, respectivamente."
  },
  {
    "objectID": "lectures/02-statistics.html#tipos-de-gráficos",
    "href": "lectures/02-statistics.html#tipos-de-gráficos",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "Tipos de gráficos",
    "text": "Tipos de gráficos\nLa elección de la **visualización de datos* depende de varios elementos, pero principalmente de\n\nQué tipo de variable se quiere investigar/presentar.\nLo que esperamos mostrar.\n\nHay gráficos que son más adecuados para presentar ciertos tipos de datos, al igual que hay gráficos que no sirven para visualizar algunas variables según su naturaleza. Al mismo tiempo, dependerá de dónde y a quién se quiera presentar los gráficos. Dado que nuestra intención es comunicar información de los datos de manera gráfica, es importante tener en consideración si los gráficos se expondran en un artículo científico, una presentación en un congreso, en una afiche divulgativo, para una clase, etc. No obstante, aquí dejo una pauta general de qué gráficos usar según los tipos de variables y cuántas variables queramos comunicar.\n\nLos gráficos univariados: muestran la distribución básica de una variable. Para ello utilizamos\n\n\nGráficos de barras,\nHistogramas y\nGráficos de caja (boxplots)\n\n\nLos gráficos bivariados: muestran cómo dos variables están relacionadas entre sí. Cuál usar depende del tipo de variables bajo análisis:\n\n\nDos variables categóricas: gráficos de barras.\nUna categórica y una cuantitativa: gráficos de cajas.\nDos variables cuantitativas: gráficos de dispersión de puntos.\n\nVeamos cómo graficar estos tipos de gráficos en R usando ggplot2 y datos reales de la CASEN 2022."
  },
  {
    "objectID": "lectures/02-statistics.html#gráficos-univariados",
    "href": "lectures/02-statistics.html#gráficos-univariados",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "Gráficos univariados",
    "text": "Gráficos univariados\n\nGráficos de barras\n\n# Vemos datos de nuestra variable de interés\n\nsjmisc::frq(casen2022$sexo) # ups! no funciona en RMarkdown\n## Sexo (x) &lt;numeric&gt; \n## # total N=202231 valid N=202231 mean=1.53 sd=0.50\n## \n## Value |     Label |      N | Raw % | Valid % | Cum. %\n## -----------------------------------------------------\n##     1 | 1. Hombre |  95656 | 47.30 |   47.30 |  47.30\n##     2 |  2. Mujer | 106575 | 52.70 |   52.70 | 100.00\n##  &lt;NA&gt; |      &lt;NA&gt; |      0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n# Gráfico de barras de la variable sexo\nggplot(casen2022, aes(x = factor(sexo, labels = c(\"Hombre\", \"Mujer\")))) +\n  geom_bar() +\n  labs(\n    x = \"Sexo\",\n    y = \"Frecuencia\",\n    title = \"Distribución de la variable Sexo\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSi queremos agregarle más colores3, cambiar el tamaño de las letras, ponerle caption, etc., solo hay que usar comandos de ggplot2 que sirvan para ello y seguir su gramática “en capas” adecuadamente\n\n# Gráfico de barras de la variable sexo más bonito\nggplot(casen2022, aes(x = factor(sexo, labels = c(\"Hombre\", \"Mujer\")), \n                      fill = factor(sexo))) +\n  geom_bar(width = 0.7, color = \"black\") +\n  scale_fill_manual(values = c(\"#8F8F8F\", \"#8B0000\")) +\n  labs(\n    x = \"Sexo\",\n    y = \"Frecuencia\",\n    title = \"Distribución de Sexo en CASEN 2022\", \n    caption = \"Elaboración propia a partir de Encuesta CASEN 2022\"\n  ) +\n  theme_minimal(base_family = \"Fira Sans\", base_size = 12) +\n  theme(\n    plot.title     = element_text(size = 18, face = \"bold\", hjust = 0.5),\n    axis.title     = element_text(size = 14),\n    axis.text      = element_text(size = 12),\n    panel.grid.minor = element_blank(),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\nMás allá de “enchular” el gráfico, lo importante es que el gráfico es más fácil de comprender rápidamente que una tabla de frecuencias, como vimos con frq(). Y cuando se agrega más categorías, facilita aún más. Por ejemplo, veamos Clasificación Internacional Normalizada de Educación (CINE-F). Para ello usaremos cinef13_area de la CASEN 2022, pero excluiremos las categorías sin datos\n\n#Exploramos nuestra variable de interés\n\nfrq(casen2022$cinef13_area)\n## Clasificación Internacional Normalizada de Educación (CINE-F). Campo amplio (x) &lt;numeric&gt; \n## # total N=202231 valid N=49628 mean=4.13 sd=6.48\n## \n## Value |                                                Label |      N | Raw %\n## -----------------------------------------------------------------------------\n##     1 |                                    Salud y Bienestar |   9383 |  4.64\n##     2 |                 Ingeniería, Industria y Construcción |  10833 |  5.36\n##     3 |                                            Educación |   7819 |  3.87\n##     4 |                                            Servicios |   2806 |  1.39\n##     5 |                 Administración de Empresas y Derecho |  10933 |  5.41\n##     6 |          Ciencias Sociales, Periodismo e Información |   1917 |  0.95\n##     7 |        Ciencias naturales, matemáticas y estadística |    654 |  0.32\n##     8 |       Agricultura, Silvicultura, Pesca y Veterinaria |   1080 |  0.53\n##     9 | Tecnología de la Información y la Comunicación (TIC) |   1843 |  0.91\n##    10 |                                  Artes y Humanidades |   2107 |  1.04\n##    11 |                        Doctorado en Ciencias Básicas |      0 |  0.00\n##    88 |                                             Sin dato |    253 |  0.13\n##  &lt;NA&gt; |                                                 &lt;NA&gt; | 152603 | 75.46\n## \n## Value | Valid % | Cum. %\n## ------------------------\n##     1 |   18.91 |  18.91\n##     2 |   21.83 |  40.74\n##     3 |   15.76 |  56.49\n##     4 |    5.65 |  62.14\n##     5 |   22.03 |  84.17\n##     6 |    3.86 |  88.04\n##     7 |    1.32 |  89.35\n##     8 |    2.18 |  91.53\n##     9 |    3.71 |  95.24\n##    10 |    4.25 |  99.49\n##    11 |    0.00 |  99.49\n##    88 |    0.51 | 100.00\n##  &lt;NA&gt; |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n# Como vemos Doctorado en Ciencias Básicas no tiene casos\n# y Sin dato no nos interesa. Tampoco NA\n# Usamos dplyr\n\narea_labels &lt;- c(\n  \"Salud y Bienestar\",\n  \"Ingeniería, Industria y Construcción\",\n  \"Educación\",\n  \"Servicios\",\n  \"Administración de Empresas y Derecho\",\n  \"Ciencias Sociales, Periodismo e Información\",\n  \"Ciencias naturales, matemáticas y estadística\",\n  \"Agricultura, Silvicultura, Pesca y Veterinaria\",\n  \"Tecnología de la Información y la Comunicación (TIC)\",\n  \"Artes y Humanidades\"\n)\n\ndf_area &lt;- casen2022 |&gt; \n  filter(!cinef13_area %in% c(11, 88, NA)) |&gt; \n  count(cinef13_area) |&gt; \n  mutate(area = factor(cinef13_area, levels = 1:10, labels = area_labels))\n\nggplot(df_area, aes(x = area, y = n, fill = area)) +\n  geom_col(color = \"white\", width = 0.8) +\n  labs(\n    x = \"Área CINE-F\",\n    y = \"Frecuencia\",\n    title = \"Distribución de Áreas CINE-F (códigos 1–10)\"\n  ) +\n  theme_minimal(base_family = \"Fira Sans\", base_size = 12) +\n  theme(\n    axis.text.x    = element_text(angle = 45, hjust = 1),\n    plot.title     = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\nEsto es mucho más amable que una tabla en la que comparamos números, porque permite una comparación visual entre categorías. Entonces, la ganancia del gráfico de barra se da en la medida que haya más categorías a analizar.\n\n\nHistogramas (y kernels)\nEste tipo de visualizaciones es recomendable para resumir gráficamente la información de una variable cuantitativa. Un histograma muestra la distribución empírica de las observaciones de un variable cuantitativa. Muchas veces, por ejemplo, se usa para observar si una variable sigue o no una distribución normal.\nEn un histograma, la altura de cada barra representa cuántas observaciones en el conjunto de datos caen dentro de un cierto rango (intervalo) de la variable cuantitativa bajo análisis. Un elemento fundamental al momento de hacer un histograma es la definición del número de rangos (intervalos) de la variable cuantitativa que se considerarán para agrupar los datos. Si no se elige el número correcto (ancho adecuado) para dichos intervalos, se corre el riesgo de que el histograma no refleje las características esenciales del conjunto de datos, llevándonos a malinterpretar cómo se distribuyen las observaciones.\nVeamos la distribución de los ingresos del trabajo en un histograma:\n\nggplot(casen2022, aes(x = ytrabajocor)) +\n  geom_histogram(bins = 30, fill = \"#4E79A7\", color = \"white\", na.rm = TRUE) +\n  scale_x_continuous(labels = scales::comma) + # para sacar notación científica\n  labs(\n    x = \"Ingreso de trabajo corregido\",\n    y = \"Frecuencia\",\n    title = \"Histograma de ytrabajocor\"\n  ) +\n  theme_minimal(base_family = \"Fira Sans\", base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.title = element_text(size = 14),\n    axis.text  = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\nComo se ve, la desigualdad de los ingresos nuevamente ataca. Al haber pocas personas con ingresos muy altos, y muchas personas con ingresos bajos, ni se alcanzan a ver las personas de ingresos altos. Ciertamente, esta forma de elefante dentro de una serpiente hacia un lado del gráfico es habitual verla en gráficos de distribución en los ingresos. Podemos para ver cómo varía esto, por ejemplo, usar percentiles, deciles, quintiles, etc., para filtar casos y observar la distribución empírica de los ingresos, e.g., para el 90% de los ingresos (excluyendo al 10% más alto):\n\ncasen2022 |&gt; \n  filter(!is.na(ytrabajocor), dau &lt; 10) |&gt; \n  ggplot(aes(x = ytrabajocor)) +\n    geom_histogram(bins = 30, fill = \"#4E79A7\", color = \"white\") +\n    scale_x_continuous(labels = comma) +\n    labs(\n      x = \"Ingreso de trabajo corregido\",\n      y = \"Frecuencia\",\n      title = \"Histograma de ytrabajocor (deciles 1–9)\"\n    ) +\n    theme_minimal(base_family = \"Fira Sans\", base_size = 12) +\n    theme(\n      plot.title     = element_text(face = \"bold\", size = 16, hjust = 0.5),\n      axis.title     = element_text(size = 14),\n      axis.text      = element_text(size = 12)\n    )\n\n\n\n\n\n\n\n\n¿Y si queremos, por ejemplo, para el 80%? Solo basta modificar dau &lt; x en el código, pues dau es la variable del Decil autónomo nacional dentro de la CASEN 2022.\n\ncasen2022 |&gt; \n  filter(!is.na(ytrabajocor), dau &lt; 9) |&gt; \n  ggplot(aes(x = ytrabajocor)) +\n    geom_histogram(bins = 30, fill = \"#4E79A7\", color = \"white\") +\n    scale_x_continuous(labels = comma) +\n    labs(\n      x = \"Ingreso de trabajo corregido\",\n      y = \"Frecuencia\",\n      title = \"Histograma de ytrabajocor (deciles 1–8)\"\n    ) +\n    theme_minimal(base_family = \"Fira Sans\", base_size = 12) +\n    theme(\n      plot.title     = element_text(face = \"bold\", size = 16, hjust = 0.5),\n      axis.title     = element_text(size = 14),\n      axis.text      = element_text(size = 12)\n    )\n\n\n\n\n\n\n\n\nAlgo que también se puede hacer, similar a los histogramas, es observar esto con kernels, que son como histogramas pero con densidad y continuos (no en barras). Esto se hace con geom_density(). Además, esto nos facilita (para visualizar la distribución empírica) ver nuestra variable de interés agrupada según otra variable que nos interese. Por ejemplo, podríamso ver el ingreso del trabajo según sexo.\n\n\ncasen2022 |&gt; \n  filter(!is.na(ytrabajocor), dau &lt; 10) |&gt; \n  mutate(sexo = factor(sexo, levels = c(1, 2), labels = c(\"Hombre\", \"Mujer\"))) |&gt; \n  ggplot(aes(x = ytrabajocor, fill = sexo)) +\n    geom_density(alpha = 0.7,adjust =2, color = \"black\") +\n    scale_x_continuous(labels = comma) +\n    labs(\n      title = \"Distribución de ingreso de trabajo corregido por sexo\",\n      x     = \"Ingreso de trabajo corregido\",\n      y     = \"Densidad\",\n      fill  = \"Sexo\"\n    ) +\n    theme_minimal(base_family = \"serif\", base_size = 12) +\n    theme(\n      plot.title     = element_text(face = \"bold\", size = 16, hjust = 0.5),\n      legend.position = \"bottom\",\n      axis.text       = element_text(size = 12)\n    )\n\n\n\n\n\n\n\n\nOtra cosa que puede resultarnos util es ver donde está mediana en el gráfico. Aprovechamos de mostrar como se verían los gráficos ya no superpuestos, sino al lado:\n\n\ndf &lt;- casen2022 |&gt;\n  filter(!is.na(ytrabajocor), dau &lt; 10) |&gt;\n  mutate(sexo = factor(sexo, levels = c(1, 2), labels = c(\"Hombre\", \"Mujer\")))\n\n# Extraemos medianas\nmedianas &lt;- df |&gt;\n  group_by(sexo) |&gt;\n  summarise(mediana = median(ytrabajocor))\n\n# Graficamos \nggplot(df, aes(x = ytrabajocor, fill = sexo, color = sexo)) +\n  geom_density(alpha = 0.3, adjust = 1, size = 1) +\n  geom_vline(data = medianas, aes(xintercept = mediana, color = sexo),\n             linetype = \"dashed\", size = 1) +\n  facet_wrap(~ sexo) +\n  scale_fill_manual(values = c(\"Hombre\" = \"#C51517\", \"Mujer\" = \"#BAB3EB\")) +\n  scale_color_manual(values = c(\"Hombre\" = \"#9C0824\", \"Mujer\" = \"#312271\")) +\n  scale_x_continuous(labels = comma) +\n  labs(\n    title = \"Distribución de ingreso de trabajo corregido por sexo\",\n    x     = \"Ingreso de trabajo corregido\",\n    y     = \"\",\n    fill  = \"Sexo\",\n    color = \"Sexo\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 12) +\n  theme(\n    plot.title     = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    legend.position = \"bottom\",\n    axis.text       = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n\nGráfico de cajas (boxplots)\nCuando son gráficos univariados este tipo de visualizaciones tipo boxplot es recomendable para resumir gráficamente la información de una variable cuantitativa (continua o discreta). Un grafico de caja o boxplot muestra las características de la distribución de las observaciones de una variable cuantitativa: “mínimo”, primer cuartil (\\(q_1\\)), mediana, tercer cuartil (\\(q_3\\)), “máximo”. También etiqueta posibles valores atípicos como puntos separados en el gráfico. En un gráfico de caja, pues, se tiene que:\n\nEl “mínimo” corresponde a \\(q_1 - 1,5RIC\\) (no es el valor más pequeño entre las observaciones).\nEl “máximo” corresponde a \\(q_3 + 1,5RIC\\) (no es el valor más grande entre las observaciones).\n\nEn esta herramienta gráfica, las observaciones etiquetadas como posibles valores atípicos (outliers) son aquellas que se ubican fuera del intervalo dado por: \\[\n[q_1 - 1,5RIC, q_3 + 1,5RIC]\n\\]\nVeamos como hacer esto con ggplot2. Usaremos otra variable cuantitativa, y ya no ingresos del trabajo porque, dada su dispersión se verá así:\n\n# Para ingresos del trabajo\n\n\nggplot(casen2022, aes(y = ytrabajocor)) +\n  geom_boxplot(fill = \"#4E79A7\", color = \"black\", outlier.color = \"red\", na.rm = TRUE) +\n  scale_y_continuous(labels = comma) +\n  labs(\n    y     = \"Ingreso de trabajo corregido\",\n    title = \"Boxplot de ingreso de trabajo corregido\"\n  ) +\n  theme_minimal(base_family = \"Fira Sans\", base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\nProbemos con otra variable que sea interesante, por ejemplo con la varriable tot_per_h que registra el “Total de personas en el hogar” de los hogares encuestados por la CASEN\n\n\n# Para Total de personas en el hogar\n\ncasen2022 |&gt;\n  filter(!is.na(tot_per_h)) |&gt;\n  ggplot(aes(y = tot_per_h)) +\n    geom_boxplot(fill = \"#CAE1FF\", color = \"black\", outlier.color = \"red\") +\n    scale_y_continuous(breaks = 1:13, limits = c(1, 13)) +\n    labs(\n      y     = \"Total de personas en el hogar\",\n      title = \"Boxplot de total de personas en el hogar\"\n    ) +\n    theme_minimal(base_family = \"Fira Sans\", base_size = 12) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n      axis.text  = element_text(size = 12)\n    )\n\n\n\n\n\n\n\n\nLa intepretación del boxplot, entonces, debe incluir lo siguiente:\n\nLa mediana está en 3 miembros, lo que indica que la mitad de los hogares tiene 3 o menos personas y la otra mitad 3 o más.\nEl primer cuartil (\\(Q1\\)) se sitúa en 2 personas y el tercer cuartil (\\(Q3\\)) en 4 personas. Esto nos dice que el 50% central de los hogares (entre \\(Q1\\) y \\(Q3\\)) agrupa tamaños de 2 a 4 miembros.\nEl rango intercuartílico (\\(RIC = Q3 – Q1\\)) es 2 personas, reflejando una variabilidad moderada en el tamaño típico de los hogares.\nLos “bigotes” se extienden desde 1 hasta 7 miembros aproximadamente, marcando los límites dentro de \\(1,5·RIC\\).\nMás allá de 7 personas aparecen puntos aislados (outliers), correspondientes a hogares muy numerosos (8 a 13 personas), que representan casos excepcionales en la distribución.\n\nEn conjunto, el gráfico revela que la mayoría de los hogares chilenos encuestados están compuestos por entre 2 y 4 personas, con un hogar típico de 3 miembros, y que los tamaños extremos (hogares muy grandes) son poco frecuentes."
  },
  {
    "objectID": "lectures/02-statistics.html#gráficos-bivariados",
    "href": "lectures/02-statistics.html#gráficos-bivariados",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "Gráficos bivariados",
    "text": "Gráficos bivariados\n\nGráficos de barras de dos variables\nEsta visualización es recomendable para resumir gráficamente la información sobre la relación entre dos variables categóricas. Específicamente, este gráfico destaca cómo una variable categórica puede diferir entre las categorías de otra variable categórica. Por ejemplo, podríamos mostrar cómo la matrícula en la educación superior difiere por género.\nPara ello, tomaré la variable e6a_asiste que responde a la pregunta ¿Cuál es el nivel educacional al que asiste?, dado que supone que asiste, al momento de ser encuestado/a, a un establecimiento educacional o no. En este caso, solo tomaremos la categoría 13 que es “13. Profesional (Carreras 4 o más años)”. Aunque no es una variable sobre la matricula como tal, es un buen proxy4\n\n\n# Creamos un df ad hoc\ndf_asiste_prof &lt;- casen2022 |&gt;\n  filter(e6a_asiste == 13) |&gt;\n  count(sexo) |&gt;\n  mutate(sexo = factor(sexo, levels = c(1, 2), labels = c(\"Hombre\", \"Mujer\")))\n\n# Ploteamos\nggplot(df_asiste_prof, aes(x = sexo, y = n, fill = sexo)) +\n  geom_col(width = 0.6, color = \"white\") +\n  scale_y_continuous(labels = comma) +\n  labs(\n    x     = \"Sexo\",\n    y     = \"Número de estudiantes en carreras profesionales (4+ años)\",\n    title = \"Asistencia a la universidad (Profesional) por sexo\"\n  ) +\n  theme_minimal(base_family = \"Fira Sans\", base_size = 12) +\n  theme(\n    plot.title     = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text      = element_text(size = 12),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\nBoxplots bivariados\nEste tipo de visualización es recomendable para resumir gráficamente la información de la relación entre una variable categórica y una variable cuantitativa. Concretamente, se visualizan los gráficos de cajas para una variable cuantitativa, separados para cada valor posible de una variable categórica. Por lo tanto, permite ver cómo la variable cuantitativa se distribuye dentro de cada valor de una variable categórica.\nPara ello, podríamos ver el ingreso del trabajo (variable continua) por sexo (categórica). Pero, como ya vimos, los boxplots con variables con tanta dispersión, se ven feos y comunican mal. Ahora bien, algo que es recomendable para comprimir la escala y reducir la asimetría entre los valores para variables con mucha dispersión es aplicarle un logaritmo a la variable de interés. De hecho, esto es algo que se hace bastante con el ingreso. No me interesa profundizar en esto ahora, porque es algo que trateremos cuando lleguemos a regresiones. No obstante, si es de interés, en este punto, el capítulo 2 de @masteringmetrics ofrece una explicación didáctica y profunda. Además, en el apéndice de dicho capítulo, específicamente en el apartado “Building Models with Logs” o “Modelos logarítmicos” –en la traducción del libro–, se profundiza específicamente en la utilidad de aplicar logaritmos a variables como el ingreso.\nVeamos cómo queda el gráfico, que además ggplot2 tiene funciones para realizar transformaciones logarítmicas de las varaibles sin hacer recodificación previa. Primero lo hago con codificación previa (“manual”) y luego en ggplot mismo.\n\ncasen2022 |&gt;\n  filter(!is.na(ytrabajocor)) |&gt;\n  mutate(\n    sexo        = factor(sexo, levels = c(1, 2), labels = c(\"Hombre\", \"Mujer\")),\n    log_ingreso = log(ytrabajocor) # transformación manual\n  ) |&gt;\n  ggplot(aes(x = sexo, y = log_ingreso, fill = sexo)) +\n    geom_boxplot(color = \"black\", outlier.color = \"red\", alpha = 0.7) +\n    scale_y_continuous(\n      name   = \"Log(Ingreso de trabajo corregido)\",\n      labels = comma\n    ) +\n    labs(\n      x     = \"Sexo\",\n      title = \"Boxplot de ingreso de trabajo corregido (log) por sexo\"\n    ) +\n    theme_minimal(base_family = \"serif\", base_size = 14) +\n    theme(\n      plot.title     = element_text(face = \"bold\", size = 16, hjust = 0.5),\n      axis.text      = element_text(size = 12),\n      legend.position = \"none\"\n    )\n\n\n\n\n\n\n\n\n## Transformación logaritmica dentro de ggplot2\n\ncasen2022 |&gt;\n  filter(!is.na(ytrabajocor)) |&gt;\n  mutate(sexo = factor(sexo, levels = c(1, 2), labels = c(\"Hombre\", \"Mujer\"))) |&gt;\n  ggplot(aes(x = sexo, y = ytrabajocor, fill = sexo)) +\n    geom_boxplot(color = \"black\", outlier.color = \"red\", alpha = 0.7) +\n    scale_y_log10(labels = comma) +\n    labs(\n      x     = \"Sexo\",\n      y     = \"Ingreso de trabajo corregido (escala log)\",\n      title = \"Boxplot de ingreso de trabajo corregido por sexo (escala log)\"\n    ) +\n    theme_minimal(base_family = \"serif\", base_size = 14) +\n    theme(\n      plot.title     = element_text(face = \"bold\", size = 16, hjust = 0.5),\n      axis.text      = element_text(size = 12),\n      legend.position = \"none\"\n    )\n\n\n\n\n\n\n\n\nComo se puede observar, la comparación de ambos boxplots deja claro que, al final, la forma de la distribución (posición de cuartiles, mediana y “bigotes”) es exactamente la misma: la transformación logarítmica sólo reescala los datos de manera monotónica, sin alterar su orden ni la detección de outliers. De modo general, sobre los gráficos podemos decir:\n\nLa mediana del ingreso de los hombres está algo por encima de la de las mujeres, lo cual se ve en ambos casos.\nEl rango intercuartílico (caja) es ligeramente más amplio en los hombres, indicando mayor dispersión en el 50 % central.\nAparecen outliers en ambos sexos, sobre todo hacia los ingresos muy bajos y muy altos, que quedan marcados como puntos fuera de los “bigotes”.\n\nRespecto a las diferencias gráficas según transformación logarítmica “manual” o en el código de ggplot2:\n\nBoxplot con transformación manual (log_ingreso):\n\n\nEn el eje Y leemos directamente la escala de log(ingreso). Por ejemplo, una mediana alrededor de 12,4 en hombres equivale a un ingreso de $e^{12,4} ,4 ^5 $, es decir, 240.000 pesos\nEs útil si nuestro interés está en trabajar explícitamente con valores logarítmicos (p. ej. para comparar diferencias porcentuales, como veremos después).\n\n\nBoxplot con ggplot2 (scale_y_log10()):\n\n\nAquí el eje Y muestra los valores de ingreso en pesos, pero “espaciados” según su logaritmo. La mediana se lee directamente en unidades monetarias (p. ej. 200.00 vs 180.000), lo que facilita la interpretación sin cálculo inverso.\nConserva el lenguaje natural de las unidades en el gráfico (no aparecen logaritmos ni ejes en valores crudos de log), pero controla la asimetría y comprime los outliers en una visual más manejable.\n\nEn resumen, ambas aproximaciones equivalen en términos estadísticos. La elección depende de si quieres presentar valores ya en escala log (transformación manual) o prefieres mantener el eje en la unidad original (pesos) pero con la ventaja visual de una escala logarítmica que ofrece el paquete (scale_y_log10()).\n\n\nGráficos de dispresión de puntos (scatter plots)\nEste tipo de gráficos es recomendable para resumir gráficamente la información de la asociación de dos variables cuantitativas. Un gráfico de dispersión muestra cada observación como un punto en un sistema de coordenadas para dos variables cuantitativas. Por ejemplo, podríamos graficar la relación entre el ingreso del trabajo y los años de escolaridad.\nAhora bien, un problema común que surge en los gráficos de dispersión es cuando los datos de muchas observaciones se intentan presentar en sólo una figura. En nuestro ejemplo, contamos con la información de más de 200.000 encuestados. En estos casos, es recomendable procesar antes los datos. Se pueden hacer varias cosas. Podrían crearse rangos de ingresos, por ejemplo, o tomar quintiles, deciles, etc., de ingresos. O bien, también podríamos aplicar una transformación logarítmica en los datos como hicimos anteriormente.\nPodemos hacer ambas, pero la verdad es que dependerá mucho de la variable cuál es mejor. Por ejemplo, si estuvieramos viendo puntajes PSU de Matemáticas y a su asociación al Ranking, sería útil hacer grupos. Pero para ingresos no funciona mucho esto. En las clases Estadística I de Engel y Díaz de la FEN se pasa el primer ejemplo. Se presentan primero sin agrupar y luego agrupando:\n\n\nAhora bien, veamos cómo quedaría con ingreso esto. Primero tomaremos los déciles, registrados por la casen en dau (Decil autónomo nacional) que se calculan tomando todos los ingresos del hogar (o sea, ya no ingresos del trabajo de los encuestados encuestado) y se dividen, siguiendo la lógica explicada en las medidas de posición, en 10 grupos. En este caso, el grupo 1 es el grupo de ingresos más bajos (el 10% más pobre) y el 10 es el de ingresos más altos (el 10% más rico). Luego, para ver si es un problema de que sean pocos grupos, lo haremos para percentiles (100 grupos). Para la otra variable, en ambos casos, usaremos esc que mide los años de escolaridad (solo personas de 15 años en adelante) como variable cuantitativa discreta.\n\n# 1) Scatter: escolaridad vs decil de ingreso del hogar\ncasen2022 |&gt;\n  filter(!is.na(esc), dau %in% 1:10) |&gt;\n  ggplot(aes(x = esc, y = dau)) +\n    geom_jitter(width = 0.2, height = 0.2, alpha = 0.3, color = \"#4E79A7\") +\n    scale_y_continuous(breaks = 1:10) +\n    labs(\n      x     = \"Años de escolaridad\",\n      y     = \"Decil autónomo nacional\",\n      title = \"Dispersión: Escolaridad vs Decil de ingreso del hogar\"\n    ) +\n    theme_minimal(base_family = \"serif\", base_size = 14)\n\n\n\n\n\n\n\n\n# 2) Agrupar ingreso autónomo del hogar en 100 percentiles y graficar\ncasen2022 |&gt;\n  filter(!is.na(esc), !is.na(yautcorh)) |&gt;\n  mutate(percentil = ntile(yautcorh, 100)) |&gt;\n  ggplot(aes(x = esc, y = percentil)) +\n    geom_jitter(width = 0.2, height = 0.2, alpha = 0.3, color = \"#4E79A7\") +\n    scale_y_continuous(breaks = seq(0, 100, by = 10)) +\n    labs(\n      x     = \"Años de escolaridad\",\n      y     = \"Percentil de ingreso autónomo del hogar\",\n      title = \"Dispersión: Escolaridad vs Percentiles de ingreso\"\n    ) +\n    theme_minimal(base_family = \"serif\", base_size = 14)\n\n\n\n\n\n\n\n\nAhora bien, en ninguno de los casos se ve bien. Esto es por dos motivos: 1) ambas variables son discretas con muy pocos valores únicos (esc y dau). Pero, incluso si aumentamos a 100 grupos, y ya no usamos dau, tampoco funciona. En realidad, esto nuevamente se debe a la naturaleza de la variable ingreso, que es continua y tiene un rango muy alto. 2) Esto último produce lo que se conoce como overplotting, que en nuestro caso, con más de 200.000 observaciones, incluso un pequeño desplazamiento de jitter deja millones de puntos amontonados, de modo que no se distingue ninguna tendencia ni densidad real.\nEntonces, para lo que queremos graficar, en este caso, ingresos y su asociación son el nivel de escolaridad, no nos sirve tomar dos variables discretas, aunque sean cuantitativas ambas. Probemos, entonces, si el viejo logaritmo nos ayuda en este caso.\n\ncasen2022 |&gt;\n  filter(!is.na(esc), !is.na(yautcorh)) |&gt;\n  ggplot(aes(x = esc, y = yautcorh)) +\n    geom_jitter(width = 0.1, alpha = 0.5, color = \"#ADD8E6\") +\n    scale_y_log10(labels = comma) +\n    labs(\n      x     = \"Años de escolaridad\",\n      y     = \"Ingreso autónomo corregido (escala log)\",\n      title = \"Dispersión: Escolaridad vs Ingreso (log)\"\n    ) +\n    theme_minimal(base_family = \"serif\", base_size = 14)\n\n\n\n\n\n\n\n\nComo se ve, ahora si el gráfico nos comunica algo más comprensible. Además, se puede ver cómo va reduciendo la dispersión en cuanto avanzan los años de escolaridad. Es importante resaltar la cantidad de outliers que hay que notienen ingresos autónomos, aún avancen los años de escolaridad. Esto también puede tener que ver con que estamos usando ingresos autónomos del hogar y no de los individuos. Pero, a saber. No voy a profundizar en esto ahora.\nLo que si me parece más interesante ahora es adelantar algo bacán que se puede hacer con ggplot2 y los scatterplots. Esta tendencia que vemos en los datos, también podemos inmediatamente modelarla. El paquete permite, al graficar la dispersión de los datos, trazar una linea de tendencia con bandas de error estándar mediante un modelo lineal. Como ya advertimos antes, ahora es aún más útil aplicar log(), porque dado que los ingresos no se comportan con una distribución normal, transformamos el eje x (yautcorh) de una escala linear a una escala logarítmica. Esto nos permitirá un mejor ajuste de la línea de regresión estimada. Luego, cuando lleguemos a regresiones, veremos la utilidad de esto, como ya he ido adelantando. También podemos ajustar los valores de ingres a una notación mas adecuada, en este caso, pesos chilenos.\n\n#Scatter plot con línea de regresión\nggplot(\n  casen2022 |&gt; filter(!is.na(esc), !is.na(yautcorh)),\n  aes(x = esc, y = yautcorh)\n) +\n  geom_point(alpha = 0.4, color = \"#36648B\") +\n  geom_smooth(\n    method = \"gam\",\n    se     = TRUE,\n    color  = \"#8B0000\",\n    fill   = \"#696969\",\n    size   = 1\n  ) +\n  scale_y_log10(labels = scales::dollar_format(prefix = \"$\", suffix = \" CLP\")) +\n  labs(\n    x     = \"Años de escolaridad\",\n    y     = \"Ingreso autónomo corregido del hogar\",\n    title = \"Nivel de ingreso autónomo corregido según años de escolaridad\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\nEntonces, y ahora sí, el gráfico muestra, en escala logarítmica, cómo varía el ingreso autónomo corregido del hogar según los años de escolaridad (para personas de 15 años en adelante). De este scatter plot se puede interpretar que hay\n\nTendencia creciente. La línea de tendencia sube de izquierda a derecha, lo que indica que a más años de escolaridad corresponde, en promedio, un ingreso mayor;\nNo obstante, existen rendimientos decrecientes. La pendiente es más pronunciada en los primeros años de escolaridad y se aplana conforme avanzamos hacia niveles superiores, sugiriendo que cada año adicional de educación añade menos aumento porcentual al ingreso que el año anterior.\nAlta dispersión. A cualquier nivel de escolaridad hay una enorme variabilidad de ingresos (nubes de puntos muy extendidas). Esto refleja que, aunque el promedio sube con la educación, los ingresos individuales probablemente dependen también de otros factores (sector, experiencia, género, etc., a saber).\nRespecto a la confianza de la curva, se puede observar que la banda gris alrededor de la línea es más estrecha en los niveles de escolaridad donde hay más observaciones (por ejemplo entre 8 y 12 años) y más ancha en los extremos (muy poca gente con 0 ó &gt;20 años), lo que nos habla de mayor incertidumbre al estimar la relación fuera del rango central.\n\nEn suma, el gráfico confirma una asociación positiva entre educación e ingreso, con incrementos relativos mayores al inicio de la escolaridad y un efecto suavemente decreciente en los niveles más altos.\nFinalmente, respecto a los gráficos de tipo scatter plot, hay que tener ojo qué tipo de variables vamos a visualizar. No basta con asociar dos variables cuantitativas, sino que también hay que fijarse en si son discretas, continuas, en la cantidad de observaciones, etc.; en definitiva, en la naturaleza de las variables asociadas. A menudo, tendremos que realizar transformaciones a nuestras variables para que el gráfico comunique mejor el carácter de la asociación de las variables de interés."
  },
  {
    "objectID": "lectures/02-statistics.html#estadística-inferencial-una-introducción",
    "href": "lectures/02-statistics.html#estadística-inferencial-una-introducción",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "3. Estadística inferencial: una introducción",
    "text": "3. Estadística inferencial: una introducción\nRetomemos algunas cosas y veamos algunas cosas con las que deberíamos haber comenzado todo, pero que por cuestiones del curso no alcanzan. Partamos por qué es una variable aleatoria.\n\nVariables aleatorias: funciones y distribución de probabilidad\nLa probabilidad es una medida que nos entrega un grado de certidumbre de que ocurra un evento incierto. La teoría de la probabilidad es la base de toda estadístíca y, por tanto, de la econometría. Y la base de la probabilidad es la teoría de conjuntos y la matemática. Teníamos que la probabilidad intenta asignar a cada evento de un experimento un valor \\((\\in \\mathbb{R})\\) para capturar la frecuencia del evento si el experiemento fuese repetido muchas veces. De ello, deducimos los axiomas de la probabilidad y otras propiedades que eran consecuencias de ellos. Finalmente, examinamos los tipos de probabilidades (conjunta, margianl y condicional), poniendo un énfasis especial en la probabilidad condicional y la independencia estadística entre eventos. Con todo eso, veamos qué es una variable aleatoria.\nUna variable aleatoria es “una función de valor real para la cual el dominio es un espacio muestral” (Wackerly, et al., 2010, p. 76). Una variable aleatoria (v.a.), así, toma valores que son determinados por un proceso aleatorio, que muchas veces puede ser un proceso natural estocástico.5. De tal modo, una v.a. no es más que una representación numérica de los resultados potenciales de un experimento. Formalmente,\n\n\n\n\n\n\nDefinición\n\n\n\nSea \\(\\mbox{S}\\) el espacio muestral de un experimento. Una función de valor real definida en \\(\\mbox{S}\\) se denomina variable aleatoria (DeGroot y Schervish, 2014, p. 93)\n\n\nDe tal modo, dado que una variable aleatoria es un resumen numérico de algún resultado de interés. Y que, formalmente, es una función que asocia un número real a cada elemento de \\(\\mbox{S}\\), podemos representarla matemáticamente como \\[\n\\begin{aligned}\n    X&:\\mbox{S} \\longrightarrow \\mathbb{R}\\\\\n    &u \\longrightarrow X(u).\n\\end{aligned}\n\\] Por ejemplo, imaginemos que lanzamos una moneda 2 veces, tal que su espacio muestral es \\(S = \\{cc, cs, sc, ss\\}\\). Definimos, pues, la variable aleatoria \\(X\\) que es el número de caras en los dos lanzamientos. \\[\n\\begin{aligned}\n    X(cc) &= 2 \\\\\n    X(cs) &= 1 \\\\\n    X(sc) &= 1 \\\\\n    X(ss) &= 0\n\\end{aligned}\n\\] En el fondo, para cada caso que saliera cara, \\(c\\), la función arrojaba cuántos \\(c\\) hay en el espacio muestral en función de cómo la evaluáramos. Por ende, \\(X\\) puede tomar los valores 0, 1 y 2, solamente. En efecto, la principal virtud de las variables aleatorias es que nos permiten describir eventos de forma sencilla. Tomando el caso anterior,\n\n\\(\\{X = 0\\} \\iff\\) Todos los elementos en \\(S\\) que no tienen caras = \\(\\{ss\\}\\). Por lo tanto, \\[\n  \\Pr(X = 0) = \\Pr(\\{ss\\}) = \\frac{1}{4}.\n\\]\n\\(\\{X = 1\\} \\iff\\) Todos los elementos en \\(S\\) que tienen una cara = \\(\\{cs, sc\\}\\). Por lo tanto, \\[\n\\Pr(X = 1) = \\Pr(\\{cs, sc\\}) = \\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}.\n\\]\n\\(\\{X = 2\\} \\iff\\) Todos los elementos en \\(S\\) que tienen dos caras = \\(\\{cc\\}\\). Por lo tanto, \\[\n\\Pr(X = 2) = \\Pr(\\{cc\\}) = \\frac{1}{4}.\n\\]\n\nAhora bien, a partir de un espacio muestral podemos crear diversas variables aleatorias. En el ejemplo anterior creamos el número de caras, pero también podemos denotar por \\(Y\\) la v.a. que cuenta el número de sellos. \\[\n\\begin{aligned}\nY(cc) &= 0 \\\\\nY(cs) &= 1 \\\\\nY(sc) &= 1 \\\\\nY(ss) &= 2\n\\end{aligned}\n\\] A partir de un espacio muestral podemos crear diversas variables aleatorias. En el ejemplo anterior creamos el número de caras, pero también podemos denotar por \\(Y\\) la v.a. que cuenta el número de sellos. Finalmente, notemos que por definición \\[\nX + Y = 2.\n\\] #### Tipos de variables aleatorias y distribuciones de probabilidad asociada\nQuizás como ya podrían intuir, hay dos grandes grupos de variables aleatorias: las discretas y las continuas. En este curso, no profundizaremos en esto, pero si mencionaremos brevemente algunas cuestiones importantes antes de llegar al estadística inferencial.\n\nVariables aleatorias discretas\nUna variable aleatoria discreta es aquella que toma un número finito o numerable de valores. Por ejemplo, el el resultado de lanzar un dado. Formalmente, diremos que\n\n\n\n\n\n\nDefinición\n\n\n\nUna v.a. \\(X\\) es si existe un conjunto finito \\(A = \\{a_1, a_2, ..., a_n\\}\\) tal que \\[\n\\Pr(X \\text{ toma valores en } A) = 1.\n\\]\n\n\nTenemos, entonces, que la variable aleatoria captura la información contenida en todo el espacio muestral del experimento en una cantidad numérica. Ahora bien, el valor del experimento, por definición, no se conoce, dada su naturaleza aleatoria. Lo que conocemos, en cambio, es \\(\\mathbb{S}\\). Es decir, que conocemos todos los resultados potenciales del experimento aleatorio. Del lanzamiento de un dado, no sabemos qué va salir exactamente, pero sí sabemos que solo puede salir entre 1 y 6. No puede salir 7, ni Spiderman, ni Conchalí. Porque esos son valores que no pertenecen a \\(\\mathbb{S}\\). Entonces, tenemos que volver ahora al concepto de función de probabilidad, incorporando este nuevo conocimiento.\n\n\n\n\n\n\nDefinición\n\n\n\nConsideremos una v.a. discreta \\(X\\) definida sobre un espacio muestral \\(\\mathbb{S}\\). Entonces la función de probabilidad (f.p.) de \\(X\\) se define como: \\[\nf(x) = \\Pr(X = x).\n\\]\n\n\nLa expresión \\(f(x) = \\Pr(X = x)\\) nos dice que la fdp de \\(X\\) evaluada en un valor particular de \\(x\\) se corresponde con la probabilidad de que la v.a. \\(X\\) tome algún valor de \\(x\\). Es decir, que \\(X\\) corresponde a la v.a., mientras que \\(x\\) corresponde algún valor particular de \\(X\\). Además, se tiene que \\(f(x)&gt;0\\), i.e., es estrictamente positivo para \\(x\\) en el soporte de \\(X\\) y \\(f(x)=0\\), i.e., vale 0 cualquier otro caso, o sea, en caso contrario.\nPor ejemplo, si se lanza una moneda honesta 2 veces. Entonces\n\nVariable aleatoria \\(X\\): número de caras en los 2 lanzamientos.\nVariable aleatoria \\(Y\\): número de sellos en los 2 lanzamientos.\n\n¿Cuál es la f.p. de \\(X\\)? Ya deberíamos saber que \\[\nf(0) = \\frac{1}{4}, \\quad f(1) = \\frac{1}{2}, \\quad f(2) = \\frac{1}{4}, \\quad f(x) = 0 \\quad \\text{para cualquier otro valor de } x.\n\\] pero ahora además le agregamos que \\(f(x)=0\\) es cualquier otro valor. ¿Y cuál es la f.p. de \\(Y\\)? Por simetría, ya veíamos que era exactamente la misma probabilidad que la f.p. de \\(X\\). Ahora bien, a pesar de que \\(X\\) e \\(Y\\) tienen la misma función de probabilidad, no son la misma v.a. Por ejemplo, cuando salen 2 caras, tenemos que \\(X(cc)=2\\) e \\(Y(cc)=0\\). Veamos ejemplos de variables aleatorias discretas y sus distribuciones de probabilidad.\n\nDistribución uniforme discreta\nUna distribución uniforme discreta (UD) corresponde a una función de probabilidad donde todos los eventos tienen la misma probabilidad, como el lanzamiento de un dado. Si se tiene que \\(m\\) y \\(n\\) son números enteros tales que \\(m \\leq n\\), que \\(X\\) es una v.a. discreta, \\(X\\) tendrá una distribución uniforme discreta entre los eventos \\(m\\) y \\(n\\), o \\(X\\sim UD(m,n)\\) si se cumple que \\[\nf(x) =\n\\begin{cases}\n\\frac{1}{n-m+1} & x=m, m+1, \\ldots, n\\\\\n0 & \\text{en caso contrario}\n\\end{cases}\n\\] Notemos, además, que la distribución de probabilidad de una v.a. discreta suma 1.\n\n\nDistribución de Bernoulli\nUna variable aleatoria \\(X\\) sigue una distribución de Bernoulli si solo toma dos valores, específicamente \\(0\\) o \\(1\\). Es decir que \\(X\\) sigue una distribución de Bernoulli de parámetro \\(p\\in [0,1]\\) si \\(X\\) toma valores \\(0\\) o \\(1\\) y si \\(\\Pr(X=1)=p\\). Esto lo denotamos como \\(X\\sim \\mbox{Bern}(p)\\)\nEntonces, si \\(X \\sim \\mbox{Bern}(p)\\) la función de probabilidad, denotada por \\(f(x)\\) es \\[\nf(x) =\n\\begin{cases}\n    p & \\text{si } x = 1, \\\\\n    1 - p & \\text{si } x = 0, \\\\\n    0 & \\text{si } x \\notin \\{0, 1\\}\n\\end{cases}\n\\] Es habitual para experimentos con solo dos resultados posibles que se interpreten los dos resultados posibles como éxito y fracaso, i.e., \\(X=1\\) es considerado como éxito y \\(X=0\\) como fracaso. Por ejemplo, si al lanzar una moneda, definimos \\(X\\) según: si sale cara, \\(X = 1\\); y si sale sello, \\(X = 0\\). Entonces, \\[\np = \\frac{1}{2}, \\quad X \\sim \\text{Ber}(0,5).\n\\]\n\n\nDistribución Binomial: Ensayos de Bernoulli y coeficiente binomial\nAntes de ver distribución binomial, conviene ver un concepto previo, los famosos “Ensayos de Bernoulli”. Una secuencia de ensayos de Bernoulli es una secuencia \\(X_1, X_2, \\dots, X_n\\) de variables aleatorias independientes con distribución común \\(\\mbox{Bern}(p)\\), donde \\(0 \\leq p \\leq 1\\). Es decir, una secuencia de \\(n\\) ensayos de Bernoulli es una secuencia de ensayos que cumple lo siguiente:\n\nSolo dos resultados posibles en cada ensayo: 1 (éxito) y 0 (fracaso).\nEnsayos independientes.\nLa misma probabilidad de éxito en cada ensayo.\n\nDe tal modo, formalizando, diremos que una secuencia de ensayos de Bernoulli es una seguidilla de variables aleatorias independientes, tal que \\[\nX_1 \\sim \\mbox{Bern}(p), X_2 \\sim \\mbox{Bern}(p), \\ldots , X_n \\sim \\mbox{Bern}(p)\n\\] donde \\(0\\leq p \\leq 1\\). En otras palabras, una secuencia de \\(n\\) ensayos de Bernoulli cumple co que se realizan \\(n\\) experimentos donde hay dos resultados posibles (éxito o fracaso, 1 o 0), que son independientes y donde la probabilidad de éxito es la misma para cada ensayo. Ahora bien, cuando hablemos de la distribución de una secuencia de \\(n\\) ensayos de Bernoullli con parámetro \\(p\\) o probabilidad de éxito \\(p\\), estamos hablando de una distribución binomial.\nUna variable aleatoria \\(X\\) sigue una distribución binomial con parámetros \\(n\\) y \\(p\\) si \\(X\\) tiene una distribución discreta con función de probabilidad: \\[\nf(x) =\n\\begin{cases}\n\\binom{n}{x} p^x (1-p)^{n-x} & \\text{para } x = 0, 1, 2, \\dots, n, \\\\\n0 & \\text{si no.}\n\\end{cases}\n\\] El parámetro \\(n\\) es un entero mayor o igual que uno, mientras que \\(p\\) pertenece al intervalo \\(\\{0,1\\}\\). Escribimos \\(X \\sim \\text{Bin}(n, p)\\) y decimos “\\(X\\) sigue una Binomial con parámetros \\(n\\) y \\(p\\)”.\nAlgo que se suele ver en conteo y combinatoria, y que no incluyo en este apunte, es el coeficiente binomial. Este se escribe como \\[\n\\binom{n}{x} = \\frac{n!}{x!(n-x)!}\n\\] y en combinatoria representa el número de formas de escoger (sin importar el orden) un subconjunto de \\(x\\) objetos extraídos de un conjunto de \\(n\\) objetos distintos. Por ejemplo, si se tiene \\(n=5\\) frutas distintas y queremos saber de cuántas maneras puede elegir \\(x=2\\) de ellas, se hace lo siguiente: \\[\n\\binom{n}{x} = \\frac{n!}{x!(n-x)!} = \\frac{5!}{2!3!} = \\frac{120}{2 \\cdot 6} = 10\n\\] Es decir, hay 10 pares distintos que se pueden formar. Esto tiene las siguiente propiedades clave (que usaremos para un teorema de sobre la distribución binomial y ensayos de Bernoulli, por eso lo coloco):\n\nSimetría\n\\[\\binom{n}{x} = \\binom{n}{n - x}\\]\nElegir (x) de (n) es lo mismo que elegir los (n - x) que quedan fuera.\nValor en los extremos\n\\[\\binom{n}{0} = \\binom{n}{n} = 1\\]\nSólo hay una forma de no escoger nada o de escoger todo.\nRelación recursiva (Triángulo de Pascal)\n\\[\\binom{n}{x} = \\binom{n - 1}{x - 1} + \\binom{n - 1}{x}\\]\n\nAdemás, de las propieidades, una Aplicación en el Teorema del Binomio es la siguiente: en la expansión de \\((a + b)^n\\), los coeficientes vienen dados por:\n\\[\n(a + b)^n = \\sum_{x = 0}^{n} \\binom{n}{x}\\,a^x\\,b^{\\,n - x}.\n\\]\nRespecto a la interpretación probabilística del coeficiente binomial, tenemos que fijarnos en lo siguiente. En un experimento de Bernoulli (éxito o fracaso) con probabilidad de éxito (p) en cada ensayo, la probabilidad de obtener exactamente (x) éxitos en (n) ensayos es:\n\\[\nP(X = x) = \\binom{n}{x}\\,p^x\\,(1 - p)^{\\,n - x}.\n\\]\nEn resumen, \\(\\displaystyle \\binom{n}{x}\\) cuenta de cuántas maneras puedes elegir \\(x\\) elementos de un total de \\(n\\), y aparece de forma natural en combinatoria, en el desarrollo de potencias binomiales y en distribuciones de probabilidad.\nCon todo esto, veremos un Teorema, que nos permite relacionar la distribución binomial con los ensayos de Bernoulli. Con ello, sabremos bien para qué nos sirve este tipo de distribución.\n\n\n\n\n\n\nTeorema: Distribución Binomial y ensayos de Bernoulli.\n\n\n\nSea \\(X_1, X_2, \\dots, X_n\\) variables aleatorias independientes, con distribuciones Bernoulli de parámetro \\(p\\). Diremos, por tanto, que se trata de \\(n\\) ensayos de Bernoulli con probabilidad de éxito \\(p\\), donde se sobreentiende que son independientes. Denotamos por \\(S\\) el número de éxitos en los \\(n\\) ensayos, es decir \\[\nS = X_1 + X_2 + \\dots + X_n.\n\\] Entonces \\(S \\sim \\mbox{Bin}(n, p)\\).\n\n\n\n\n\nDistribución Geométrica\nUna variable aleatoria \\(X\\) sigue una distribución geométrica de parámetro \\(p\\), \\(0 &lt; p &lt; 1\\), si \\(X\\) tiene una distribución discreta con función de probabilidad: \\[\nf(x) =\n    \\begin{cases}\n    pq^x & \\text{para } x = 0, 1, 2, \\dots \\\\\n    0 & \\text{si no.}\n    \\end{cases}\n\\] donde \\(q = 1 - p\\). En este caso, escribimos \\(X \\sim \\mbox{Geo}(p)\\)\n\n\n\n\n\n\nTeorema: Distribución Geómetrica y ensayos de Bernoulli.\n\n\n\nConsideremos \\(X_1,X_2,X_3, \\ldots\\) v.a. \\(\\mbox{Ber}(p)\\) independientes. Denotemos, pues, \\(Y\\) por el número de fracasos antes del primer éxito de la secuencia anterior. Entonces, \\(X\\) sigue una distribución geométrica de parámetro \\(p\\).\n\n\n\n\nRelación Bernoulli, Binomial y Geométrica\nComo ya se podría intuir, este tres tipos de distribuciones de variables aleatorias discretas, están relacionadas. Y lo están de la siguiente manera:\n\nCuando realizamos un experimento que tiene solo dos resultados posibles, estamos ante un ensayo Bernoulli\nSi tenemos una secuencia \\(X_1, X_2, \\dots, X_n\\) de variables aleatorias independientes con distribución común \\(\\mbox{Bern}(p)\\), la suma de ``éxitoa’’ tendrá una distribución \\(\\mbox{Bin}(n,p)\\). Es básicamente, la suma una secuencia de experimentos con distribución \\(\\mbox{Bern}(p)\\)\nSi en esta misma secuencia denotamos como \\(Y\\) el número de ``fracasos’’ antes del primer “éxito”, \\(Y\\) tendrá una distribución \\(\\mbox{Geo}(p)\\)\n\nPor ejemplo, si lanzamos una moneda en la que definimos \\(X=1\\) si sale cara y \\(X=0\\) si sale sello. Supongamos que el resultado fue el siguiente en 8 lanzamientos: \\[\nS = \\{\\text{s, s, c, s, c, c, s, s}\\}\n\\] Tenemos, pues que\n\nEl lanzamiento particular de cada moneda tiene \\(\\mbox{Ber}(0,5)\\).\nSi definimos \\(Y\\) como el número de caras si lanzamos la moneda 8 veces, tenemos que el número de caras fue \\(c=3\\). La distribución de los lanzamientos, así, es de \\(\\mbox{Bin}(n=8, p=0,5\\)).\nSi definimos \\(Z\\) como el número de fracasos antes del primer éxito, dado que hubo dos sellos \\(X=0\\) antes de cara \\(X=1\\), entonces, tenemos, dado que la v.a., sigue una distribución tal qeu \\(\\mbox{Geo}(0,5)\\), entonces, que va tener un \\(\\Pr(Y)=q^2p\\)\n\nGráficamente puede ser aún más claro. Veamos este ejemplo en R.\n\npacman::p_load(dplyr, ggplot2, scales, purrr, tidyr)\n\nset.seed(2025)\nN &lt;- 10000\np &lt;- 0.5\nn &lt;- 8\n\n# 1) Simulaciones\nsim_data &lt;- tibble(\n  Ber = rbinom(N, size = 1, prob = p),\n  Bin = rbinom(N, size = n, prob = p),\n  Geo = rgeom(N, prob = p)\n) |&gt; \n  pivot_longer(everything(), names_to = \"Distrib\", values_to = \"x\")\n\n# 2) PMF empírica\ndf_pmf &lt;- sim_data |&gt; \n  count(Distrib, x) |&gt; \n  group_by(Distrib) |&gt; \n  mutate(prob = n / sum(n)) |&gt; \n  ungroup()\n\n# 3) Graficar\nggplot(df_pmf, aes(x = factor(x), y = prob, fill = Distrib)) +\n  geom_col(color = \"black\", width = 0.7, position = position_dodge(width = 0.8)) +\n  facet_wrap(~ Distrib, scales = \"free_x\", strip.position = \"top\") +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  scale_fill_manual(values = c(\"Ber\" = \"#4E79A7\", \"Bin\" = \"#2CA02C\", \"Geo\" = \"#E15759\")) +\n  labs(\n    x     = \"Valor de la variable aleatoria\",\n    y     = \"Probabilidad empírica\",\n    title = \"Relación entre Bernoulli, Binomial y Geométrica (p = 0.5, n = 8)\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 14) +\n  theme(\n    plot.title    = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    strip.text    = element_text(face = \"bold\", size = 14),\n    axis.text     = element_text(size = 12),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\nDistribución de Poisson\nLa distribución de Poisson es algo que podríamos colocar más adelante. Pero al ser también una distribución propia de variables aleatorias discretas decido dejarla aquí. La distribución de Poisson permite modelar el número de éxistos en un determinado intervalo de tiempo. Por ejemplo, si en 1 hora vendo 20 chocolates promedio, puedo modelar esto con Poisson con parámetro 20. Formalmente tenemos lo siguiente.\nSea \\(\\lambda&gt;0\\). La v.a. \\(X\\) tiene una distribución de Poisson de parámetro \\(\\lambda\\), lo cual denotamos como \\(X\\sim \\mbox{Poi}(\\lambda)\\), si su función de probabilidad satiface \\[\nf(x) = \\frac{e^{-\\lambda}\\lambda^x}{x!}, \\qquad x= 0, 1, 2, \\ldots\n\\] Aquí es donde conviene haber visto algunas cosas antes, particularmente los términos Esperanza y Varianza en este contexto. Pero da igual porque lo pondré en el apartado siguiente. Solo quería seguir la lógica de colocar las distribuciones juntas. Una vez visto esta distribución, esperanza y varianza (siguiente sección), pasaremos a las variables aleatorias continuas y sus distribuciones. Lo que tenemos que ver ahora, respecto a la distribución de Poisson, son sus propiedades.\nPropiedades de la Distribución de Poisson\n\nSi \\(X\\sim \\mbox{Poi}(\\lambda)\\) entonces \\[\n\\mbox{E}(X) = \\lambda, \\qquad \\mbox{Var}(X)=\\lambda\n\\]\nSi \\(X\\sim \\mbox{Poi}(\\lambda_1)\\), \\(Y\\sim \\mbox{Poi}(\\lambda_2)\\), y \\(X\\) e \\(Y\\) son independientes, entonces se tiene que \\[\nX+Y \\sim \\mbox{Poi}(\\lambda_1 +\\lambda_2).\n\\] Es decir, la suma de las v.a. independientes Poisson es Poisson, y el parámetro de las sumas es la suma de los parámetros de las variables individuales.\n\nComo ya mencionamos, la distribución de Poisson es principalmente utilizada para contar el número de éxitos en un determinado intervalo de tiempo o región del espacio, pues una Poisson es una muy buena aproximación para una binomial con un \\(n\\) que tiende a infinito y un parámetro \\(p\\) muy pequeño. En efecto, si se tiene qeu \\(X_n \\sim \\mbox{Bin}(n,p)\\) y \\(n\\) tiende a infinito, entonces \\(X_n\\) converge a Poisson de parámetro \\(\\lambda = np\\), i.e., \\[\n\\lim_{n\\to \\infty} (\\Pr(X_n=x)) = \\frac{e^{-\\lambda}\\lambda^x}{x!}\n\\] Por lo tanto, es recomentable usar este tipo de distribución en el caso que nos enfrentemos a una distribución binomial con un número de ensayos \\(n\\) bastante grande y una probabilidad de éxito \\(p\\) pequeña.\n\n\n\nDistribuciones de variables aleatorias continuas\ndiferencia de las v.a. discretas, las v.a. continuas son aquellas que pueden tomar cualquier valor de un intervalo de una recta real. Es decir, cualquier número real. Un ejemplo puede ser el tiempo, los ingresos, distancias, etc. De tal modo, las v.a. continuas describen el resultado de situaciones de probabilidades en donde lso valores de la v.a. forman un continuum de valores y, por tanto, no es posible listar valores. De tal modo, conviene aprehenderlos mediante intervalos. Formalmente, tenemos lo siguiente:\n\n\n\n\n\n\nDefinición\n\n\n\nLa v.a. \\(X\\) tiene una distribución continua si existe una función \\(f\\) definida sobre la recta real, que toma valores mayores o iguales que 0, tal que cualquier para intervalo la probabilidad de que \\(X\\) tome valores en el intervalo que va de \\(a\\) a \\(b\\) es igual a la integral de \\(f\\) sobre el intervalo. Matemáticamente, \\[\n\\Pr(a&lt;X&lt;b) = \\int^b_a f(x)dx\n\\]\n\n\nCiertamente los intervalos dependerán de lo que queramos modelar. Si \\(a\\leq b\\), entonces, \\[\n\\Pr(a\\leq X\\leq b) = \\int^b_a f(x)dx\n\\] Si, e.g., \\(b=+\\infty\\), entonces \\[\n\\Pr(a\\geq X) = \\int^\\infty_a f(x)dx\n\\] O, si \\(a=-\\infty\\), entonces, \\[\n\\Pr(X\\leq b) = \\int^b_{-\\infty} f(x)dx\n\\] Diremos, ademñas, que \\(f(x)\\) es la función de densidad de probabilidad (o f.d.p.), y ya no solo la f.p., de la v.a. \\(X\\). El conjunto de valores de \\(x\\) donde \\(f(x)&gt;0\\), se conoce como el soporte de \\(X\\). Un ejemplo de esto, lo podríamos observar con lo siguiente. Sea la v.a. continua \\(X\\), cuya f.d.p. está dad por \\[\nf(x)=\n\\begin{cases}\n  \\frac{x}{2} & \\text{si } \\quad 0 \\leq x \\leq 2,\\\\\n  0 & \\text{si no}\n\\end{cases}\n\\] Deberíamos calcular, entonces, \\(\\Pr(1\\leq X \\leq 1,5)\\). Y siguiendo la definición, tendríamos que \\[\n\\Pr(1\\leq X \\leq 1,5) = \\int^{1,5}_1 \\frac{x}{2} dx\n\\] Si resolvemos la integral: \\[\n\\begin{aligned}\n  \\int^{1,5}_1 \\frac{x}{2} dx &= \\frac{1}{2}\\int^{1,5}_1 xdx \\quad || \\text{ regla de la potencia}\\\\\n  &= \\frac{1}{2}\\frac{x^2}{2} \\quad || \\text{ simplificamos}\\\\\n  &= 0,5[0,5x^2]^{1,5}_1 \\quad || F(b)- F(a)\\\\\n  &| \\lim _{x\\to \\:1+}\\left(0.5x^2\\right)=0,5 \\\\\n  &| \\lim _{x\\to \\:1,5-}\\left(0.5x^2\\right)=1,125 \\\\\n  &= 1,125-0,5\\\\\n  &= 0,625\n\\end{aligned}\n\\] Propiedades de una v.a. continua. Para garantizar que se cumple con los axiomas de probabilidad, la f.d.p. \\(f(x)\\) de la v.a. continua \\(X\\) debe cumplir con:\n\nSer positiva: \\[\nf(x) \\geq 0 \\text{ para todo } - \\infty \\leq x \\leq \\infty\n\\]\nLa probabilidad del soporte de \\(X\\) igual a uno \\[\n\\int^\\infty_{-\\infty} f(x)dx =1\n\\] ##### Función de distribución cumulativa\n\nOtro concepto relevante que surge una vez conocemos las v.a. continuas, es el de función de distribución cumulativa. Ahora bien, también tenemos cumulativa para v.a. discretas. Veremos ambas y las propiedades de todas las funciondes cumulativas, además de especialmente fijarnos en el caso de v.a. continuas.\n\n\n\n\n\n\nDefinición\n\n\n\nLa **función de distribución cumulativa (f.d.c.) de una v.a. \\(X\\) es la función \\[\nF(x) = \\Pr(X \\leq x)\n\\] Abreviaremos la f.d.c. como función de distribución, como función cumulativa o cumulativa. La cumulativa está definida para toda v.a. (discreta o continua), y la denotamos con mayúscula \\(F(\\cdot)\\) para distinguirla de la f.d.p y f.p.\n\n\n\nDistribución uniforme para el caso de v.a. continuas\nPartimos con una distribución que ya vimos, pero ahora para el caso de las v.a. continuas. Arrancamos por su definición\n\n\n\n\n\n\nDefinición\n\n\n\nDecimos que la v.a. \\(X\\) sigue una distribución uniforme en el intervalo \\([a,b]\\), donde \\(a\\) y \\(b\\) son números reales con \\(a&lt;b\\), si \\(X\\) toma valores entre \\(a\\) y \\(b\\), y la probabilidad de que \\(X\\) tome valores en cualquier subintervalo de \\([a,b]\\) es proporcional al largo del subintervalo. Si esto es así, escribimos \\(X\\sim \\mbox{U}(a,b)\\).\n\n\nPondré solo un ejemplo. Cumulativa de una v.a. discreta: supongamos que \\(X\\sim \\mbox{Bin}(4, 1/2)\\), de modo que su f.p. está dadar por \\[\nf(x)=\n\\begin{cases}\n\\frac{4}{x}(1/2)^4, & \\quad x=0, 1, 2, 3, 4,\\\\\n0, & \\quad \\text{en caso contrario}\n\\end{cases}\n\\] Y queremos calcular \\(F(2)\\). Esto es, \\[\n\\begin{aligned}\n  F(2) &= \\Pr(X\\leq 2)\\\\\n  &=\\Pr(X=0) + \\Pr(X=1)+\\Pr(X=2)\\\\\n  &=0,5^4+4\\cdot 0,5^4+6\\cdot 0,5^4\\\\\n  &= \\frac{11}{16}\n\\end{aligned}\n\\]\nSi hicieramos esto con todos los valores que toma \\(x\\), y no solo \\(2\\), se puede construir la función cumulativa completa. En R, en el paquete stats hay funciones específicas para distribuciones binomiales que usamos antes. Pero vale la pena especificar que dbinom(), proporciona la densidad, pbinom() proporciona la función de distribución, qbinom() proporciona la función cuantílica y rbinom() genera desviaciones aleatorias. Gráficamente es más facil verlo, así que lo hacemos en R podemos graficarlo así:\n\n\npacman::p_load(dplyr, ggplot2, \n               patchwork) # Para combinar gráficos.\n\n# Preparar datos para Binomial(4, 0.5)\ndf &lt;- tibble(\n  x        = 0:4,\n  pmf      = dbinom(x, size = 4, prob = 0.5),\n  cdf      = pbinom(x, size = 4, prob = 0.5)\n) |&gt; \n  mutate(prev_cdf = lag(cdf, default = 0))\n\n# Gráfico PMF\np_pmf &lt;- ggplot(df, aes(x = x, y = pmf)) +\n  geom_segment(aes(xend = x, y = 0, yend = pmf)) +\n  geom_point(size = 3) +\n  scale_x_continuous(breaks = 0:4) +\n  scale_y_continuous(limits = c(0, max(df$pmf) * 1.1)) +\n  labs(x = \"x\", y = \"f(x)\", title = \"PMF de Binomial(4, 0.5)\") +\n  theme_minimal(base_family = \"sans\", base_size = 14) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n# Gráfico CDF\np_cdf &lt;- ggplot(df, aes(x = x)) +\n  geom_step(aes(y = cdf), direction = \"hv\") +\n  geom_point(aes(y = cdf), size = 3) +\n  geom_point(aes(y = prev_cdf), shape = 21, fill = \"white\", size = 3) +\n  scale_x_continuous(breaks = 0:4) +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.25)) +\n  labs(x = \"x\", y = \"F(x)\", title = \"CDF de Binomial(4, 0.5)\") +\n  theme_minimal(base_family = \"sans\", base_size = 14) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n# Mostrar ambos juntos\np_pmf + p_cdf\n\n\n\n\n\n\n\n\nPuse un ejemplo por lo siguiente: en la primera figura se muestra la función de probabilidad de \\(X\\), donde se centra en 2. En la siguiente figura, se muestra la función cumulativa de \\(X\\). Como se ve, hay saltos y tiene forma de escalera. Esto ocurre porque, en la medida que nos movemos hacia la derecha, \\(0,1, \\ldots, 4\\), cada valor del soporte de \\(X\\) añade a su propia probabilidad de ocurrencia a la probabilidad que la función ya venía acumulando. Por esto mismo, el “tamaño” del salto para un valor particualr de \\(X\\) es igual a la probabilidad de que \\(X\\) tome dicho valor. Por ejemplo, \\(\\Pr(X=2)\\) se expresa la linea vertical (el “salto”) del punto blanco al negro en el valor \\(2\\) de las abscisas.\nCumulativa de una v.a. continua: Para definir esto, partamos con una propiedad de toda cumulativa de una v.a. continua. Sea \\(X\\) una v.a. continua con cumativa \\(F\\) y f.d.p. \\(f\\). Entonces, \\[\nF(x)= \\int^x_{-\\infty}f(u)du\n\\] Aquí la demostración es directa, pues \\[\nF(x)= \\Pr (X \\leq x) = \\int^x_{-\\infty}f(u)du\n\\] lo único que cambia respecto a lo que ya sabíamos es que la variable de integración no puede ser \\(x\\) dado que \\(x\\) es el límite superior de la integral. Por eso se usa \\(u\\), como variable auxiliar.\n\n\nDistribución exponencial\nCon la distribución exponencial, explicaremos lo mismo que explicamos antes con la uniforme, i.e., f.d.p., la cumulativa, sus propiedades, esperanza y varianza. La distribución exponencial es útil para modelar el tiempo de espera hasta el primer éxito en un determinado experimento, donde se sabe que los éxitos llegan a una tasa de \\(\\lambda\\) éxitos en promedio por unidad de tiempo6.\n\n\n\n\n\n\nDefinición\n\n\n\nUna v.a. continua \\(X\\) tiene una distribución exponencial con parámetro \\(\\lambda&gt;0\\) si su densidad de probabilidad es de la forma \\[\nf(x)=\n\\begin{cases}\n  \\lambda e^{-\\lambda x}, & \\text{ si } x \\geq 0,\\\\\n  0 & \\text{ en caso contrario.}\n\\end{cases}\n\\] En tal caso, escribimos \\(X\\sim \\mbox{Exp}(\\lambda)\\)\n\n\nGráficamente, podemos visualizar esto (para distintos parámetros de \\(\\lambda\\)) de la siguiente manera:\n\n\npacman::p_load(dplyr, ggplot2, scales)\n\nlambdas &lt;- c(0.5, 1.0, 1.5)\n\ndf_expo &lt;- expand.grid(\n  x      = seq(0, 6, length.out = 1000),\n  lambda = lambdas\n) |&gt; \n  as_tibble() |&gt; \n  mutate(\n    f     = lambda * exp(-lambda * x),\n    label = sprintf(\"λ = %.1f\", lambda)\n  )\n\nggplot(df_expo, aes(x = x, y = f, color = label)) +\n  geom_line(size = 1) +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = comma) +\n  scale_color_manual(\n    breaks = c(\"λ = 0.5\", \"λ = 1.0\", \"λ = 1.5\"),\n    values = c(\n      \"λ = 0.5\" = \"#1F77B4\",\n      \"λ = 1.0\" = \"#7F7F7F\",\n      \"λ = 1.5\" = \"#2CA02C\"\n    )\n  ) +\n  labs(\n    x     = \"x\",\n    y     = expression(f[X](x)),\n    title = \"F.d.p. de la distribución Exponencial para distintos λ\",\n    color = \"Parámetro λ\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 14) +\n  theme(\n    plot.title   = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    legend.title = element_text(size = 12),\n    legend.text  = element_text(size = 12),\n    axis.text    = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nDistribución normal estándar\nSobre esta distribución, nos detendremos un poco más. Veremos, no solo su función de densidad y cumulativa, sino que también los percentiles de una normal estándar y propiedes importantes. Esta será nuestro vinculo directo con el otro aspecto que habíamos mencionado como relevante para la inferencia estadística y causal además de la Ley de los Grandes Números: el Teorema del Límite Central.\nAdemás, la distribución normal estándar es bastante importante para las ciencias sociales y naturales. Esta distribución provee buen ajuste de los datos para muchos fenómenos naturales, económicos y sociales. Por ejemplo, los datos de altura suelen distribuirse de manera normal estándar, o al menos aproximarse como tal. Por otro lado, podríamos pensar que, e.g., la altura es la suma de multiples factores: edad, genética, sexo, alimentación, etc. Justamente el TLC muestra que el promedio de un número lo suficientemente grande de v.a. independientes sigue una distribución muy cecana a una normal. Así, cuando una v.a. resulta de sumar muchas v.a. aleatorias independientes, la distribución normal es una buena aproximación de la v.a. que resulta. En ello reside el vínculo de esta distribución con el TLC y, lo que posteriormente veremos en inferencia estadística y modelamiento de fenómenos de interés.\n\n\n\n\n\n\nDefinición\n\n\n\nUna variable aleatoria continua sigue una distribución normal estándar si la función de densidad viene dada por \\[\n\\phi(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^2}, \\qquad -\\infty &lt; x &lt; + \\infty\n\\] Notemos, además, que el soporte de la distribución normal estándar son todos los \\(\\mathbb{R}\\), i.e., \\(-\\infty &lt; x &lt; + \\infty\\).\nPor otro lado, se puede probar que \\(\\int^{+\\infty}_{-\\infty} \\phi (X) dx =1\\), lo cual está unido al hehco de que \\(\\phi(x)&gt;0\\) para todo \\(x\\) establece que \\(\\phi(x)\\) efectivamente define una densidad de probabilidad\n\n\nGráficamente, la densidad de una distribución normal estándar se ve así:\n\npacman::p_load(dplyr, ggplot2, grid)\n\n# Crear datos para la densidad de la normal estándar\ndf_norm &lt;- data.frame(x = seq(-4, 4, length.out = 1000)) |&gt;\n  mutate(phi = dnorm(x))\n\n# Graficar densidad y marcar intervalos de 68% y 95%\nggplot(df_norm, aes(x = x, y = phi)) +\n  geom_line(size = 1, color = \"#104E8B\") +\n  geom_vline(xintercept = c(-1, 1), linetype = \"dashed\", color = \"#24693D\") +\n  geom_vline(xintercept = c(-2, 2), linetype = \"dashed\", color = \"#8B1A1A\") +\n  # Flecha para 68%\n  geom_segment(aes(x = -1, y = 0.25, xend = 1, yend = 0.25),\n               arrow = arrow(ends = \"both\", length = unit(0.2, \"cm\")),\n               color = \"#24693D\", size = 1) +\n  annotate(\"text\", x = 0, y = 0.27, label = \"68%\", color = \"#24693D\", size = 4) +\n  # Flecha para 95%\n  geom_segment(aes(x = -2, y = 0.06, xend = 2, yend = 0.06),\n               arrow = arrow(ends = \"both\", length = unit(0.2, \"cm\")),\n               color = \"#8B1A1A\", size = 1) +\n  annotate(\"text\", x = 0, y = 0.08, label = \"95%\", color = \"#8B1A1A\", size = 4) +\n  labs(\n    x     = \"x\",\n    y     = expression(phi(x)),\n    title = \"Densidad de la normal estándar\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.text  = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\nComo se puede observar, la distribución aquí está centrada en una media de \\(0\\). La probabilidad de que nuestra variable aleatoria tome valores entre \\([-1, 1]\\) es del 68%. A su vez, que la v.a. tome valores \\([-2, 2]\\) es del 95%. Por otro lado, la forma de la densidad de la distribución es similar a una campana. Por ello, cuando una distribución toma dicha forma, se le suele decir que toma forma de campana de Gauss.\nComo en todas las otras distribuciones, a partir de la f.d.p. podemos definir su f.d.c., que denotaremos por \\(\\Phi\\). Definamosla:\n\n\n\n\n\n\nDefinición\n\n\n\nLa función cumulativa correspondiente a \\(\\phi(x)\\), que se denota por \\(\\Phi(x)\\), está dada por \\[\n\\Phi(x) = \\int^x_{-\\infty} \\phi(x)du\n\\] Un punto importante, es que la función cumulativa de una normal estándar no tiene una expresión cerrada, por lo cual se usan tablas (con Excel o similares) para calcular sus valores.\nPor otro lado, una consecuencia directa de la simetría antes mencionada (y graficada) para \\(\\phi(x)\\) es que su cumulativa \\(\\Phi(\\cdot)\\) evaluada en \\(-x\\) es \\[\n\\Phi(-x) = 1 - \\Phi(x)\n\\]\n\n\n\nPropiedades de la Distribución Normal Estándar\nPor último, dejamos expresadas las propiedades de una distribución normal estándar. No las demostraré, luego que es más útil ver algunas cuestiones antes, particularmente al ver familia de distribuciones normales.\n\n\n\n\n\n\nPropiedades de la Distribución Normal Estándar\n\n\n\nSupongamos que la v.a. \\(Z\\) sigue una distribución normal estándar, que denotamos como \\(Z \\sim \\mathcal{N}(0,1)\\). Entonces,\n\nSe tiene que \\(\\mbox{E}(Z)=0,\\)\nSe tiene que \\(\\mbox{Var}(Z)=1,\\)\nSe tiene que \\(\\mbox{E}(Z^3)=0,\\)\nSe tiene que \\(\\mbox{Var}(Z^4)=3\\)"
  },
  {
    "objectID": "lectures/02-statistics.html#inferencia-estadística-idea-general-e-introducción-a-los-test-de-hipótesis",
    "href": "lectures/02-statistics.html#inferencia-estadística-idea-general-e-introducción-a-los-test-de-hipótesis",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "4. Inferencia estadística: idea general e introducción a los test de hipótesis",
    "text": "4. Inferencia estadística: idea general e introducción a los test de hipótesis\nEntonces, ahora sí. Hsata aquí, tenemos que existen variables aleatorias discretas o continuas, que tienen una distribución de probabilidad asociada, que se puede calcular mediante sus funciones de densidad (cumulativa). Ahora bien, es justamente esa distribución de las v.a. que fundamentan la inferencia estadística. No obstante, en estadística ocurre algo increíble que nos permitirá tratar distribuciones como si fueran la misma, permitiéndonos a su vez predecir mejor valores probables dentro de esta distribución. Para ello, veremos dos conceptos fundamentales: la Ley de los Grandes Números y el Teorema del Límite Central.\n\nLey de los grandes números (LGN)\nPara comprender la ley de los grandes números, introducimos los conceptos de muestras aleatorias, media de los datos y media muestral. Hasta ahora, no hemos distinguido claramente entre muestra y población. Esta distinción, en conjunto con propiedades y leyes, como la Ley de los Grandes Números (LGN) y el Teorema del Límite Central (TLC), son la base esencial de la inferencia estadística (Canavos, 1988; DeGroot y Schervish, 2014).\nCuando hablamos de población en términos estadísticos, nos referimos al universo completo del fenómeno a medir, tal cual es. Si nuestra población en nuestro estudio son los chilenos, entonces, la población serán todos los individuos de la población chilena. La única forma de obtener esto “en bruto” es encuestando a cada uno de los chilenos, que es lo que pretende el censo (y aún así nunca se logra esto a cabalidad). Obviamente, esto sería no solo muy costoso, sino que además es muy complejo de lograr. Va ser dificil tener plena certeza de que mediante un censo podremos obtener a toda la población, dado que hay personas en situación de calle, migrantes irregulares, etc., que intervienen directamente en relaciones que nos interesan investigar.\nEn cambio, una muestra es una porción de ese universo que nos interesa investigar. Más concretamente, es una colección de datos que se obtienen al llevar a cabo repetidos ensayos de un experimento para lograr una evidencia representativa acerca de la población. Una muestra representativa de la población chilena, por ejemplo, es la CASEN, la ENUT, la ENE, etc., que a través de encuestas solo una porción de la población objetivo, con un diseño muestral adecuado7, infieren información de la población. Por lo tanto, la idea central que queremos tratar de las muestras, es que con ellas podemos inferir estadísticamente de una población específica. Esto conlleva ciertos grados de error, como vimos anteriormente, pero errores conocidos. Por lo tanto, no son equivocaciones, sino que un error estadístico medible.\n\nMuestras aleatorias, medias de los datos y media muestral\n\n\n\n\n\n\nDefinición\n\n\n\nConsideremos una distribución de probabilidad dada en la recta real que puede representarse mediante una función de probabilidad (f.p.) o una función de densidad de probabilidad (f.d.p) \\(f\\). Se dice que \\(n\\) variables aleatorias \\(X_1,\\ldots,X_n\\) forman una muestra aleatoria de esta distribución si estas variables aleatorias son independientes y la función de probabilidad marginal o la función de densidad de probabilidad de cada una de ellas es \\(f\\). También se dice que estas variables aleatorias son independientes e idénticamente distribuidas, lo que se abrevia como i.i.d. Nos referimos al número n de variables aleatorias como el tamaño de la muestra [@probability-statistics]\n\n\nEntonces, cuando hablemos de muestra aleatoria, nos referimos a esa colección de variables \\(X_1, \\ldots, X_n\\), con \\(n\\) observaciones y que entrega datos \\(x_1, \\ldots, x_n\\) que no son más que la realización de dichas v.a. Si esas v.a. de la muestra aleatoria son i.i.d., entonces comparten una función de probabilidad \\(f(x)\\) y una esperanza \\(\\mu\\). El promedio de los datos provenientes de las realizaciones de cada v.a. convergerá a \\(\\mu\\) si \\(n\\) es lo suficientemente grande, tal que \\[\n\\lim_{n\\to \\infty} \\frac{1}{n}\\sum^n_{i=1} x_i \\approx \\mu\n\\] Y este promedio de los datos, pues, corresponde a la media de los datos. Veamos esta convergencia en lanzamientos de un dado, que, obviamente es una muestra aleatoria. Veamos como, en función de que aumenten los experimentos, y con ello la realización de nuestra v.a. \\(X\\), es decir que \\(n\\) crezca por cada lanzamiento de dado, la “esperanza \\(\\mu\\) empírica” (i.e., la media muestral) se va acercando cada vez más a la “teórica”. Sabemos ya que la esperanza del lanzamiento de un dado es \\(3,5\\). Veamos si se va a acercando o no en una simulacion de R.\n\n\npacman::p_load(dplyr, ggplot2, scales)\n\nset.seed(2025)\nn_max &lt;- 100000\nrolls &lt;- sample(1:6, size = n_max, replace = TRUE)\n\ndf_lgn &lt;- tibble(\n  N     = seq_len(n_max),\n  media = cumsum(rolls) / N\n)\n\nggplot(df_lgn, aes(x = N, y = media)) +\n  geom_line(color = \"#4E79A7\") +\n  geom_hline(yintercept = 3.5, linetype = \"dashed\", color = \"#E15759\") +\n  scale_x_log10(labels = comma) +\n  labs(\n    x     = \"Número de lanzamientos\",\n    y     = \"Media muestral\",\n    title = \"Ley de los Grandes Números: convergencia de la media muestral\",\n    subtitle = \"Media teórica del dado = 3,5\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 14) +\n  theme(\n    plot.title    = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    plot.subtitle = element_text(size = 12, hjust = 0.5),\n    axis.text     = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\nEntonces, como vimos, nuestra variable aleatoria \\(X\\), que en este caso es un dado, al realizarse, al lanzar el dado, genera un dato, un \\(x_1\\). Ese dato es el resultado del experimento. Por ejemplo, que salga 5. Si sale 5, el promedio muestral, hasta ahora, que denotaremos como \\(\\bar{x}_1\\) de esa primera realización es 5, \\(\\bar{x}_1=5\\). Si sale para \\(x_2=2\\), entonces \\(\\bar{x}_2=4,5\\). Y así. Como vemos en la simulación, los primeros lanzamientos arrojan un promedio distinto de 3,5. No obstante, mientras más lanzamos el dado, mientras más realizaciones de nuestra v.a. hay, y por tanto, el tamaño muestral \\(n\\) crece, más se asemeja a la esperanza, al valor esperado, que en este caso \\(\\mu=3,5\\). Ello es tal, porque nuestras v.a. tienen una distribución en común, que denotamos como (es decir, son i.i.d.), cuyo valor esperado es \\(\\mbox{E}(X_i)=\\mu\\). Y vimos que se cumple empíricamente que\n\\[\n\\lim_{n\\to \\infty} \\frac{1}{n}\\sum^n_{i=1} x_i \\approx \\mu\n\\] para este caso. Pero además, veremos que esto es así siempre y cuando tengamos una muestra aleatoria adecuada. Ya sabemos qué es la media muestral y con este ejemplo queda claro. Pero formalicemoslo para este caso.\n\n\n\n\n\n\nDefinición\n\n\n\nLa media muestral \\((\\bar{X}_n)\\) corresponde a una v.a. que, por definición, es el promedio de las v.a. de una muestra aleatoria. Si nuestra muestra aleatoria se compone por v.a. \\(X_1, X_2, \\ldots, X_n\\) i.i.d., con \\(\\mbox{E}(X_i) = \\mu\\) y \\(\\mbox{Var}(X_i)= \\sigma^2\\). Entonces, tendremos que \\[\n\\begin{aligned}\n  \\bar{X}_n &= \\frac{1}{n} \\sum^n_{i=1}X_i\\\\\n  \\mbox{E}(\\bar{X}_n) &= \\mu\\\\\n  \\mbox{Var}(\\bar{X}_n) &= \\frac{\\sigma^2}{n}\\\\\n  \\mbox{sd}(\\bar{X}_n) &= \\frac{\\sigma}{n}\n\\end{aligned}\n\\] Dado que \\(\\bar{X}_n\\) es una v.a. del promedio de las v.a. de la muestra, es lógico que tendrá el mismo valor esperado, pero una dispersión bastante menor. El valor observado o realización de la variable aleatoria \\(\\bar{X}_n\\) corresponde al dato \\(\\bar{x}_n\\).\n\n\n\n\nLey de los grandes números\nSabiendo todo esto, ya podemos enunciar la Ley de los grandes números (LGN). Y lo haremos en relación con la media muestral\n\n\n\n\n\n\nDefinición\n\n\n\nSean \\(X_1, \\ldots, X_n\\) variables aleatorias independientes e idénticamente distribuidas con esperanza común \\(\\mu\\) y varianza común \\(\\sigma^2\\), ambas finitas. Entonces la media muestral, \\(\\bar{X}_n\\), converge a \\(\\mu\\) a medida que \\(n\\) aumenta.\n\n\nCiertamente la LGN aplica en varios aspectos y es uno de los pilares que sustenta la consistencia de muchísimos otros estimadores y métodos de probabilidad y estadística. Mantiene proporciones muestrales, e.g., si \\(X_1, \\ldots, X_n\\) son variables Bernoulli (\\(p\\)) la proporción \\[\n\\hat{p}_n = \\frac{1}{n}\\sum^n_{i=1} X_i\n\\] converge al \\(p\\) verdadero (poblacional), lo cual es clave para el trabajo en encuestas, calidad y demografía. Sirve para estimadores basados en momentos, que veremos más adelante al ver método de momentos. Entrega consistencia a la varianza muestral. Y así un sin fin de aspectos donde veremos presente la LGN. No obstante, me interesa seguir profundizando más en esto más adelante. Por ahora, puede ser útil revisar el apéndice “Asymptotic Theory” [@microeconometrics], el cual que ofrece un buen resumen de los elementos más centrales de teoría asintótica aplicada a estimadores econométricos.\nPor último, la demostración de la definición que dimos de la LGN, solo hay que usar la definición de convergencia. Esto es, \\(\\bar{X}_n\\) converge a \\(\\mu\\) dado que \\[\n\\lim_{n\\to\\infty} \\mbox{E}(\\bar{X}_n - \\mu)^2= 0\n\\] Pues si descomponemos, llegaremos a \\(\\lim_{n\\to\\infty}\\sigma^2/n\\), y como \\(n\\to \\infty\\), entonces nos dará \\(0\\). Que demostramos tal que \\[\n\\begin{aligned}\n  \\lim_{n\\to\\infty} \\mbox{E}(\\bar{X}_n - \\mu)^2&= \\lim_{n\\to\\infty} \\mbox{Var}(\\bar{X}_n)\\\\\n  &= \\lim_{n\\to\\infty} \\frac{\\sigma^2}{n} \\\\\n  &=0\n\\end{aligned}\n\\] Más allá de lo formal, la intuición detrás del resultado nos indica que la media mustral pierde su aleatoriedad cuando \\(n\\to \\infty\\), ergo, se centra en el parámetro \\(\\mu\\). Esa es, justamente, la intuición detrás de la LGN. Y es lo que vimos con la simulación del dado.\n\n\n\nTeorema Central del Límite (TCL)\nFinalmente, para casi finalizar el capítulo por fin, veremos el teorema del limite central. Dejo esto al final porque, junto con la Ley de los Grandes Números, y todo lo que hemos visto hasta ahora, tendremos una base sólida para meternos en estadística inferencial como tal. Hagamoslo mediante la siguiente motivación.\nConsideremos la siguientes funciones de probabilidad y función de densidad de probabilidad: Poisson con \\(\\lambda=0,8\\), Bernoulli con \\(p=0,8\\) y Exponencial de \\(\\lambda=0,8\\). Como ya sabemos, son v.a. con distribuciones muy distintas, partiendo porque dos son discretas y la otra continua. Pero incluso las discretas son distintas entre sí, dado que la Bernoulli solo puede tomar dos valores. Además, gráficamente, se ven así:\n\n\npacman::p_load(dplyr, ggplot2, patchwork, scales)\n\n# 1) Poisson(λ = 0.8)\ndf_pois &lt;- tibble(x = 0:6,\n                  f = dpois(x, lambda = 0.8))\np_pois &lt;- ggplot(df_pois, aes(x = x, y = f)) +\n  geom_segment(aes(xend = x, y = 0, yend = f),\n               size = 1, color = \"#9467BD\") +\n  geom_point(size = 3, color = \"#9467BD\") +\n  labs(title = \"Poisson (λ = 0.8)\", x = \"x\", y = \"f(x)\") +\n  scale_y_continuous(labels = comma) +\n  theme_minimal(base_family = \"serif\", base_size = 12) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n# 2) Bernoulli(p = 0.8)\ndf_bern &lt;- tibble(x = c(0, 1),\n                  f = dbinom(x, size = 1, prob = 0.8))\np_bern &lt;- ggplot(df_bern, aes(x = x, y = f)) +\n  geom_segment(aes(xend = x, y = 0, yend = f),\n               size = 1, color = \"#9467BD\") +\n  geom_point(size = 3, color = \"#9467BD\") +\n  labs(title = \"Bernoulli (p = 0.8)\", x = \"x\", y = \"f(x)\") +\n  scale_y_continuous(labels = comma, limits = c(0, 1)) +\n  theme_minimal(base_family = \"serif\", base_size = 12) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n# 3) Exponencial(λ = 0.8)\ndf_exp &lt;- tibble(x = seq(0, 1, length.out = 1000),\n                 f = dexp(x, rate = 0.8))\np_exp &lt;- ggplot(df_exp, aes(x = x, y = f)) +\n  geom_line(size = 1, color = \"#9467BD\") +\n  labs(title = \"Exponencial (λ = 0.8)\", x = \"x\", y = \"f(x)\") +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = comma) +\n  theme_minimal(base_family = \"serif\", base_size = 12) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n# Mostrar los tres gráficos lado a lado\np_pois + p_bern + p_exp + plot_layout(ncol = 3)\n\n\n\n\n\n\n\n\nEntonces, ¿qué tienen en común estas variables aleatorias con distinta distribución? Por sí solas, nada, o al menos no a primera vista. Pero, si sumaramos cada vez más v.a. de esas mismas distribuciones, y graficaramos la suma de cada distribución al irse sumando más v.a. Poisson, Bernoulli y Exponencial, veríamos que sí tienen algo en común:\n\n\npacman::p_load(dplyr, ggplot2, purrr, patchwork)\n\nset.seed(1917)\n\n# Parámetros y tamaños de muestra\nlambda_pois &lt;- 0.8\np_bern      &lt;- 0.8\nrate_exp    &lt;- 0.8\nns          &lt;- c(1, 50, 320)\nn_rep       &lt;- 10000\n\n# Etiquetas y colores\nlbls &lt;- c(pois = \"Poisson\", bern = \"Bernoulli\", expo = \"Exponencial\")\ncols &lt;- c(pois = \"#1F77B4\", bern = \"#7F7F7F\", expo = \"#2CA02C\")\n\n# Función para simular y graficar un solo histograma\nplot_suma &lt;- function(dist, n) {\n  xvals &lt;- switch(dist,\n    pois = replicate(n_rep, sum(rpois(n, lambda_pois))),\n    bern = replicate(n_rep, sum(rbinom(n, size = 1, prob = p_bern))),\n    expo = replicate(n_rep, sum(rexp(n, rate = rate_exp)))\n  )\n  ggplot(data.frame(x = xvals), aes(x)) +\n    geom_histogram(aes(y = after_stat(density)),\n                   bins = 30,\n                   fill = cols[dist], alpha = 0.6,\n                   color = cols[dist]) +\n    labs(\n      title = paste0(\"Σ Xᵢ con n = \", n, \" (\", lbls[dist], \")\"),\n      x     = \"Suma de variables\",\n      y     = \"Densidad\"\n    ) +\n    theme_minimal(base_family = \"serif\", base_size = 10) +\n    theme(\n      plot.title   = element_text(face = \"bold\", size = 11, hjust = 0.5),\n      axis.text   = element_text(size = 10)\n    )\n}\n\n# Para cada n, generar una fila de tres gráficos\nplots_por_n &lt;- map(ns, function(n) {\n  map(c(\"pois\",\"bern\",\"expo\"), ~ plot_suma(.x, n)) %&gt;% \n    wrap_plots(nrow = 1)\n})\n\n# Mostrar todas las filas apiladas\nwrap_plots(plots_por_n, ncol = 1)\n\n\n\n\n\n\n\n\nQuizás tanto gráfico marea, pero de izquierda a derecha, vemos como al sumar las varaibles con distintas distribuciones, \\(\\sum X_i\\), todas van pareciéndose cada vez más a una distribución normal. Esto no es para nada obvio si vemos que en \\(\\sum X_i\\) con \\(n=1\\), en todos los casos, la distribución es muy distinta. Pero cuando ya hay un \\(n=50\\) se parecen aún más. Al seguir creciendo, se parecen aún más.\nEste resultado es muy potente. Pues nos indica que la distribución de la suma de v.a., independiente de la distribución original de cada v.a. sumada, se aproxima a una distribución normal. A esta idea, por tanto, es lo que le llamamos el Teorema del Límite Central.\nLo que vimos recién es una forma de presentar el TLC. Pero no es la única. La que vimos ahora, podemos formalizarla así:\n\n\n\n\n\n\nDefinición\n\n\n\nLa suma de variables aleatorias i.i.d. se distribuye aproximadamente como una normal, cuya media y varianza son resultado de la suma de las v.a., tal que \\[\n\\sum^n_{i=1} X_i  \\overset{a}{\\sim} \\mathcal{N}(n\\mu, n \\sigma^2)\n\\] donde \\(\\overset{a}{\\sim}\\) significa “se distribuye aproximadamente como”. A esta primera definición, la denominaremos como la primera formulación de TLC\n\n\nUna segunda formulación, como habíamos adelantado anteriormente, es respecto al promedio. Lo cual tiene sentido, porque al final si la suma de \\(X_i\\) tiende a una normal, ¿por qué no el promedio, que es una suma ponderada? Siguiendo la lógica anterior,\n\n\n\n\n\n\nDefinición\n\n\n\nEl promedio de \\(n\\) variables aleatorias i.i.d. se distribuye aproximadamente como una normal, cuya media y varianza son iguales a la esperanza y a la varianza del promedio muestral, tal que \\[\n\\bar{X}_n \\overset{a}{\\sim} \\mathcal{N} \\left(\\mu,  \\frac{\\sigma^2}{n}\\right)\n\\]\n\n\nSi nos damos cuenta, segunda formulación no es más que la multiplicación de la primera por \\(1/n\\).\nUna tercera formulación, que probablemente tratemos más adelante, reside en lo siguiente. En algunos casos, la parametrización de la distribución normal queremos que no dependa de \\(n\\). En esto casos, hacemos lo que se llama como “estandarización”. El proceso es el siguiente: si a la segunda formulación, le restamos \\(\\mu\\), nos queda como \\[\n\\bar{X}_n \\overset{a}{\\sim} \\mathcal{N} \\left(\\mu,  \\frac{\\sigma^2}{n}\\right) - \\mu = \\bar{X}_n-\\mu \\overset{a}{\\sim} \\mathcal{N} \\left(0,\\frac{\\sigma^2}{n}\\right)\n\\] Luego dividimos por la desviación estándar: \\[\n\\bar{X}_n-\\mu \\overset{a}{\\sim} \\mathcal{N} \\left(0,\\frac{\\sigma^2}{n}\\right) \\div \\mbox{sd}(\\bar{X}_n) = \\frac{\\bar{X}_n-\\mu}{\\mbox{sd}(\\bar{X}_n)} \\overset{a}{\\sim}\\mathcal{N}(0,1)\n\\] Lo que es igual a \\(\\sigma/\\sqrt{n}\\). Es decir, \\[\n\\frac{\\bar{X}_n-\\mu}{\\mbox{sd}(\\bar{X}_n)} \\overset{a}{\\sim}\\mathcal{N}(0,1) =\\frac{\\bar{X}_n-\\mu}{\\sigma/\\sqrt{n}} \\overset{a}{\\sim}\\mathcal{N}(0,1)\n\\] Y así llegamos a una tercera formulación. Solo hay que restar la media y dividir por la desviación estándar y, al final, tomar esta última expresión y aplicamos la regla de 3, o dicho más bonito y como dicen los profes, “con un poco de algebra”, llegamos a que \\[\n\\frac{\\sqrt{n}(\\bar{X}_n-\\mu)}{\\sigma} \\overset{a}{\\sim}\\mathcal{N}(0,1)\n\\] Y a ese proceso le decimos estandarización.\nVeamos esto gráficamente. Apliquemosle a una variable aleatoria Poisson de parámetro \\(\\lambda=5\\) la primera, la segunda y la tercera formulación. Partamos por la primera\n\npacman::p_load(ggplot2)\n\nset.seed(1917)\nlambda &lt;- 5\nn      &lt;- 1000\nn_rep  &lt;- 10000\n\n# 1) Primera formulación: suma de n v.a. Poisson(λ=5)\nsuma &lt;- replicate(n_rep, sum(rpois(n, lambda)))\nggplot(data.frame(x = suma), aes(x)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 bins = 100,\n                 fill = \"#EEC9E5\", color = \"#7C4D79\", alpha = 0.6) +\n  labs(\n    title = \"Primera formulación: Σ Xᵢ con n = 1000 (Pois(λ=5))\",\n    x     = \"x\",\n    y     = \"Densidad\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 12) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5))\n\n\n\n\n\n\n\n\n\n# Segunda formulación: promedio de n v.a. Poisson(λ=5)\nmedia &lt;- replicate(n_rep, mean(rpois(n, lambda)))\nggplot(data.frame(x = media), aes(x)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 bins = 100,\n                 fill = \"#EEC9E5\", color = \"#7C4D79\", alpha = 0.6) +\n  labs(\n    title = \"Segunda formulación: Σ Xᵢ/n con n = 1000 (Pois(λ=5))\",\n    x     = expression(bar(X)[n]),\n    y     = \"Densidad\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 12, hjust = 0.5),\n    axis.text  = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n# Tercera formulación: variable estandarizada\nstdz &lt;- replicate(n_rep, {\n  m &lt;- mean(rpois(n, lambda))\n  (m - lambda) / sqrt(lambda / n)\n})\nggplot(data.frame(x = stdz), aes(x)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 bins = 100,\n                 fill = \"#EEC9E5\", color = \"#7C4D79\", alpha = 0.6) +\n  labs(\n    title = expression(\"Tercera formulación: \" *\n      frac(sqrt(n) * (bar(X)[n] - mu), sigma) *\n      \" con \" * X[i] ~ \"~Pois(\" * lambda == 5 * \")\"),\n    x = expression(frac(sqrt(n) * (bar(X)[n] - mu), sigma)),\n    y = \"Densidad\"\n  ) +\n  theme_minimal(base_family = \"serif\", base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 12, hjust = 0.5),\n    axis.text  = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\nComo vemos, no cambia mucho la forma. Todas siguen la campana de Gauss característica de las distribuciones normales. No obstante, cambian los valores de las abscisas y las ordenadas, pues justamente hay trasnformaciones en su “escala”. Por ejemplo, la primera tiene un eje \\(X\\) con valores entre 4700 y 5200. La segunda de 4,7 a 5,2, porque está dividido por \\(n\\) siguiendo la segunda formulación. Siguiendo la tercera, es decir, un proceso de estandarización, el eje de las abscisas queda como una normal estándar :). Entonces, formalicemos todo esto\n\n\n\n\n\n\nTeorema Central del Límite\n\n\n\nSean \\(X_1, X_2, \\ldots, X_n\\) variables aleatorias i.i.d. con media \\(\\mu\\) y varianza \\(\\sigma^2\\). Denotamos por \\(\\bar{X}_n\\) la media meustral de las primera \\(n\\) variables aleatorias. Entonces, \\[\n\\forall y  \\quad \\lim_{n\\to \\infty} \\Pr\\left(\\frac{\\sqrt{n}(\\bar{X}_n-\\mu)}{\\sigma} \\leq y \\right) = \\Phi(y)\n\\] El TCL es un resultado de convergencia en distribución de probabilidad. La distribución de la v.a. dada por \\[\n\\frac{\\sqrt{n}(\\bar{X}_n-\\mu)}{\\sigma}\n\\] converge a la distribución normal estándar cuando \\(n\\) tiende a infinito.\n\n\nHay que insistir en la importancia de este resultado. Extrememos el caso. Imaginemos que no tenemos idea de la distribución de nuestras variables aleatorias originales. Mientras trabajemos con la suma (primera formulación) o el promedio (segunda) de un \\(n\\) grande de v.a., entonces podemos usar la distribución normal para aproximar la distribución de la suma o promedio. Con este resultado, pues, podremos aproximar todas las distribuciones que querramos. No lo haré aquí. Pero sin duda tendremos que hacerlo al ir avanzando en cuestiones estadísticas y econométricas\nPor otro lado, hasta ahora, hemos visto la Ley de los Grandes Números (LGN) afirma que, para \\(n\\) grande, la media muestral es aproximadamente una constante (la experanza \\(\\mu\\)). Acabamos de ver, además, que el TCL afirma que, para \\(n\\) grande, la media muestral se distribuye aproximadamente normal con media \\(\\mu\\) y varianza \\(\\sigma^2/n\\). Visto así, podría parecer contradictorio que la media muestral, al mismo tiempo, sea aproximadamente constante y distribuirse aproximadamente normal. Pero no hay contradicción, porque como ya podríamos intuir, la varianza de \\(\\bar{X}_n\\) tiende a cero cuando \\(n\\) tiende a infinito."
  },
  {
    "objectID": "lectures/02-statistics.html#footnotes",
    "href": "lectures/02-statistics.html#footnotes",
    "title": "Sesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEl LaTex se coloca \\dbtilde{}. No me deja en Quarto, pero colocar \\tilde{\\tilde{x}} es para representar que se denota con doble tilde↩︎\nEsto no lo haré para los datos muestrales de la CASEN 2022. Principalmente, porque para eso usaremos, más adelante, paquetes especializados, como survey y srvyr↩︎\nYo uso las paletas de colores de aquí↩︎\nPara ello, hay muchas bases de datos que si registran esta información. Además, el MINEDUC una buena plataforma de datos abiertos, pero para centrarnos, en este capítulo, en la CASEN↩︎\nUn proceso estocástico es aquel cuyo resultado no puede preverse con certeza de antemano. En cambio, un proceso determinista produce siempre el mismo resultado cuando se parte de una misma condición inicial. Por ejemplo, lanzar una moneda es un proceso estocástico, mientras que sumar dos números concretos es un proceso determinista. Luego lo usaremos como homólogo de proceso aleatorio↩︎\nSe podría denominar esta distribució como la contraparte continua de una v.a. geométrica, pues se utiliza frecuentemente para representar tiempo de espera antes del éxito. En rigor, la distribución exponencial es un caso particular de la distribución gamma.↩︎\nPor ejemplo, la CASEN utilliza un diseño probabilístico, estratificado y bietápico; y es representativa a nivel nacional, áreas geográficas urbana y rural y regional. Pero no entra en ese este apunte ni muestreo ni diseños de investigación↩︎"
  },
  {
    "objectID": "lectures/01-intro.html",
    "href": "lectures/01-intro.html",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "",
    "text": "Al finalizar esta sesión serás capaz de:\n\nNavegar en la interfaz de RStudio\nObtener conocimientos básicos sobre R y su lógica de programación\nCrear y manipular objetos básicos en R (vectores, dataframes)\nImportar datos, cargar paquetes, crear funciones de usuario\nCalcular medidas de tendencia central\nCrear tablas de frecuencia simples y de contingencia"
  },
  {
    "objectID": "lectures/01-intro.html#objetivos-de-la-sesión",
    "href": "lectures/01-intro.html#objetivos-de-la-sesión",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "",
    "text": "Al finalizar esta sesión serás capaz de:\n\nNavegar en la interfaz de RStudio\nObtener conocimientos básicos sobre R y su lógica de programación\nCrear y manipular objetos básicos en R (vectores, dataframes)\nImportar datos, cargar paquetes, crear funciones de usuario\nCalcular medidas de tendencia central\nCrear tablas de frecuencia simples y de contingencia"
  },
  {
    "objectID": "lectures/01-intro.html#introducción-a-r-y-rstudio",
    "href": "lectures/01-intro.html#introducción-a-r-y-rstudio",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "1. Introducción a R y RStudio",
    "text": "1. Introducción a R y RStudio\n\n¿Qué es R?\nR es un lenguaje de programación especializado en análisis estadístico y visualización de datos. Es:\n\nGratuito y de código abierto\nSe ha consolidado en las últimas décadas como una herramienta de primer nivel para el análisis estadístico y programación (Fernández-Avilés y Montero, 2024)\nPotente para análisis estadísticos complejos\nVersátil con miles de paquetes disponibles\nReproducible: tu análisis queda documentado en código :)\n\n\n\nLa interfaz de RStudio\nRStudio tiene 4 paneles principales:\n\nEditor (arriba izquierda): Donde escribes tu código en scripts\nConsola (abajo izquierda): Donde se ejecuta el código y ves resultados\nEnvironment (arriba derecha): Muestra tus objetos/datos cargados\nFiles/Plots/Help (abajo derecha): Archivos, gráficos, ayuda\n\nEstos paneles se pueden modificar a comodidad, así como el theme del IDE, el tamaño y fuente de la letra y código, etc. Lo importante no es sólo que aprendas a usar las herramientas que nos entrega RStudio, sino que también lo hagas una herramienta propia para usar R de la manera más cómoda posible. Al final, como R es un lenguaje de programación, cada quien puede hablarlo como quiera, con sus mañas y prácticas.\n\n\n\n\n\n\nConsejo\n\n\n\nSiempre trabaja con scripts (archivos .R o .qmd) en lugar de escribir directo en la consola. Así tu trabajo queda guardado y es reproducible.\n\n\nAntes de comenzar, cabe aclarar que iremos tratando de exponer el contenido de R no tanto en orden como si fuera solo un curso de R, sino que siguiendo la lógica de un curso de metodología. Para ello, temáticamente, iremos avanzando en función de los contenidos del programa y, en virtud de ello, veremos cómo hacer esto en R. Ahora bien, no por ello no nos detendremos todo lo que necesiten en algún aspecto de R que quieran profundizar. Recuerden que este curso es para aportarles herramienrtas metodológicas para sus investigaciones de Magíster, para las que probablemente tengan que hacer un uso extensivo de R (incluso para investigaciones más cualitativas)."
  },
  {
    "objectID": "lectures/01-intro.html#conceptos-básicos-de-r",
    "href": "lectures/01-intro.html#conceptos-básicos-de-r",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "2. Conceptos básicos de R",
    "text": "2. Conceptos básicos de R\nR, ante todo, es “un sistema para computación estadística: software de análisis de datos y lenguaje de programación” (Cano en Fernández-Avilés y Montero, 2024). Es ampliamente utilizado en investigación y docencia, pero también ha tomado un lugar importante en la industria y el servicio público.\nR nació como una adaptación (en clave software libre y bajo la lógica de programación reproducible) del lenguaje S, complementándolo con un excelente soporte para el uso estadístico (Wickham y Grolemund, 2023). R tiene una lógica de programación llamada Programación Orientada a Objetos (OOP, por sus cifras en inglés: object-oriented programming), el cual permite un polimorfismo muy útil y versatil para programación estadística y que se relaciona con la encapsulación de objetos (Wickham, 2019). Más allá de tecnicismos, veremos todo esto en el curso, con ejemplos aplicados a sus investigaciones del Magíster.\n\nPreparación\n\n# Cargar librerías necesarias\nlibrary(tidyverse)  # Para manipulación de datos\nlibrary(psych)      # Para estadística descriptiva\nlibrary(sjmisc)     # Para explorar datos\nlibrary(haven)      # Para cargar archivos .dta o .sav\nlibrary(kableExtra) # Para presentacion de resultados\n\n# Configuración\noptions(scipen = 999)  # Evitar notación científica\n\n\n\nOperaciones básicas\nR funciona como una calculadora avanzada:\n\n# Operaciones aritméticas\n5 + 3\n\n[1] 8\n\n10 - 2\n\n[1] 8\n\n4 * 6\n\n[1] 24\n\n20 / 4\n\n[1] 5\n\n2^3  # Potencia\n\n[1] 8\n\n# R respeta el orden de operaciones\n(5 + 3) * 2\n\n[1] 16\n\n\n\n\nCrear objetos\nEn R guardamos información en objetos usando &lt;-:\n\n# Crear un objeto numérico\nedad &lt;- 25\nedad\n## [1] 25\n\n# Crear un vector (secuencia de valores)\nedades &lt;- c(23, 25, 28, 30, 22, 27)\nedades\n## [1] 23 25 28 30 22 27\n\n# Operaciones con vectores\nmean(edades)    # Promedio\n## [1] 25.83333\nlength(edades)  # Largo del vector\n## [1] 6\n\n\n\n\n\n\n\nNota importante\n\n\n\nLos nombres de objetos:\n\nPueden contener letras, números, . y _\nNO pueden empezar con números\nR distingue entre mayúsculas y minúsculas (edad ≠ Edad), lo que se suele conocer como un lenguaje key-sensitive\n\n\n\n\nCrear objetos: vectores y matrices\nGuardar objetos también nos permite hacer operaciones matemáticas más complejas, por ejemplo para el uso de una calculadora de algebra lineal. También se pueden hacer simulaciones, con una distribución deseada, para hacer más interesante nuestras operaciones. Veamos primero la creación de objetos y luego operaciones más complejas\n\n\n# a) Creación de un vector de números naturales del 1 al 8\nvector1 &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 25, 44, 36, 20, 50, 88)\nvector1\n##  [1]  1  2  3  4  5  6  7  8  9 11 25 44 36 20 50 88\n\n# b) Creación de un vector con números reales comprendidos entre 1 y 6\nset.seed(123)\nvector2 &lt;- runif(60, 1, 6)\nvector2\n##  [1] 2.437888 4.941526 3.044885 5.415087 5.702336 1.227782 3.640527 5.462095\n##  [9] 3.757175 3.283074 5.784167 3.266671 4.387853 3.863167 1.514623 5.499125\n## [17] 2.230439 1.210298 2.639604 5.772518 5.447697 4.464017 4.202534 5.971349\n## [25] 4.278529 4.542652 3.720330 3.970710 2.445799 1.735568 5.815121 5.511495\n## [33] 4.453526 4.977337 1.123068 3.388980 4.792298 2.082040 2.590905 2.158129\n## [41] 1.714000 3.072732 3.068622 2.844227 1.762224 1.694030 2.165170 3.329812\n## [49] 2.329863 5.289139 1.229156 3.211000 4.994624 1.609496 3.804740 2.032657\n## [57] 1.637658 4.766539 5.475227 2.872314\n\n# c) Creación de un vector con números que provienen de una distribución normal\nvector3 &lt;- rnorm(30, 0, 2)\nvector3\n##  [1]  0.85292844 -0.59014297  1.79025132  1.75626698  1.64316216  1.37728051\n##  [7]  1.10783531 -0.12382342 -0.61192533 -0.76094200 -1.38941396 -0.41583456\n## [13] -2.53079270  4.33791193  2.41592400 -2.24621717 -0.80576967 -0.93331071\n## [19]  1.55993024 -0.16673813  0.50663703 -0.05709351 -0.08574091  2.73720457\n## [25] -0.45154197  3.03294121 -3.09750561  1.16922750  0.24770849  0.43188314\n\n# d) Creación de un vector con caracteres (letras)\nvector4 &lt;- c(\"Lima\", \"Ucayali\", \"Loreto\", \"San Juan\", \"Pucallpa\")\nvector4\n## [1] \"Lima\"     \"Ucayali\"  \"Loreto\"   \"San Juan\" \"Pucallpa\"\n\n# e) Creación de un vector que combine números y texto\nvector5 &lt;- c(\"rojo\", 3, \"Azul\", 7, \"morado\", 10)\nvector5\n## [1] \"rojo\"   \"3\"      \"Azul\"   \"7\"      \"morado\" \"10\"\n\n#OTRO CASOS CON VECTORES\n#a) Crea un vector con los primeros 20 números pares.\nvector1 &lt;- seq(2, 40, by = 2)\nvector1\n##  [1]  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40\n\n#b) Simular 50 valores entre 5 y 15, pero solo números enteros (valores repetidos).\nvector2 &lt;- sample(5:15, 50, replace = TRUE)\nvector2\n##  [1] 11  7 11 10 14  9  9 12  7 14  6 14  6 14 10  8  5 10  7 12  7 12  5 11 15\n## [26] 11 11 14 10 11 15 14  9 10 12  9 11 15  8  7 13 11 10 14 13 11  6  7 12  8\n\n# Simular 50 valores entre 5 y 150, pero solo números enteros (valores no repetidos).\nvector2 &lt;- sample(5:150, 50, replace = FALSE)\nvector2\n##  [1] 115  43   5  34  98  20  92  58  24 108  97  56 112  26  46  63  88  15 125\n## [20]  59  12  50  89 113  70 111  81 129  74  76  48  36  40  49  18 145  91  37\n## [39]  44 138  14  93 121  86  13  11 105  62  65  78\n# Crear un vector con categorías de satisfacción (Baja, Media, Alta) y conviértelo en \n#factor ordenado.\nvector3 &lt;- factor(sample(c(\"Baja\", \"Media\", \"Alta\"), 30, replace = TRUE), \n                  levels = c(\"Baja\", \"Media\", \"Alta\"), \n                  ordered = TRUE)\nvector3\n##  [1] Alta  Media Alta  Media Alta  Baja  Baja  Baja  Baja  Alta  Media Baja \n## [13] Media Baja  Alta  Alta  Baja  Media Alta  Baja  Alta  Media Baja  Baja \n## [25] Baja  Baja  Baja  Alta  Media Media\n## Levels: Baja &lt; Media &lt; Alta\n\n# Generar un vector con los primeros 15 valores de una progresión geométrica de razón 3.\nvector4 &lt;- 2*(3/11)^(0:14)\nvector4\n##  [1] 2.00000000000000 0.54545454545455 0.14876033057851 0.04057099924869\n##  [5] 0.01106481797691 0.00301767763007 0.00082300299002 0.00022445536091\n##  [9] 0.00006121509843 0.00001669502684 0.00000455318914 0.00000124177886\n## [13] 0.00000033866696 0.00000009236372 0.00000002519010\n\n# Generar 100 valores de un proceso AR(1):\n#Xt=0.7Xt-1+et donde et~N(0,1)\nset.seed(123)\nvector5 &lt;- numeric(100)\nvector5[1] &lt;- rnorm(1)\nfor (t in 2:100) {\n  vector5[t] &lt;- 0.7 * vector5[t-1] + rnorm(1)\n}\nvector5\n##   [1] -0.560475647 -0.622510442  1.122951005  0.856574095  0.728889601\n##   [6]  2.225287708  2.018617602  0.147971086 -0.583273091 -0.853953134\n##  [11]  0.626314604  0.798234050  0.959535285  0.782357416 -0.008190944\n##  [16]  1.781179476  1.744676112 -0.745343879  0.179615187 -0.347060777\n##  [21] -1.310766250 -1.135511290 -1.820862351 -2.003494875 -2.027485680\n##  [26] -3.105933287 -1.336366256 -0.782083262 -1.685595220  0.073898267\n##  [31]  0.478193008  0.039663623  0.922890197  1.524156625  1.888490719\n##  [36]  2.010583758  1.961326284  1.311016688  0.611749018  0.047753312\n##  [41] -0.661279661 -0.670813041 -1.734965480  0.954480129  1.876098089\n##  [46]  0.190160079 -0.269772780 -0.655496300  0.321117709  0.141413330\n##  [51]  0.352307845  0.218068736  0.109777658  1.445446645  0.786041666\n##  [56]  2.066699770 -0.102062965  0.513169674  0.483073016  0.554092680\n##  [61]  0.767504359  0.034929598 -0.308756665 -1.234705049 -1.936084761\n##  [66] -1.051730691 -0.288001705 -0.148596967  0.818249591  2.622859399\n##  [71]  1.344970414 -1.367689586  0.048355814 -0.675351693 -1.160754801\n##  [76]  0.213043009 -0.135642901 -1.315667743 -0.739663940 -0.656656121\n##  [81] -0.453895099  0.067553832 -0.323372349  0.418015904  0.072124571\n##  [86]  0.382269164  1.364427428  1.390280690  0.647264898  1.601893047\n##  [91]  2.114828989  2.028777252  1.658875811  0.533306992  1.733967343\n##  [96]  0.613517553  2.616795280  3.364367322  2.119356766  0.457128836\n\n#--Graficar la serie de tiempo\nplot.ts(vector5, col=\"#7F000D\", main=\"Proceso AR(1)\")\n\n\n\n\n\n\n\n\n¿Y si quisieramos operaciones con vectores? Hagamos un ejercicio. Sean los vectores \\(A\\) y \\(B\\), ambos con la misma cantidad de números aleatorios. El vector \\(A\\) contiene datos que provienen de una distribución chi-cuadrada con 3 grados de libertad (gl), mientras que el vector \\(B\\) contiene datos que provienen de una distribución uniforme definida en el intervalo \\([3, 5]\\). Entonces, hallemos con R la solución a los siguientes cálculos:\n\n\\(2A+5B\\)\n\\(\\sin(A)+\\cos(B)−\\tan(A+B)\\)\n\\(\\sqrt[3]{A} + \\exp(B) - 4B^2\\)\n\\(\\log(A+1)+B^3-10 \\sqrt{B}\\)\n\n\n# Definimos objetos para la creación de los objetos según instrucciones\nn=80\nA&lt;-rchisq(n,3) # Distribución Chi-Cuadrada con 3 gl\nB&lt;-runif(n,3,5) # Distribución uniforme [3,5]\n\n# Hallar los siguientes cálculos:\n#1) 2A+5B\nR1 &lt;- 2*A + 5*B\nR1\n##  [1] 19.69210 23.03420 26.69313 25.70334 28.35293 26.64890 24.68047 28.09814\n##  [9] 19.37783 27.30493 19.08945 26.21774 21.28977 21.04553 19.67761 29.61104\n## [17] 30.46180 22.50579 29.14007 28.82716 37.59187 23.24578 20.10291 26.05125\n## [25] 21.31597 28.21674 27.54909 28.87870 22.17543 26.48466 32.92355 22.76607\n## [33] 23.45849 19.91794 32.04690 22.38126 22.65389 34.35684 24.66019 21.24424\n## [41] 20.95409 24.56103 19.48345 32.42303 23.86838 27.14611 24.88628 25.74374\n## [49] 23.17346 36.48939 22.85570 29.78744 18.20893 27.98537 19.52830 24.42174\n## [57] 20.80129 25.62571 33.99841 20.50393 23.86187 24.03436 26.62792 30.83077\n## [65] 36.04283 17.73191 35.57557 28.77954 16.43000 25.45428 35.16100 26.46746\n## [73] 24.87297 23.24329 20.85788 22.64388 31.20013 19.58654 24.27057 19.14470\n\n#2) sin(A)+cos(B)−tan(A+B)\nR2 &lt;- sin(A) + cos(B) - tan(A + B)\nR2\n##  [1]  -3.69871781   0.52932773  -0.14649449   1.44602908   0.54403329\n##  [6]  -1.55641966  -1.55866936   0.99389017  -4.40833050  -2.08558457\n## [11] 128.22307375  -1.87754483  -0.05757828   0.73500217  -4.53203936\n## [16]  -0.27794495   0.18359820  -0.74062578  -2.06599699 -15.61964420\n## [21]   1.36081585  -1.65275479  -4.32443745   0.24815190  -8.00620676\n## [26]  -0.66222329  -0.68928017  -0.99627362   0.15563453   1.24336597\n## [31]  -1.17243861 -13.95459475  -1.81618294   2.53138309   0.83183601\n## [36]   1.51603274   1.42600605  -0.03628195   0.63919508   1.52939188\n## [41]   1.56304102   1.29568028  -3.20067386  -0.94459629  -2.91566325\n## [46]   0.52023905  -0.82360904   0.98140771   2.77398261   0.20811657\n## [51]   3.15124846  -1.54676948  -1.51491217  -2.06577654 -10.66771053\n## [56]   2.12058688   3.77380148   0.65734503  -1.12366287   1.03422297\n## [61]  -2.55867067   1.58528319  -4.20732464   0.99172732  -2.79511002\n## [66]  -1.75380189   1.05139758 -15.01869886  -1.04601754   2.21332123\n## [71]  -0.11138087  -0.59958851   1.09408425  20.66156069   6.44208116\n## [76]   0.71104716  -1.59454903   2.76693085  -0.76535693  -5.73788804\n\n#3) raiz_cúbica(A) + exp(B) - 4B^2\nR3 &lt;- A^(1/3) + exp(B) - 4*B^2\nR3\n##  [1] -14.255620 -12.110377 -14.713197  24.448582  40.082941  -4.685214\n##  [7] -13.257257  48.844148 -15.023519  -1.559712 -15.297013  -8.502851\n## [13] -15.042858 -15.122710 -14.516771  -3.273798   8.692007 -14.985719\n## [19]  25.424846   6.314224  12.115420 -14.949348 -13.220614   2.938968\n## [25]  -7.457513 -12.623203 -14.258828 -14.402407 -14.672829  28.812485\n## [31]  18.051722   9.275726 -14.927720 -15.235218  44.648938 -10.779485\n## [37]  -9.764369 -14.347868  -3.604389 -14.440643 -14.846226   4.307060\n## [43] -14.553812  17.838086 -14.830561  18.948512 -10.807368  10.826627\n## [49]   1.652100  -9.591720  -1.063778 -13.970162 -15.364066   5.902215\n## [55] -15.122612  17.489365 -14.008778   4.131836  36.721962 -15.157534\n## [61] -14.901083   3.105458 -10.625458  20.931845  44.227299 -15.332014\n## [67]  -9.074260   5.658878 -15.739576  47.537372 -13.786626 -14.475961\n## [73]   3.919048  13.808245 -13.182624 -12.680460 -13.551670 -15.134584\n## [79] -12.550918 -15.319228\n\n#4) log(A+1)+B^3-10raiz(B)\nR4 &lt;- log(A + 1) + B^3 - 10*sqrt(B)\nR4\n##  [1]  28.49843  35.54705  20.20142  84.47064  97.01486  51.37850  31.29607\n##  [8] 103.09007  23.84246  56.29000  16.25668  44.25693  16.14260  19.61268\n## [15]  27.11649  53.66290  69.41751  20.07700  85.58413  66.64177  73.27157\n## [22]  19.07572  32.60644  62.42528  46.62661  33.17041  25.32883  14.64705\n## [29]  24.48755  88.19187  79.11806  69.75788  19.55993  17.32759 100.53653\n## [36]  39.30442  41.70714  20.98362  53.15140  26.61957  23.86616  64.07605\n## [43]  27.05512  78.89942  16.14349  79.69590  38.98565  71.55383  60.66658\n## [50]  41.35389  56.95591  11.82915  22.39737  66.13017  22.62734  78.09871\n## [57]  29.10722  63.90620  94.87808  16.92526  18.02416  62.56160  39.31798\n## [64]  81.71854 100.42864  13.96516  42.61457  65.86200  14.40384 101.84851\n## [71]  26.66225  14.02985  63.61271  74.47058  32.46619  33.79005  28.79113\n## [78]  14.83907  33.95460  20.25958\n\n¡¡¿¿¿Y matrices??!! Podemos hacerlo de distintas maneras:\n\n# 1️⃣ Declaración de Matrices en R (Forma Manual))\nA &lt;- matrix(c(6,5,4,1.2,6,4,7,7,8,2.5,1.15,6,4,5,7,3), nrow=4, byrow=TRUE)\nA\n##      [,1] [,2] [,3] [,4]\n## [1,]    6  5.0 4.00  1.2\n## [2,]    6  4.0 7.00  7.0\n## [3,]    8  2.5 1.15  6.0\n## [4,]    4  5.0 7.00  3.0\n\nB &lt;- matrix(c(5, sqrt(7), exp(2), 7, -1/7, 6), nrow=2, byrow=TRUE)\nB\n##      [,1]       [,2]     [,3]\n## [1,]    5  2.6457513 7.389056\n## [2,]    7 -0.1428571 6.000000\n\n\n\n#2️⃣ Declaración de Matrices Aleatoriass\nA &lt;- matrix(rnorm(36), nrow=6)  # 6×6 con distribución normal estándar\nA\n##             [,1]        [,2]        [,3]       [,4]        [,5]       [,6]\n## [1,]  0.09049665 -1.53290200  1.54758106  0.9625280  0.07455118 -0.2656516\n## [2,]  1.59850877 -0.52111732 -0.13315096  0.6843094  0.42816676  0.1181445\n## [3,] -0.08856511 -0.48987045 -1.75652740 -1.3952743  0.02467498  0.1340386\n## [4,]  1.08079950  0.04715443 -0.38877986  0.8496430 -1.66747510  0.2210195\n## [5,]  0.63075412  1.30019868  0.08920722 -0.4465572  0.73649596  1.6408462\n## [6,] -0.11363990  2.29307897  0.84501300  0.1748027  0.38602657 -0.2190504\n\nB &lt;- matrix(runif(25, 7, 20), nrow=5)  # 5×5 con distribución uniforme en [7,20]\nB\n##          [,1]      [,2]      [,3]      [,4]      [,5]\n## [1,] 14.36754 11.782647 19.705986  8.563083 18.626350\n## [2,] 13.37082 18.361349 14.575617  8.148723  7.415631\n## [3,] 18.42276  8.967396 13.845671 18.449933 10.083986\n## [4,] 17.56708 10.663552  7.790169 13.608818 15.924375\n## [5,] 18.10330 15.667167 19.597505 11.387435  9.935640\n\nC &lt;- diag(rnorm(16,6,1.75), nrow=4)  # 4×4 con valores en la diagonal\nC\n##          [,1]     [,2]     [,3]     [,4]\n## [1,] 5.174153 0.000000 0.000000 0.000000\n## [2,] 0.000000 7.481793 0.000000 0.000000\n## [3,] 0.000000 0.000000 7.620099 0.000000\n## [4,] 0.000000 0.000000 0.000000 5.438546\n\n\nD &lt;- diag(1, nrow=5)  # Matriz identidad de orden 5\nD\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    0    0    0    0\n## [2,]    0    1    0    0    0\n## [3,]    0    0    1    0    0\n## [4,]    0    0    0    1    0\n## [5,]    0    0    0    0    1\n\nE &lt;- diag(0, nrow=5)  # Matriz nula de orden 5\nE\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    0    0    0    0    0\n## [2,]    0    0    0    0    0\n## [3,]    0    0    0    0    0\n## [4,]    0    0    0    0    0\n## [5,]    0    0    0    0    0\n\nG &lt;- diag(rnorm(5))  # Matriz diagonal\nG[upper.tri(G)] &lt;- rnorm(5)  # Convertir en matriz triangular superior\nG\n##          [,1]      [,2]       [,3]      [,4]       [,5]\n## [1,] -0.77225 0.3206011 -1.3697758 1.3855455 -1.3697758\n## [2,]  0.00000 0.6809156  0.2912297 0.1690452  0.2912297\n## [3,]  0.00000 0.0000000 -0.2075835 0.3206011  1.3855455\n## [4,]  0.00000 0.0000000  0.0000000 0.8374265  0.1690452\n## [5,]  0.00000 0.0000000  0.0000000 0.0000000 -0.2918737\n\nG &lt;- diag(rnorm(5))\nG[lower.tri(G)] &lt;- rnorm(5)  # Convertir en matriz triangular inferior\nG\n##             [,1]       [,2]        [,3]       [,4]      [,5]\n## [1,]  1.06892128  0.0000000  0.00000000  0.0000000 0.0000000\n## [2,] -1.43983706 -1.5858892  0.00000000  0.0000000 0.0000000\n## [3,] -1.00616615 -0.5739455 -0.38385009  0.0000000 0.0000000\n## [4,] -0.94035503 -1.4398371 -0.94035503  0.8648344 0.0000000\n## [5,]  0.05345133 -1.0061661  0.05345133 -0.5739455 0.5612503\n\nCon ello, podemos hacer las siguiente operaciones:\n\n#3️⃣ Transpuesta de una Matriz\nA &lt;- matrix(rnorm(36,3,0.2), nrow=9)\nA\n##           [,1]     [,2]     [,3]     [,4]\n##  [1,] 3.044110 2.784029 3.010454 2.600387\n##  [2,] 2.833097 3.041931 3.122176 3.229956\n##  [3,] 2.973929 2.739416 2.941241 3.287172\n##  [4,] 3.113466 2.926038 2.464057 2.904112\n##  [5,] 3.241693 2.871413 2.752431 3.457821\n##  [6,] 3.025444 3.218233 3.115314 2.392444\n##  [7,] 2.809718 3.067319 3.227178 2.791295\n##  [8,] 2.867497 2.937034 3.138828 3.049301\n##  [9,] 3.068919 2.964186 3.057314 3.014013\nt(A)  # Transpuesta\n##          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]\n## [1,] 3.044110 2.833097 2.973929 3.113466 3.241693 3.025444 2.809718 2.867497\n## [2,] 2.784029 3.041931 2.739416 2.926038 2.871413 3.218233 3.067319 2.937034\n## [3,] 3.010454 3.122176 2.941241 2.464057 2.752431 3.115314 3.227178 3.138828\n## [4,] 2.600387 3.229956 3.287172 2.904112 3.457821 2.392444 2.791295 3.049301\n##          [,9]\n## [1,] 3.068919\n## [2,] 2.964186\n## [3,] 3.057314\n## [4,] 3.014013\n\n#4️⃣ Traza de una Matriz\nA &lt;- matrix(rnorm(25), nrow=5)\nA\n##             [,1]        [,2]       [,3]        [,4]        [,5]\n## [1,] -1.48378791  1.21791351 -0.2216759 -0.23457505 -2.07988119\n## [2,]  1.63172709 -0.82832296  0.3945915  0.87279300  1.37395794\n## [3,] -0.67635833 -0.71812572  0.8894268  0.91333624  0.10681370\n## [4,] -1.46375788 -0.04448748  0.8687173  0.39722919 -0.02650367\n## [5,] -0.02547748 -1.06184814 -0.6720418 -0.09698557 -0.23364408\ntraza &lt;- sum(diag(A))\npaste(\"La traza es:\", traza)\n## [1] \"La traza es: -1.25909891680289\"\n\n\n#5️⃣ Suma de Matrices\nA &lt;- matrix(rnorm(30), nrow=6)\nB &lt;- matrix(rnorm(30,5,2), nrow=6)\nA + B  # Suma de matrices\n##          [,1]     [,2]     [,3]     [,4]      [,5]\n## [1,] 2.070677 5.674789 7.332295 5.819102 4.4218596\n## [2,] 6.797006 3.600217 5.282065 6.588906 5.2436218\n## [3,] 1.209273 6.333353 6.720439 4.798674 0.9434001\n## [4,] 3.167788 4.815598 2.326593 5.370866 2.3541586\n## [5,] 5.640490 4.864771 4.099813 5.846048 5.9530386\n## [6,] 2.535960 5.828734 7.136285 4.246691 8.3280428\n\n#6️⃣ Producto de un Escalar por una Matriz\nC &lt;- matrix(rnorm(40,6,1), nrow=8)\nsqrt(7) * C  # Producto con un escalar\n##          [,1]     [,2]     [,3]     [,4]     [,5]\n## [1,] 16.08303 16.51992 14.51782 16.33740 17.35173\n## [2,] 14.63379 13.22912 13.19817 12.72343 16.73229\n## [3,] 11.30045 18.89441 11.35979 15.73099 17.72055\n## [4,] 18.69264 10.62822 20.58891 11.41730 13.16903\n## [5,] 17.14521 15.80967 11.78878 14.24842 15.42931\n## [6,] 16.23830 15.32379 15.38026 16.84572 13.86509\n## [7,] 17.96189 13.26302 15.53936  9.37299 15.20537\n## [8,] 13.68626 14.79632 13.01599 15.33389 18.39506\n\nA &lt;- matrix(runif(42), nrow=7)\nB &lt;- matrix(runif(42,4,6), nrow=7)\nP &lt;- 2.35 * A + log(13) * B  # Combinación lineal de matrices\nP\n##          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]\n## [1,] 13.47663 14.25929 13.82812 15.09279 11.70540 14.59548\n## [2,] 16.20203 11.45008 13.54358 11.80367 16.62356 13.79231\n## [3,] 14.20694 16.52816 12.86935 12.91500 14.21301 13.11315\n## [4,] 13.24659 16.04601 13.68651 14.02032 14.93595 11.70117\n## [5,] 14.32942 14.05038 13.32676 12.03458 15.91931 12.76438\n## [6,] 11.88001 15.53602 13.05379 14.84587 15.30746 13.39807\n## [7,] 12.65452 15.92107 15.43912 14.99238 15.64276 13.27560\n\n#7️⃣ Multiplicación de Matrices\nA &lt;- matrix(runif(30,1,3), nrow=5)  # 5×6\nB &lt;- matrix(runif(30,2,9), nrow=6)  # 6×5\nA %*% B  # Producto de matrices\n##          [,1]     [,2]     [,3]     [,4]     [,5]\n## [1,] 54.75619 57.04299 58.38904 74.89661 63.80753\n## [2,] 53.03199 58.17523 48.83200 69.80488 62.63474\n## [3,] 64.24920 67.36303 54.95997 81.96668 71.76121\n## [4,] 69.21387 74.19012 57.16532 87.87814 74.00812\n## [5,] 61.88446 62.14712 57.98378 82.12525 65.21642\n(1/2*A) %*% (exp(3)*B)\n##          [,1]     [,2]     [,3]     [,4]     [,5]\n## [1,] 549.9038 572.8696 586.3876 752.1693 640.8042\n## [2,] 532.5880 584.2404 490.4084 701.0343 629.0262\n## [3,] 645.2398 676.5113 551.9503 823.1724 720.6812\n## [4,] 695.0989 745.0742 574.0981 882.5398 743.2464\n## [5,] 621.4913 624.1292 582.3177 824.7649 654.9534\n(1/17*B) %*% (4*A)\n##           [,1]      [,2]      [,3]     [,4]     [,5]     [,6]\n## [1,] 13.736128 14.181174 13.613064 17.96612 17.19283 17.89083\n## [2,]  9.578455  9.874332  9.587239 11.66554 12.11357 11.81713\n## [3,] 10.883822 10.379757 10.621954 12.39297 13.08647 13.44568\n## [4,] 12.453547 13.984342 12.046658 13.62633 15.72787 15.56274\n## [5,]  9.962515 10.687997  9.492623 10.90207 12.46591 12.55654\n## [6,] 12.510982 12.982812 12.958671 15.35784 15.21049 15.20145\n\n#8️⃣ Determinante de una Matriz\nA &lt;- matrix(runif(36,1,10), nrow=6)\nA\n##          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]\n## [1,] 4.648275 6.655643 9.270593 2.889983 1.652222 4.616325\n## [2,] 1.653687 3.954148 5.758889 4.382591 7.218909 6.837007\n## [3,] 9.583828 2.250185 4.347809 2.866289 3.582619 9.246752\n## [4,] 2.954654 9.231915 1.592275 5.133167 2.344712 2.949959\n## [5,] 4.650627 6.392044 8.689329 3.173520 9.751888 5.931990\n## [6,] 6.631015 7.746464 5.593702 2.068213 4.694630 7.480454\ndet(A)  # Determinante de la matriz\n## [1] 58219.58\n\n#9️⃣ Rango de una Matriz\nA &lt;- matrix(runif(25,10,36), nrow=5)\nA\n##          [,1]     [,2]     [,3]     [,4]     [,5]\n## [1,] 20.32840 27.65459 30.50027 21.68470 12.85484\n## [2,] 12.44404 32.52092 28.01576 29.92033 35.18232\n## [3,] 26.50731 30.79213 25.45110 10.67854 20.01516\n## [4,] 10.06445 13.50991 13.22030 15.07446 32.32338\n## [5,] 15.47360 20.07495 24.43203 32.91210 33.07200\nqr(A)$rank  # Rango de la matriz\n## [1] 5\n\n\nB &lt;- matrix(runif(28,9,100), nrow=7)\nB\n##          [,1]     [,2]     [,3]     [,4]\n## [1,] 53.50733 58.33913 43.77830 89.62371\n## [2,] 74.34635 46.90581 81.99863 95.83720\n## [3,] 53.29021 99.89832 27.01105 12.67465\n## [4,] 98.97251 32.26625 95.12238 53.91907\n## [5,] 14.89235 55.21669 40.45620 29.57180\n## [6,] 23.34731 16.18638 56.50657 87.15083\n## [7,] 80.46672 83.04382 19.16361 57.31515\nqr(B)$rank\n## [1] 4\n\n\n#🔟 Inversa de una Matriz\nA &lt;- matrix(runif(36,0,10), nrow=6)\nA\n##            [,1]      [,2]      [,3]      [,4]      [,5]      [,6]\n## [1,] 0.04638151 1.1067879 6.2490554 1.9071746 1.4377810 2.4872636\n## [2,] 2.77560080 7.0375381 4.4024185 7.2708647 8.6596708 6.1495395\n## [3,] 3.25203143 9.3902124 8.0134530 8.2669005 0.8256106 0.3175732\n## [4,] 5.88706277 3.1116902 2.7928381 5.1072108 2.4457068 1.4642354\n## [5,] 2.49684701 0.7849293 5.7071319 5.6772617 9.8154316 7.0307297\n## [6,] 0.43117281 3.2174409 0.4212801 0.0115582 5.7758128 0.6556071\ninv &lt;- solve(A)  # Inversa de la matriz\ninv\n##            [,1]        [,2]        [,3]        [,4]        [,5]        [,6]\n## [1,]  0.1635868  0.03138115 -0.14644118  0.29197919 -0.14467915  0.05539374\n## [2,]  0.1412754  0.19436903 -0.06953814  0.03911732 -0.23043826  0.05839836\n## [3,]  0.1668564 -0.10402786  0.02702846  0.01917559  0.02043062  0.06773001\n## [4,] -0.3841904 -0.13172257  0.23361634 -0.17602226  0.29240060 -0.16263677\n## [5,] -0.1351900 -0.14342385  0.07646570 -0.05553539  0.16740642  0.14991882\n## [6,]  0.2896546  0.35819487 -0.25756590  0.09604393 -0.26706783 -0.15914120\nround(A %*% inv)  # Verificación: debe aproximarse a la matriz identidad\n##      [,1] [,2] [,3] [,4] [,5] [,6]\n## [1,]    1    0    0    0    0    0\n## [2,]    0    1    0    0    0    0\n## [3,]    0    0    1    0    0    0\n## [4,]    0    0    0    1    0    0\n## [5,]    0    0    0    0    1    0\n## [6,]    0    0    0    0    0    1\n\nIncluso podríamos calcular MCO matricialmente1. Solo tendríamos que seguir la expresión que se obtiene al derivar los estimadores MCO con notación matricial, es decir, \\[\n\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y\n\\] donde nuestra variable dependiente es un vector-columna de \\(n\\times 1\\) dimensiones; los parámetros \\(\\beta\\) también son un vector columna \\(k+1\\times 1\\) dimensiones; las variables independientes son una matriz de \\(n\\times k+1\\) dimensiones; y los residuos del modelo son de \\(n\\times 1\\) dimensiones. De manera tal que se tiene \\[\nY_{n\\times 1} = \\begin{bmatrix}\nY_1 \\\\\nY_2 \\\\\n\\vdots \\\\\nY_n\n\\end{bmatrix}, \\quad\nX_{n\\times (k+1)} =\n\\begin{bmatrix}\n1 & X_{11} & a_{12} & \\cdots & a_{1k} \\\\\n1 & X_{21} & a_{22} & \\cdots & a_{2k} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & X_{n1} & a_{n2} & \\cdots & a_{nk}\n\\end{bmatrix},\n\\quad\n\\beta_{k+1\\times 1} =\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_k\n\\end{bmatrix},\n\\quad\nU_{n\\times 1} =\n\\begin{bmatrix}\nU_1 \\\\\nU_2 \\\\\n\\vdots \\\\\nU_n\n\\end{bmatrix}\n\\]\nSimulemos, entonces, un caso conocido: la ecuación de Mincer. Un ejemplo relativamente básico de esta sería el siguiente: \\[\n\\ln \\text{salario}_i = \\ln \\beta_0 + \\beta_1 \\text{educ}_i +\\beta_2 \\text{exp}_i+\\beta_3 \\text{exp}_i^2+ \\beta_4 \\text{dummy-mujer}_i + u_i\n\\] donde la variable dependiente es salario del individuo \\(i\\), a la cual se le aplica un logaritmo natural; \\(\\beta_0\\) es el intercepto (salario de alguien sin educación ni experiencia (ni mujer)); \\(\\text{educ}_i\\) es la variable que registra los años de escolaridad del individuo \\(i\\); \\(\\text{exp}_i\\) es la variable que contiene la experiencia laboral del individuo \\(i\\); \\(\\text{dummy-mujer}_i\\) es una variable que identifica si \\(i\\) es mujer o no; y \\(u_i\\) es el término de error. Veamos cómo podríamos hacer esto en R con una simulación:\n\n# MCO \"a mano\" (solo betas) + comparación con lm()\nset.seed(2025)\n\n# 1) Simulación tipo Mincer\nn &lt;- 1000\nesc   &lt;- pmax(0, round(rnorm(n, 12, 2)))\nexp   &lt;- pmax(0, round(rnorm(n, 15, 5)))\nmujer &lt;- rbinom(n, 1, 0.45)\n\nb0 &lt;- 1.5; b_esc &lt;- 0.08; b_exp &lt;- 0.10; b_exp2 &lt;- -0.002; b_muj &lt;- -0.20\neps &lt;- rnorm(n, 0, 0.30)\ny &lt;- b0 + b_esc*esc + b_exp*exp + b_exp2*(exp^2) + b_muj*mujer + eps  # log ingreso\n\n# 2) Matriz de diseño y vector\nX &lt;- cbind(1, esc, exp, exp^2, mujer) # Matriz X\ncolnames(X) &lt;- c(\"(Intercept)\", \"esc\", \"exp\", \"exp2\", \"mujer\")\n\n# 3) Betas por álgebra matricial:  β̂ = (X'X)^(-1) X'y\nbeta_hat &lt;- solve(t(X) %*% X) %*% (t(X) %*% y) \n\n# 4) Comparación con lm()\nbeta_lm &lt;- coef(lm(y ~ esc + exp + I(exp^2) + mujer))\n\n# 5) Mostrar lado a lado\nout &lt;- cbind(beta_manual = as.numeric(beta_hat), beta_lm = as.numeric(beta_lm))\nrownames(out) &lt;- colnames(X)\nround(out, 6)\n##             beta_manual   beta_lm\n## (Intercept)    1.497691  1.497691\n## esc            0.079347  0.079347\n## exp            0.104212  0.104212\n## exp2          -0.002206 -0.002206\n## mujer         -0.197648 -0.197648\n\n\n\n\nTipos de datos\nNo obstante, para todo ello, ¡hay que aprender R! Probablemente muchxs de ustedes ya saben algo de R. A su vez, si saben R pero no como derivar MCO no se preocupen, no es necesario saber esto para hacer una regresión en R. Es más, como vieron, lm() que es la función más básica para realizar regresiones lineales en R realiza la operación matricial que hicimos en una sola línea de código (lm(y ~ esc + exp + I(exp^2) + mujer)). Todo lo anterior, por tanto, fueron ejemplos de cosas que se pueden hacer en R, utilizándolo más “en bruto” y para que puedan visualizar su potencial.\nPero volvamos a R. Los objetos de R tienen distintas “clases”. Para efectos del curso, podemos pensar esto como la naturaleza de variables, i.e., como variables cuantitativas (discretas y continuas) y cualitativas (ordinales y nominales). Los objetos de R tienen categorías similares. Pero también tienen combinaciones, como los objetos dbl+lbl, que son numéricos y con etiquetas. Adicionalmente, también podemos encontrar datos de tipo lógico (TRUE y FALSE).\n\n# Numérico\nnumero &lt;- 42\nclass(numero)\n## [1] \"numeric\"\n\n# Carácter (texto)\nnombre &lt;- \"María\"\nclass(nombre)\n## [1] \"character\"\n\n# Lógico\nes_estudiante &lt;- TRUE\nclass(es_estudiante)\n## [1] \"logical\"\n\n# Factor (categorías)\nnivel_educacion &lt;- factor(c(\"Básica\", \"Media\", \"Superior\", \"Media\"))\nnivel_educacion\n## [1] Básica   Media    Superior Media   \n## Levels: Básica Media Superior"
  },
  {
    "objectID": "lectures/01-intro.html#trabajar-con-dataframes",
    "href": "lectures/01-intro.html#trabajar-con-dataframes",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "3. Trabajar con DataFrames",
    "text": "3. Trabajar con DataFrames\nLos dataframes son tablas de datos, similares a hojas de Excel. Cada columna es una variable, cada fila es una observación. Es en este formato en el que trabajaremos con bases de datos reales.\n\nCrear un dataframe\n\n# Crear un dataframe desde vectores\nestudiantes &lt;- data.frame(\n  nombre = c(\"Ana\", \"Bruno\", \"Carla\", \"Diego\", \"Elena\"),\n  edad = c(23, 25, 24, 26, 23),\n  carrera = c(\"Sociología\", \"Sociología\", \"Antropología\", \n              \"Sociología\", \"Antropología\"),\n  nota = c(6.5, 5.8, 6.9, 6.2, 7.0)\n)\n\n# Ver el dataframe\nestudiantes\n\n  nombre edad      carrera nota\n1    Ana   23   Sociología  6.5\n2  Bruno   25   Sociología  5.8\n3  Carla   24 Antropología  6.9\n4  Diego   26   Sociología  6.2\n5  Elena   23 Antropología  7.0\n\n\nPero partamos inmediatamente con bases de datos reales. Tomemos la Encuesta Nacional de Empleo, realizada por el INE mes a mes y que agrupa datos trimestrales. Para ello, utilizaremos la función read.csv(), del paquete utils, pues las bases de datos vienen en formato .csv. Una vez que cargamos los datos, exploraremos nuestra base de datos. No obstante, conviene saber antes que los archivos .csv son archivos de texto, que generalmente hay que especificar el delimitador que usa para separar las columnas (; o , comúnmente).\n\ndatos &lt;- read.csv(\"data-sesiones/ene-2025-07-jja.csv\", # Ruta\n                  sep=\",\", # Delimitador\n                  encoding = \"UTF-8\" # UTF-8 o Latin-1\n                  )\n\nhead(datos) # UPS\n\n                                                                                                                                                                                                                                                                                                                                                                                                                      ano_trimestre.mes_central.ano_encuesta.mes_encuesta.region.provincia.tipo.r_p_c.estrato.conglomerado.id_identificacion.hogar.idrph.nro_linea.proveedor.parentesco.sexo.edad.est_conyugal.mig1.mig2_cod.mig3_cod.mig4.mig5_cod.mig6_cod.nacionalidad.orig1. ...\n2025;7;2025;6;8;81;1;8111;8100212;35395;188791;1;853676467929;1;1;1;1;57;3;1;;;1;;;152;2;;;3;9;2;2;3;13;2;2;1;;1;;;;;;;7;2;;;2;;2;2;2;1;2;2;2;2;2;;1;1;;7;1;2;1;;88;2011;8;8111;1;2;2;;2;;;;1;1;2;0;;;;;2;2;2;2;2;2;;;;;8;5;40;;;;8;5;40;;;;;;2;;2;;;;;;;2;;;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;9;3;2;24;2;1;1;1;3;40;40;0;2;1;7;;0;;2;130                                                                                                                                                                                                                                                                                                                         126164801805\n2025;7;2025;6;8;81;1;8111;8100212;35395;188792;1;69857573301;2;0;4;1;23;2;1;;;1;;;152;2;;;4;4;1;2;4;8;1;2;1;;1;;;;;;;9;1;;2;;;;;;;;;;;;;2;;;19;1;1;5;;6;2024;8;8111;1;2;1;FACEBOOK;2;;;;;;;;2;;4;;2;2;2;2;2;2;;;;;8;4;32;;;;;;;;;;;;1;3;;;16;;3;5;15;1;1;2;1;0;0;0;1;0;0;0;0;0;0;0;;1;1;;;;;;;;3;;;;;;;;;;;;;;;;;2;3;2;24;2;1;1;1;2;32;35;0;2;2;19;;1;;2;120                                                                                                                                                                                                                                                                                                            770034305589\n2025;7;2025;6;8;81;1;8111;8100212;35395;188792;1;733202104071;4;1;1;2;54;2;1;;;1;;;152;2;;;5;5;1;2;5;9;1;2;1;;1;;;;;;;5;2;;;2;;1;1;1;1;1;1;88;1;2;;1;1;;7;2;9;1;;88;2010;8;8111;1;2;2;;2;;;;1;1;1;0;;;;;2;2;2;2;2;2;;;;;888;6;44;;;;888;6;44;;;;;;2;;2;;;;;;;2;;;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;8;3;2;25;2;1;1;1;3;44;44;0;1;1;7;;0;;2;117                                                                                                                                                                                                                                                                                                                     699995068579\n2025;7;2025;6;8;81;1;8111;8100212;35395;188792;1;974021027494;3;0;4;2;21;2;1;;;1;;;152;2;;;2;7;2;1;2;12;2;1;2;2;;;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;2;;;;;;;;;;;;;;;;;;;;;;;4;;;2;2;3;;1;12;2024;5;3;;;;;2;3;2;24;;3;9;15;0;;;;;;;0;;0;;120                                                                                                                                                                                                                                                                                                                                                                         145638363174\n2025;7;2025;6;8;81;1;8111;8100212;35395;188792;1;408193222712;1;0;3;1;55;2;2;7406;;1;;;152;2;;;2;4;2;2;2;8;2;2;2;2;;;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;2;;;;;;;;;;;;;;;;;;;;;;;22;NO PUDO RENOVAR LA LICENCIA DE CONDUCIR;;1;2;13;PARA RENOVAR LICENCIA DE CONDUCIR LE EXIGEN PAGAR LA PENSION DE ALIMENTOS;1;88;2024;1;1;6;;;;9;2;1;14;;3;9;28;0;;;;;;;0;;0;;130                                                                                                                                                                                                                                                   126164801805\n2025;7;2025;6;8;81;1;8111;8100212;35395;188793;1;439623161927;1;0;3;2;30;2;1;;;1;;;152;2;;;5;9;1;2;5;13;1;2;1;;1;;;;;;;2;2;;;1;;1;1;1;2;1;1;1;1;1;5;1;1;;16;5;;1;;9;2024;8;8111;1;2;2;;2;;;;1;1;1;0;;;;;1;2;2;2;2;2;;;;;888;5;36;;;;888;5;36;;;;;;2;;2;;;;2;2;4;1;1;1;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;4;4;4;46;2;1;1;1;4;36;36;0;1;1;16;;0;;1;141                                                                                                                                                                                                                                                                                                               845401035688\n\ndatos &lt;- read.csv(\"data-sesiones/ene-2025-07-jja.csv\", # Ruta\n                  sep=\";\", # Delimitador\n                  encoding = \"Latin-1\", # UTF-8 o Latin-1\n                  stringsAsFactors = F # character to factor\n                  ) \n\nhead(datos) # :D\n\n  ano_trimestre mes_central ano_encuesta mes_encuesta region provincia tipo\n1          2025           7         2025            6      8        81    1\n2          2025           7         2025            6      8        81    1\n3          2025           7         2025            6      8        81    1\n4          2025           7         2025            6      8        81    1\n5          2025           7         2025            6      8        81    1\n6          2025           7         2025            6      8        81    1\n  r_p_c estrato conglomerado id_identificacion hogar        idrph nro_linea\n1  8111 8100212        35395            188791     1 853676467929         1\n2  8111 8100212        35395            188792     1  69857573301         2\n3  8111 8100212        35395            188792     1 733202104071         4\n4  8111 8100212        35395            188792     1 974021027494         3\n5  8111 8100212        35395            188792     1 408193222712         1\n6  8111 8100212        35395            188793     1 439623161927         1\n  proveedor parentesco sexo edad est_conyugal mig1 mig2_cod mig3_cod mig4\n1         1          1    1   57            3    1       NA       NA    1\n2         0          4    1   23            2    1       NA       NA    1\n3         1          1    2   54            2    1       NA       NA    1\n4         0          4    2   21            2    1       NA       NA    1\n5         0          3    1   55            2    2     7406       NA    1\n6         0          3    2   30            2    1       NA       NA    1\n  mig5_cod mig6_cod nacionalidad orig1 orig2 orig3 curso nivel termino_nivel\n1       NA       NA          152     2    NA           3     9             2\n2       NA       NA          152     2    NA           4     4             1\n3       NA       NA          152     2    NA           5     5             1\n4       NA       NA          152     2    NA           2     7             2\n5       NA       NA          152     2    NA           2     4             2\n6       NA       NA          152     2    NA           5     9             1\n  estudia_actual edu1 edu2 edu3 edu4 a1 a2 a3 a4 a5 a6 a6_otro a7 a8 b1 b2 b3\n1              2    3   13    2    2  1 NA  1 NA NA NA         NA NA  7  2 NA\n2              2    4    8    1    2  1 NA  1 NA NA NA         NA NA  9  1 NA\n3              2    5    9    1    2  1 NA  1 NA NA NA         NA NA  5  2 NA\n4              1    2   12    2    1  2  2 NA NA  2 NA         NA NA NA NA NA\n5              2    2    8    2    2  2  2 NA NA  2 NA         NA NA NA NA NA\n6              2    5   13    1    2  1 NA  1 NA NA NA         NA NA  2  2 NA\n  b4 b5 b6 b7a_1 b7a_2 b7a_3 b7b_1 b7b_2 b7b_3 b7b_4 b8 b9 b10 b11_proxy b12\n1 NA  2 NA     2     2     2     1     2     2     2  2  2  NA         1   1\n2  2 NA NA    NA    NA    NA    NA    NA    NA    NA NA NA  NA         2  NA\n3 NA  2 NA     1     1     1     1     1     1    88  1  2  NA         1   1\n4 NA NA NA    NA    NA    NA    NA    NA    NA    NA NA NA  NA        NA  NA\n5 NA NA NA    NA    NA    NA    NA    NA    NA    NA NA NA  NA        NA  NA\n6 NA  1 NA     1     1     1     2     1     1     1  1  1   5         1   1\n  b13_rev4cl_caenes b14_rev4cl_caenes b15_1 b15_2 b16 b16_otro b17_mes b17_ano\n1                NA                 7     1     2   1               88    2011\n2                NA                19     1     1   5                6    2024\n3                NA                 7     2     9   1               88    2010\n4                NA                NA    NA    NA  NA               NA      NA\n5                NA                NA    NA    NA  NA               NA      NA\n6                NA                16     5    NA   1                9    2024\n  b18_region b18_codigo b18_varias ocup_honorarios plataformas_digitales\n1          8       8111          1               2                     2\n2          8       8111          1               2                     1\n3          8       8111          1               2                     2\n4         NA         NA         NA              NA                    NA\n5         NA         NA         NA              NA                    NA\n6          8       8111          1               2                     2\n  pd_especifique b19 dependencia_segunda sda_pd sda_pd_especifique i1 i2 i3\n1                  2                  NA     NA                     1  1  2\n2       FACEBOOK   2                  NA     NA                    NA NA NA\n3                  2                  NA     NA                     1  1  1\n4                 NA                  NA     NA                    NA NA NA\n5                 NA                  NA     NA                    NA NA NA\n6                  2                  NA     NA                     1  1  1\n  i3_v i4 i5 i6 i7 f7a f7b f7c f7d f7e turno turno_d turno_de turno_h turno_t\n1    0 NA NA NA NA   2   2   2   2   2     2      NA       NA      NA      NA\n2   NA  2 NA  4 NA   2   2   2   2   2     2      NA       NA      NA      NA\n3    0 NA NA NA NA   2   2   2   2   2     2      NA       NA      NA      NA\n4   NA NA NA NA NA  NA  NA  NA  NA  NA    NA      NA       NA      NA      NA\n5   NA NA NA NA NA  NA  NA  NA  NA  NA    NA      NA       NA      NA      NA\n6    0 NA NA NA NA   1   2   2   2   2     2      NA       NA      NA      NA\n  c2_1_1 c2_1_2 c2_1_3 c2_2_1 c2_2_2 c2_2_3 c3_1 c3_2 c3_3 turno_cont_d\n1      8      5     40     NA     NA     NA    8    5   40           NA\n2      8      4     32     NA     NA     NA   NA   NA   NA           NA\n3    888      6     44     NA     NA     NA  888    6   44           NA\n4     NA     NA     NA     NA     NA     NA   NA   NA   NA           NA\n5     NA     NA     NA     NA     NA     NA   NA   NA   NA           NA\n6    888      5     36     NA     NA     NA  888    5   36           NA\n  turno_cont_de turno_cont_h turno_cont_t c4 c5 c6 c7 c8 c9 c9_otro\n1            NA           NA           NA NA  2 NA  2 NA NA        \n2            NA           NA           NA NA  1  3 NA NA 16        \n3            NA           NA           NA NA  2 NA  2 NA NA        \n4            NA           NA           NA NA NA NA NA NA NA        \n5            NA           NA           NA NA NA NA NA NA NA        \n6            NA           NA           NA NA  2 NA  2 NA NA        \n  adicionales_h adicionales_d adicionales_t c10 c11 c12 e2 e3_1 e3_2 e3_3 e3_4\n1            NA            NA            NA   2  NA  NA  2   NA   NA   NA   NA\n2             3             5            15   1   1   2  1    0    0    0    1\n3            NA            NA            NA   2  NA  NA  2   NA   NA   NA   NA\n4            NA            NA            NA  NA  NA  NA  2   NA   NA   NA   NA\n5            NA            NA            NA  NA  NA  NA  2   NA   NA   NA   NA\n6             2             2             4   1   1   1  2   NA   NA   NA   NA\n  e3_5 e3_6 e3_7 e3_8 e3_9 e3_10 e3_11 e3_12 e3_total e4 e5 e5_dia e5_sem\n1   NA   NA   NA   NA   NA    NA    NA    NA       NA NA NA     NA     NA\n2    0    0    0    0    0     0     0    NA        1  1 NA     NA     NA\n3   NA   NA   NA   NA   NA    NA    NA    NA       NA NA NA     NA     NA\n4   NA   NA   NA   NA   NA    NA    NA    NA       NA NA NA     NA     NA\n5   NA   NA   NA   NA   NA    NA    NA    NA       NA NA NA     NA     NA\n6   NA   NA   NA   NA   NA    NA    NA    NA       NA NA NA     NA     NA\n  e5_mes e5_ano e6_mes e6_ano e7 e9                                 e9_otro e10\n1     NA     NA     NA     NA NA NA                                          NA\n2     NA     NA     NA     NA  3 NA                                          NA\n3     NA     NA     NA     NA NA NA                                          NA\n4     NA     NA     NA     NA NA  4                                          NA\n5     NA     NA     NA     NA NA 22 NO PUDO RENOVAR LA LICENCIA DE CONDUCIR  NA\n6     NA     NA     NA     NA NA NA                                          NA\n  deseo_trabajar e11 e12\n1             NA  NA  NA\n2             NA  NA  NA\n3             NA  NA  NA\n4              2   2   3\n5              1   2  13\n6             NA  NA  NA\n                                                                   e12_otro e13\n1                                                                            NA\n2                                                                            NA\n3                                                                            NA\n4                                                                             1\n5 PARA RENOVAR LICENCIA DE CONDUCIR LE EXIGEN PAGAR LA PENSION DE ALIMENTOS   1\n6                                                                            NA\n  e21_mes e21_ano e21_tramo e22 e23 e23_otro e24 e24_otro tramo_edad cine97\n1      NA      NA        NA  NA  NA           NA                   9      3\n2      NA      NA        NA  NA  NA           NA                   2      3\n3      NA      NA        NA  NA  NA           NA                   8      3\n4      12    2024         5   3  NA           NA                   2      3\n5      88    2024         1   1   6           NA                   9      2\n6      NA      NA        NA  NA  NA           NA                   4      4\n  cine11_1d cine11_2d ina_cal_edu activ cae_general cae_especifico\n1         2        24           2     1           1              1\n2         2        24           2     1           1              1\n3         2        25           2     1           1              1\n4         2        24          NA     3           9             15\n5         1        14          NA     3           9             28\n6         4        46           2     1           1              1\n  categoria_ocupacion habituales efectivas tpi ocup_form sector\n1                   3         40        40   0         2      1\n2                   2         32        35   0         2      2\n3                   3         44        44   0         1      1\n4                   0         NA        NA  NA        NA     NA\n5                   0         NA        NA  NA        NA     NA\n6                   4         36        36   0         1      1\n  r_p_rev4cl_caenes ftp obe id asocia         fact_cal\n1                 7  NA   0 NA      2 130,126164801805\n2                19  NA   1 NA      2 120,770034305589\n3                 7  NA   0 NA      2 117,699995068579\n4                NA   0  NA  0     NA 120,145638363174\n5                NA   0  NA  0     NA 130,126164801805\n6                16  NA   0 NA      1 141,845401035688\n\n\n\n\nExplorar datos\n\n# Estructura del dataframe\nstr(datos)\n## 'data.frame':    98600 obs. of  185 variables:\n##  $ ano_trimestre        : int  2025 2025 2025 2025 2025 2025 2025 2025 2025 2025 ...\n##  $ mes_central          : int  7 7 7 7 7 7 7 7 7 7 ...\n##  $ ano_encuesta         : int  2025 2025 2025 2025 2025 2025 2025 2025 2025 2025 ...\n##  $ mes_encuesta         : int  6 6 6 6 6 6 6 6 6 6 ...\n##  $ region               : int  8 8 8 8 8 8 8 8 8 8 ...\n##  $ provincia            : int  81 81 81 81 81 81 81 81 81 81 ...\n##  $ tipo                 : int  1 1 1 1 1 1 1 1 1 1 ...\n##  $ r_p_c                : int  8111 8111 8111 8111 8111 8111 8111 8111 8111 8111 ...\n##  $ estrato              : int  8100212 8100212 8100212 8100212 8100212 8100212 8100212 8100212 8100212 8100212 ...\n##  $ conglomerado         : int  35395 35395 35395 35395 35395 35395 35395 35395 35395 35395 ...\n##  $ id_identificacion    : int  188791 188792 188792 188792 188792 188793 188793 188794 188796 188796 ...\n##  $ hogar                : int  1 1 1 1 1 1 1 1 1 1 ...\n##  $ idrph                : num  853676467929 69857573301 733202104071 974021027494 408193222712 ...\n##  $ nro_linea            : int  1 2 4 3 1 1 2 1 4 1 ...\n##  $ proveedor            : int  1 0 1 0 0 0 1 1 1 0 ...\n##  $ parentesco           : int  1 4 1 4 3 3 1 1 1 2 ...\n##  $ sexo                 : int  1 1 2 2 1 2 1 2 1 2 ...\n##  $ edad                 : int  57 23 54 21 55 30 31 70 52 46 ...\n##  $ est_conyugal         : int  3 2 2 2 2 2 2 3 1 1 ...\n##  $ mig1                 : int  1 1 1 1 2 1 1 2 1 1 ...\n##  $ mig2_cod             : int  NA NA NA NA 7406 NA NA 13101 NA NA ...\n##  $ mig3_cod             : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ mig4                 : int  1 1 1 1 1 1 1 1 1 2 ...\n##  $ mig5_cod             : int  NA NA NA NA NA NA NA NA NA 8107 ...\n##  $ mig6_cod             : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ nacionalidad         : int  152 152 152 152 152 152 152 152 152 152 ...\n##  $ orig1                : int  2 2 2 2 2 2 2 2 2 2 ...\n##  $ orig2                : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ orig3                : chr  \"\" \"\" \"\" \"\" ...\n##  $ curso                : int  3 4 5 2 2 5 6 2 4 4 ...\n##  $ nivel                : int  9 4 5 7 4 9 9 4 4 5 ...\n##  $ termino_nivel        : int  2 1 1 2 2 1 1 2 1 1 ...\n##  $ estudia_actual       : int  2 2 2 1 2 2 2 2 2 2 ...\n##  $ edu1                 : int  3 4 5 2 2 5 6 2 4 4 ...\n##  $ edu2                 : int  13 8 9 12 8 13 13 8 8 9 ...\n##  $ edu3                 : int  2 1 1 2 2 1 1 2 1 1 ...\n##  $ edu4                 : int  2 2 2 1 2 2 2 2 2 2 ...\n##  $ a1                   : int  1 1 1 2 2 1 1 2 2 2 ...\n##  $ a2                   : int  NA NA NA 2 2 NA NA 2 2 2 ...\n##  $ a3                   : int  1 1 1 NA NA 1 1 NA NA NA ...\n##  $ a4                   : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ a5                   : int  NA NA NA 2 2 NA NA 2 1 2 ...\n##  $ a6                   : int  NA NA NA NA NA NA NA NA 2 NA ...\n##  $ a6_otro              : chr  \"\" \"\" \"\" \"\" ...\n##  $ a7                   : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ a8                   : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ b1                   : int  7 9 5 NA NA 2 2 NA 5 NA ...\n##  $ b2                   : int  2 1 2 NA NA 2 2 NA 2 NA ...\n##  $ b3                   : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ b4                   : int  NA 2 NA NA NA NA NA NA NA NA ...\n##  $ b5                   : int  2 NA 2 NA NA 1 1 NA 2 NA ...\n##  $ b6                   : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ b7a_1                : int  2 NA 1 NA NA 1 77 NA 1 NA ...\n##  $ b7a_2                : int  2 NA 1 NA NA 1 77 NA 1 NA ...\n##  $ b7a_3                : int  2 NA 1 NA NA 1 77 NA 1 NA ...\n##  $ b7b_1                : int  1 NA 1 NA NA 2 77 NA 1 NA ...\n##  $ b7b_2                : int  2 NA 1 NA NA 1 77 NA 1 NA ...\n##  $ b7b_3                : int  2 NA 1 NA NA 1 77 NA 1 NA ...\n##  $ b7b_4                : int  2 NA 88 NA NA 1 77 NA 2 NA ...\n##  $ b8                   : int  2 NA 1 NA NA 1 1 NA 1 NA ...\n##  $ b9                   : int  2 NA 2 NA NA 1 1 NA 2 NA ...\n##  $ b10                  : int  NA NA NA NA NA 5 4 NA NA NA ...\n##  $ b11_proxy            : int  1 2 1 NA NA 1 1 NA 1 NA ...\n##  $ b12                  : int  1 NA 1 NA NA 1 1 NA 1 NA ...\n##  $ b13_rev4cl_caenes    : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ b14_rev4cl_caenes    : int  7 19 7 NA NA 16 15 NA 11 NA ...\n##  $ b15_1                : int  1 1 2 NA NA 5 5 NA 5 NA ...\n##  $ b15_2                : int  2 1 9 NA NA NA NA NA NA NA ...\n##  $ b16                  : int  1 5 1 NA NA 1 5 NA 1 NA ...\n##  $ b16_otro             : chr  \"\" \"\" \"\" \"\" ...\n##  $ b17_mes              : int  88 6 88 NA NA 9 1 NA 4 NA ...\n##  $ b17_ano              : int  2011 2024 2010 NA NA 2024 2025 NA 2012 NA ...\n##  $ b18_region           : int  8 8 8 NA NA 8 8 NA 8 NA ...\n##  $ b18_codigo           : int  8111 8111 8111 NA NA 8111 8111 NA 8110 NA ...\n##  $ b18_varias           : int  1 1 1 NA NA 1 1 NA 1 NA ...\n##  $ ocup_honorarios      : int  2 2 2 NA NA 2 1 NA 2 NA ...\n##  $ plataformas_digitales: int  2 1 2 NA NA 2 2 NA 2 NA ...\n##  $ pd_especifique       : chr  \"\" \"FACEBOOK\" \"\" \"\" ...\n##  $ b19                  : int  2 2 2 NA NA 2 2 NA 2 NA ...\n##  $ dependencia_segunda  : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ sda_pd               : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ sda_pd_especifique   : chr  \"\" \"\" \"\" \"\" ...\n##  $ i1                   : int  1 NA 1 NA NA 1 1 NA 1 NA ...\n##  $ i2                   : int  1 NA 1 NA NA 1 1 NA 1 NA ...\n##  $ i3                   : int  2 NA 1 NA NA 1 1 NA 1 NA ...\n##  $ i3_v                 : int  0 NA 0 NA NA 0 0 NA 0 NA ...\n##  $ i4                   : int  NA 2 NA NA NA NA NA NA NA NA ...\n##  $ i5                   : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ i6                   : int  NA 4 NA NA NA NA NA NA NA NA ...\n##  $ i7                   : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ f7a                  : int  2 2 2 NA NA 1 2 NA 1 NA ...\n##  $ f7b                  : int  2 2 2 NA NA 2 2 NA 2 NA ...\n##  $ f7c                  : int  2 2 2 NA NA 2 2 NA 2 NA ...\n##  $ f7d                  : int  2 2 2 NA NA 2 2 NA 2 NA ...\n##  $ f7e                  : int  2 2 2 NA NA 2 2 NA 2 NA ...\n##  $ turno                : int  2 2 2 NA NA 2 2 NA 2 NA ...\n##  $ turno_d              : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ turno_de             : int  NA NA NA NA NA NA NA NA NA NA ...\n##  $ turno_h              : int  NA NA NA NA NA NA NA NA NA NA ...\n##   [list output truncated]\n\n# Estructura con glimpse\nglimpse(datos)\n## Rows: 98,600\n## Columns: 185\n## $ ano_trimestre         &lt;int&gt; 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, …\n## $ mes_central           &lt;int&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, …\n## $ ano_encuesta          &lt;int&gt; 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, …\n## $ mes_encuesta          &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, …\n## $ region                &lt;int&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, …\n## $ provincia             &lt;int&gt; 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, …\n## $ tipo                  &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n## $ r_p_c                 &lt;int&gt; 8111, 8111, 8111, 8111, 8111, 8111, 8111, 8111, …\n## $ estrato               &lt;int&gt; 8100212, 8100212, 8100212, 8100212, 8100212, 810…\n## $ conglomerado          &lt;int&gt; 35395, 35395, 35395, 35395, 35395, 35395, 35395,…\n## $ id_identificacion     &lt;int&gt; 188791, 188792, 188792, 188792, 188792, 188793, …\n## $ hogar                 &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n## $ idrph                 &lt;dbl&gt; 853676467929, 69857573301, 733202104071, 9740210…\n## $ nro_linea             &lt;int&gt; 1, 2, 4, 3, 1, 1, 2, 1, 4, 1, 3, 2, 1, 2, 1, 2, …\n## $ proveedor             &lt;int&gt; 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, …\n## $ parentesco            &lt;int&gt; 1, 4, 1, 4, 3, 3, 1, 1, 1, 2, 4, 4, 4, 1, 4, 1, …\n## $ sexo                  &lt;int&gt; 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, …\n## $ edad                  &lt;int&gt; 57, 23, 54, 21, 55, 30, 31, 70, 52, 46, 14, 19, …\n## $ est_conyugal          &lt;int&gt; 3, 2, 2, 2, 2, 2, 2, 3, 1, 1, 0, 3, 5, 4, 3, 6, …\n## $ mig1                  &lt;int&gt; 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, …\n## $ mig2_cod              &lt;int&gt; NA, NA, NA, NA, 7406, NA, NA, 13101, NA, NA, NA,…\n## $ mig3_cod              &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ mig4                  &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, …\n## $ mig5_cod              &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 8107, NA, NA…\n## $ mig6_cod              &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ nacionalidad          &lt;int&gt; 152, 152, 152, 152, 152, 152, 152, 152, 152, 152…\n## $ orig1                 &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n## $ orig2                 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ orig3                 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ curso                 &lt;int&gt; 3, 4, 5, 2, 2, 5, 6, 2, 4, 4, 8, 4, 4, 6, 3, 2, …\n## $ nivel                 &lt;int&gt; 9, 4, 5, 7, 4, 9, 9, 4, 4, 5, 3, 4, 4, 6, 9, 11,…\n## $ termino_nivel         &lt;int&gt; 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, …\n## $ estudia_actual        &lt;int&gt; 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, …\n## $ edu1                  &lt;int&gt; 3, 4, 5, 2, 2, 5, 6, 2, 4, 4, 8, 4, 4, 6, 3, 2, …\n## $ edu2                  &lt;int&gt; 13, 8, 9, 12, 8, 13, 13, 8, 8, 9, 6, 8, 8, 10, 1…\n## $ edu3                  &lt;int&gt; 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, …\n## $ edu4                  &lt;int&gt; 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, …\n## $ a1                    &lt;int&gt; 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, NA, 2, 2, 2, 1, 1,…\n## $ a2                    &lt;int&gt; NA, NA, NA, 2, 2, NA, NA, 2, 2, 2, NA, 2, 2, 2, …\n## $ a3                    &lt;int&gt; 1, 1, 1, NA, NA, 1, 1, NA, NA, NA, NA, NA, NA, N…\n## $ a4                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ a5                    &lt;int&gt; NA, NA, NA, 2, 2, NA, NA, 2, 1, 2, NA, 2, 2, 2, …\n## $ a6                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA, NA, N…\n## $ a6_otro               &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ a7                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ a8                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ b1                    &lt;int&gt; 7, 9, 5, NA, NA, 2, 2, NA, 5, NA, NA, NA, NA, NA…\n## $ b2                    &lt;int&gt; 2, 1, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ b3                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ b4                    &lt;int&gt; NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ b5                    &lt;int&gt; 2, NA, 2, NA, NA, 1, 1, NA, 2, NA, NA, NA, NA, N…\n## $ b6                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ b7a_1                 &lt;int&gt; 2, NA, 1, NA, NA, 1, 77, NA, 1, NA, NA, NA, NA, …\n## $ b7a_2                 &lt;int&gt; 2, NA, 1, NA, NA, 1, 77, NA, 1, NA, NA, NA, NA, …\n## $ b7a_3                 &lt;int&gt; 2, NA, 1, NA, NA, 1, 77, NA, 1, NA, NA, NA, NA, …\n## $ b7b_1                 &lt;int&gt; 1, NA, 1, NA, NA, 2, 77, NA, 1, NA, NA, NA, NA, …\n## $ b7b_2                 &lt;int&gt; 2, NA, 1, NA, NA, 1, 77, NA, 1, NA, NA, NA, NA, …\n## $ b7b_3                 &lt;int&gt; 2, NA, 1, NA, NA, 1, 77, NA, 1, NA, NA, NA, NA, …\n## $ b7b_4                 &lt;int&gt; 2, NA, 88, NA, NA, 1, 77, NA, 2, NA, NA, NA, NA,…\n## $ b8                    &lt;int&gt; 2, NA, 1, NA, NA, 1, 1, NA, 1, NA, NA, NA, NA, N…\n## $ b9                    &lt;int&gt; 2, NA, 2, NA, NA, 1, 1, NA, 2, NA, NA, NA, NA, N…\n## $ b10                   &lt;int&gt; NA, NA, NA, NA, NA, 5, 4, NA, NA, NA, NA, NA, NA…\n## $ b11_proxy             &lt;int&gt; 1, 2, 1, NA, NA, 1, 1, NA, 1, NA, NA, NA, NA, NA…\n## $ b12                   &lt;int&gt; 1, NA, 1, NA, NA, 1, 1, NA, 1, NA, NA, NA, NA, N…\n## $ b13_rev4cl_caenes     &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ b14_rev4cl_caenes     &lt;int&gt; 7, 19, 7, NA, NA, 16, 15, NA, 11, NA, NA, NA, NA…\n## $ b15_1                 &lt;int&gt; 1, 1, 2, NA, NA, 5, 5, NA, 5, NA, NA, NA, NA, NA…\n## $ b15_2                 &lt;int&gt; 2, 1, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n## $ b16                   &lt;int&gt; 1, 5, 1, NA, NA, 1, 5, NA, 1, NA, NA, NA, NA, NA…\n## $ b16_otro              &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ b17_mes               &lt;int&gt; 88, 6, 88, NA, NA, 9, 1, NA, 4, NA, NA, NA, NA, …\n## $ b17_ano               &lt;int&gt; 2011, 2024, 2010, NA, NA, 2024, 2025, NA, 2012, …\n## $ b18_region            &lt;int&gt; 8, 8, 8, NA, NA, 8, 8, NA, 8, NA, NA, NA, NA, NA…\n## $ b18_codigo            &lt;int&gt; 8111, 8111, 8111, NA, NA, 8111, 8111, NA, 8110, …\n## $ b18_varias            &lt;int&gt; 1, 1, 1, NA, NA, 1, 1, NA, 1, NA, NA, NA, NA, NA…\n## $ ocup_honorarios       &lt;int&gt; 2, 2, 2, NA, NA, 2, 1, NA, 2, NA, NA, NA, NA, NA…\n## $ plataformas_digitales &lt;int&gt; 2, 1, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ pd_especifique        &lt;chr&gt; \"\", \"FACEBOOK\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ b19                   &lt;int&gt; 2, 2, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ dependencia_segunda   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ sda_pd                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ sda_pd_especifique    &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ i1                    &lt;int&gt; 1, NA, 1, NA, NA, 1, 1, NA, 1, NA, NA, NA, NA, N…\n## $ i2                    &lt;int&gt; 1, NA, 1, NA, NA, 1, 1, NA, 1, NA, NA, NA, NA, N…\n## $ i3                    &lt;int&gt; 2, NA, 1, NA, NA, 1, 1, NA, 1, NA, NA, NA, NA, N…\n## $ i3_v                  &lt;int&gt; 0, NA, 0, NA, NA, 0, 0, NA, 0, NA, NA, NA, NA, N…\n## $ i4                    &lt;int&gt; NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ i5                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ i6                    &lt;int&gt; NA, 4, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ i7                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ f7a                   &lt;int&gt; 2, 2, 2, NA, NA, 1, 2, NA, 1, NA, NA, NA, NA, NA…\n## $ f7b                   &lt;int&gt; 2, 2, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ f7c                   &lt;int&gt; 2, 2, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ f7d                   &lt;int&gt; 2, 2, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ f7e                   &lt;int&gt; 2, 2, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ turno                 &lt;int&gt; 2, 2, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ turno_d               &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ turno_de              &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ turno_h               &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ turno_t               &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ c2_1_1                &lt;int&gt; 8, 8, 888, NA, NA, 888, 888, NA, 888, NA, NA, NA…\n## $ c2_1_2                &lt;int&gt; 5, 4, 6, NA, NA, 5, 5, NA, 5, NA, NA, NA, NA, NA…\n## $ c2_1_3                &lt;int&gt; 40, 32, 44, NA, NA, 36, 44, NA, 44, NA, NA, NA, …\n## $ c2_2_1                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ c2_2_2                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ c2_2_3                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ c3_1                  &lt;int&gt; 8, NA, 888, NA, NA, 888, 888, NA, 888, NA, NA, N…\n## $ c3_2                  &lt;int&gt; 5, NA, 6, NA, NA, 5, 5, NA, 5, NA, NA, NA, NA, N…\n## $ c3_3                  &lt;int&gt; 40, NA, 44, NA, NA, 36, 44, NA, 44, NA, NA, NA, …\n## $ turno_cont_d          &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ turno_cont_de         &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ turno_cont_h          &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ turno_cont_t          &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ c4                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ c5                    &lt;int&gt; 2, 1, 2, NA, NA, 2, 1, NA, 2, NA, NA, NA, NA, NA…\n## $ c6                    &lt;int&gt; NA, 3, NA, NA, NA, NA, 12, NA, NA, NA, NA, NA, N…\n## $ c7                    &lt;int&gt; 2, NA, 2, NA, NA, 2, NA, NA, 1, NA, NA, NA, NA, …\n## $ c8                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, 44, NA, NA, NA, …\n## $ c9                    &lt;int&gt; NA, 16, NA, NA, NA, NA, 13, NA, 3, NA, NA, NA, N…\n## $ c9_otro               &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ adicionales_h         &lt;int&gt; NA, 3, NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, NA…\n## $ adicionales_d         &lt;int&gt; NA, 5, NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, NA…\n## $ adicionales_t         &lt;int&gt; NA, 15, NA, NA, NA, 4, NA, NA, NA, NA, NA, NA, N…\n## $ c10                   &lt;int&gt; 2, 1, 2, NA, NA, 1, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ c11                   &lt;int&gt; NA, 1, NA, NA, NA, 1, NA, NA, NA, NA, NA, NA, NA…\n## $ c12                   &lt;int&gt; NA, 2, NA, NA, NA, 1, NA, NA, NA, NA, NA, NA, NA…\n## $ e2                    &lt;int&gt; 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, NA, 2, 2, 2, 1, 2,…\n## $ e3_1                  &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_2                  &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_3                  &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_4                  &lt;int&gt; NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_5                  &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_6                  &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_7                  &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_8                  &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_9                  &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_10                 &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_11                 &lt;int&gt; NA, 0, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e3_12                 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e3_total              &lt;int&gt; NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e4                    &lt;int&gt; NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e5                    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e5_dia                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e5_sem                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e5_mes                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e5_ano                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e6_mes                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e6_ano                &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e7                    &lt;int&gt; NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e9                    &lt;int&gt; NA, NA, NA, 4, 22, NA, NA, 15, NA, 17, NA, 4, 21…\n## $ e9_otro               &lt;chr&gt; \"\", \"\", \"\", \"\", \"NO PUDO RENOVAR LA LICENCIA DE …\n## $ e10                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ deseo_trabajar        &lt;int&gt; NA, NA, NA, 2, 1, NA, NA, 2, NA, 1, NA, 2, NA, 2…\n## $ e11                   &lt;int&gt; NA, NA, NA, 2, 2, NA, NA, 2, NA, 1, NA, 2, NA, 2…\n## $ e12                   &lt;int&gt; NA, NA, NA, 3, 13, NA, NA, 5, NA, NA, NA, 3, NA,…\n## $ e12_otro              &lt;chr&gt; \"\", \"\", \"\", \"\", \"PARA RENOVAR LICENCIA DE CONDUC…\n## $ e13                   &lt;int&gt; NA, NA, NA, 1, 1, NA, NA, 1, NA, 2, NA, 2, 1, 1,…\n## $ e21_mes               &lt;int&gt; NA, NA, NA, 12, 88, NA, NA, 2, NA, NA, NA, NA, 8…\n## $ e21_ano               &lt;int&gt; NA, NA, NA, 2024, 2024, NA, NA, 2025, NA, NA, NA…\n## $ e21_tramo             &lt;int&gt; NA, NA, NA, 5, 1, NA, NA, 1, NA, NA, NA, NA, 5, …\n## $ e22                   &lt;int&gt; NA, NA, NA, 3, 1, NA, NA, 3, NA, NA, NA, NA, 3, …\n## $ e23                   &lt;int&gt; NA, NA, NA, NA, 6, NA, NA, NA, NA, NA, NA, NA, N…\n## $ e23_otro              &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ e24                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ e24_otro              &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ tramo_edad            &lt;int&gt; 9, 2, 8, 2, 9, 4, 4, 12, 8, 7, NA, 1, 9, 12, 2, …\n## $ cine97                &lt;int&gt; 3, 3, 3, 3, 2, 4, 4, 2, 3, 3, 2, 3, 3, 3, 3, 5, …\n## $ cine11_1d             &lt;int&gt; 2, 2, 2, 2, 1, 4, 4, 1, 2, 2, 1, 2, 2, 2, 2, 5, …\n## $ cine11_2d             &lt;int&gt; 24, 24, 25, 24, 14, 46, 46, 14, 24, 25, 14, 24, …\n## $ ina_cal_edu           &lt;int&gt; 2, 2, 2, NA, NA, 2, 2, NA, 2, NA, NA, NA, NA, NA…\n## $ activ                 &lt;int&gt; 1, 1, 1, 3, 3, 1, 1, 3, 1, 3, NA, 3, 3, 3, 1, 1,…\n## $ cae_general           &lt;int&gt; 1, 1, 1, 9, 9, 1, 1, 9, 3, 8, 0, 9, 9, 9, 1, 1, …\n## $ cae_especifico        &lt;int&gt; 1, 1, 1, 15, 28, 1, 1, 19, 5, 26, 0, 15, 24, 17,…\n## $ categoria_ocupacion   &lt;int&gt; 3, 2, 3, 0, 0, 4, 4, 0, 3, 0, 0, 0, 0, 0, 3, 4, …\n## $ habituales            &lt;int&gt; 40, 32, 44, NA, NA, 36, 44, NA, 44, NA, NA, NA, …\n## $ efectivas             &lt;int&gt; 40, 35, 44, NA, NA, 36, 56, NA, 0, NA, NA, NA, N…\n## $ tpi                   &lt;int&gt; 0, 0, 0, NA, NA, 0, 0, NA, 0, NA, NA, NA, NA, NA…\n## $ ocup_form             &lt;int&gt; 2, 2, 1, NA, NA, 1, 2, NA, 1, NA, NA, NA, NA, NA…\n## $ sector                &lt;int&gt; 1, 2, 1, NA, NA, 1, 1, NA, 1, NA, NA, NA, NA, NA…\n## $ r_p_rev4cl_caenes     &lt;int&gt; 7, 19, 7, NA, NA, 16, 15, NA, 11, NA, NA, NA, NA…\n## $ ftp                   &lt;int&gt; NA, NA, NA, 0, 0, NA, NA, 0, NA, 1, NA, 0, 0, 0,…\n## $ obe                   &lt;int&gt; 0, 1, 0, NA, NA, 0, 0, NA, 0, NA, NA, NA, NA, NA…\n## $ id                    &lt;int&gt; NA, NA, NA, 0, 0, NA, NA, 0, NA, 0, NA, 0, 0, 0,…\n## $ asocia                &lt;int&gt; 2, 2, 2, NA, NA, 1, 2, NA, 1, NA, NA, NA, NA, NA…\n## $ fact_cal              &lt;chr&gt; \"130,126164801805\", \"120,770034305589\", \"117,699…\n\n# Dimensiones (filas x columnas)\ndim(datos)\n## [1] 98600   185\n\n\n\nExplorar variables\nEn el formato data.frame, las columnas son las variables y las filas son las observaciones, i.e., la información de cada persona encuestada para cada variable (columna). En este sentido, a través de la fila vemos lo que respondió cada informante en las preguntas que se les realizó en la determinada encuesta (o en las variables derivadas del cuestionario). Por ello, conviene revisar los manuales metodológicos, los libros de códigos, los cuestionarios, etc., de la encuesta que estemos usando. Para nuestro caso, revisando el Libro de Códigos de la ENE, podríamos revisar las siguientes variables:\n\n# Acceder a una columna específica con $\nestudiantes$edad\n## [1] 23 25 24 26 23\n\n# Otra forma: usando corchetes\nestudiantes[, \"edad\"]\n## [1] 23 25 24 26 23\n\n\n# Ahora con funciones de R y variables de la ENE \n# Condición de actividad (Ocupados (1), Desocupado (2) y Fuerza de la FDT (3))\nfrq(datos$activ) # Proporción de activ\n## x &lt;integer&gt; \n## # total N=98600 valid N=82671 mean=1.93 sd=0.97\n## \n## Value |     N | Raw % | Valid % | Cum. %\n## ----------------------------------------\n##     1 | 42467 | 43.07 |   51.37 |  51.37\n##     2 |  3918 |  3.97 |    4.74 |  56.11\n##     3 | 36286 | 36.80 |   43.89 | 100.00\n##  &lt;NA&gt; | 15929 | 16.16 |    &lt;NA&gt; |   &lt;NA&gt;\n\n# Clasificación Internacional de Nivel Educacional (CINE) 1997\nfrq(datos$cine97) # Proporción CINE 97\n## x &lt;integer&gt; \n## # total N=98600 valid N=98600 mean=2.34 sd=1.47\n## \n## Value |     N | Raw % | Valid % | Cum. %\n## ----------------------------------------\n##     0 | 19015 | 19.28 |   19.28 |  19.28\n##     1 |  7052 |  7.15 |    7.15 |  26.44\n##     2 | 18626 | 18.89 |   18.89 |  45.33\n##     3 | 32876 | 33.34 |   33.34 |  78.67\n##     4 | 19610 | 19.89 |   19.89 |  98.56\n##     5 |   972 |  0.99 |    0.99 |  99.54\n##     9 |   449 |  0.46 |    0.46 | 100.00\n##  &lt;NA&gt; |     0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n# Condición de actividad económica general\n## Ver categorias en documento\nfrq(datos$cae_general)\n## x &lt;integer&gt; \n## # total N=98600 valid N=98600 mean=3.91 sd=3.85\n## \n## Value |     N | Raw % | Valid % | Cum. %\n## ----------------------------------------\n##     0 | 15929 | 16.16 |   16.16 |  16.16\n##     1 | 38405 | 38.95 |   38.95 |  55.11\n##     2 |  1396 |  1.42 |    1.42 |  56.52\n##     3 |  2666 |  2.70 |    2.70 |  59.23\n##     4 |  3558 |  3.61 |    3.61 |  62.83\n##     5 |   360 |  0.37 |    0.37 |  63.20\n##     6 |   240 |  0.24 |    0.24 |  63.44\n##     7 |    40 |  0.04 |    0.04 |  63.48\n##     8 |  5442 |  5.52 |    5.52 |  69.00\n##     9 | 30564 | 31.00 |   31.00 | 100.00\n##  &lt;NA&gt; |     0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n\n\n\nTip: Rutas relativas\n\n\n\nUsa rutas relativas desde tu archivo .R: - ../data/archivo.csv (sube una carpeta, entra a data) - Nunca uses C:/Mi Computador/... (no funcionará en otros computadores)\n\n\nObviamente, como son muy astutxs, ya se estarán preguntando si se pueden hacer análisis más refinados. Ciertamente sí, y eso iremos viendo a lo largo del curso y también en esta sesión. Pero por poner un ejemplo, la ENE se utiliza para para calcular indicadores como la tasa de ocupación, desempleo, de participación, de ocupación informal, etc. Aunque aún no veremos cómo hacerlo estimando nuestra muestra a nivel poblacional (con muestras complejas (survey y srvyr)).\nLa ENE calcula la tasa de ocupación como \\[\n\\text{Tasa de ocupacion} = \\frac{\\text{Ocupados/as}}{\\text{Poblacion en edad de trabajar}} \\times 100\n\\] Como ya les parecerá obvio por su astucia, vimos una variable que nos permitiría cómo calcular esto: activ. Dado que 1. Ocupados/as, entonces, solo habría que\n\n## Tasa de ocupación muestral (sin survey)\n## Requiere en 'datos' las variables: activ (1=ocupado, 2/3=no (o sea PET)) y edad\n\n# 1) Variables auxiliares equivalentes a Stata\ndatos$oc    &lt;- ifelse(datos$activ == 1, 1, 0)        # ocupado\ndatos$may15 &lt;- ifelse(datos$edad  &gt;= 15, 1, 0)       # PET potencial (15+)\n\n# 2) Tasa de ocupación (toc)\ndatos$toc &lt;- ifelse(datos$may15 == 1, datos$oc, NA_real_)\n\n# 3) Estimación muestral de la tasa de ocupación (subpoblación edad&gt;=15)\nnumerador   &lt;- sum(datos$oc  [datos$may15 == 1 & !is.na(datos$activ)], na.rm = TRUE)\ndenominador &lt;- sum(          datos$may15 == 1 & !is.na(datos$activ))\ntoc_muestra &lt;- numerador / denominador\n\ntoc_muestra                    # proporción\n## [1] 0.5136868\ntoc_muestra * 100              # porcentaje\n## [1] 51.36868\n\nEsto significaría que, a nivel muestral, la tasa de ocupación es del 51,36%. Pero, antes de pasar un procesamiento más refinado de los datos, para justamente obtener indicadores y análisis estadísticos mejores, hay que mencionar que el código anterior podría estar mucho más optimizado. ¿Cómo? Con nuestro nuevo amigo que nos acompañará todo el curso: dplyr, paquete dentro de tidyverse. Con él, y sus funciones, podremos calcular la tasa de ocupación (muestral) con una línea de código concateando procesos con |&gt; (o %&gt;% que viene en magritrr, también paquete incluido en tidyverse):\n\ntoc_muestra &lt;- datos |&gt;\n  mutate(oc = activ == 1, # Creamos ocupado (oc) y mayores de 15 (may15)\n         may15 = edad &gt;= 15) |&gt;  \n  filter(may15, !is.na(activ)) |&gt;  # Filtramos mayores de 15 y sin NA en activ\n  summarise(toc = mean(oc)) |&gt; # Calculamos promedio de ocupados\n  pull(toc)   # Extraemos el valor numérico\n\ntoc_muestra          # Proporción\n## [1] 0.5136868\ntoc_muestra * 100    # Porcentaje\n## [1] 51.36868\n\nDicho esto, es momento de avanzar en nuestro análisis exploratorio de datos usando una base que nos permita profundizar en estadística descriptiva. Para ello, trabajaremos con la Encuesta Suplementaria de Ingresos (ESI), que es un módulo complementario de la ENE aplicado anualmente en el trimestre noviembre-enero."
  },
  {
    "objectID": "lectures/01-intro.html#trabajando-con-la-encuesta-suplementaria-de-ingresos-esi",
    "href": "lectures/01-intro.html#trabajando-con-la-encuesta-suplementaria-de-ingresos-esi",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "4. Trabajando con la Encuesta Suplementaria de Ingresos (ESI)",
    "text": "4. Trabajando con la Encuesta Suplementaria de Ingresos (ESI)\n\n¿Qué es la ESI?\nLa Encuesta Suplementaria de Ingresos (ESI) es un módulo de la ENE que se aplica una vez al año y tiene como objetivo principal caracterizar los ingresos de las personas y los hogares en Chile. Esta encuesta nos permite, entre otras cosas:\n\nAnalizar la distribución de ingresos en la población\nEstudiar brechas salariales por género, edad, nivel educacional\nExaminar la relación entre educación y ingresos\nComprender la estructura de ingresos laborales\n\nPara nuestros propósitos metodológicos, esta base es ideal porque contiene variables tanto cuantitativas (edad, ingresos) como cualitativas (sexo, nivel educacional, condición de actividad), lo que nos permitirá aplicar las distintas herramientas de estadística descriptiva que aprenderemos.\n\n\nCargando la base de datos\nCargaremos la ESI 2024 directamente desde el sitio web del INE. Usaremos el paquete haven para leer archivos en formato Stata (.dta):\n\n# Cargar la ESI 2024 desde el INE\nesi2024 &lt;- haven::read_dta(\"https://www.ine.gob.cl/docs/default-source/encuesta-suplementaria-de-ingresos/bbdd/stata_esi/2024/esi_2024.dta?sfvrsn=627c0f59_4&download=true\")\n\n# Explorar la estructura\nesi2024 |&gt; \n  glimpse()\n\nRows: 85,172\nColumns: 282\n$ ano_trimestre            &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 202…\n$ mes_central              &lt;dbl+lbl&gt; 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1…\n$ ano_encuesta             &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 202…\n$ mes_encuesta             &lt;dbl+lbl&gt; 10, 11, 11, 12, 10, 10, 10, 10, 10, 11, 1…\n$ region                   &lt;dbl+lbl&gt;  6, 13,  9,  5, 11, 13,  8,  4,  5,  3,  …\n$ provincia                &lt;dbl+lbl&gt;  61, 131,  91,  55, 111, 131,  81,  43,  …\n$ tipo                     &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1,…\n$ r_p_c                    &lt;dbl+lbl&gt;  6116, 13105,  9112,  5502, 11101, 13104,…\n$ estrato                  &lt;dbl&gt; 6100112, 13100412, 9100113, 5500112, 11100110…\n$ conglomerado             &lt;chr&gt; \"14368\", \"38039\", \"43839\", \"17334\", \"12672\", …\n$ id_identificacion        &lt;dbl&gt; 174594, 169149, 169426, 189147, 175247, 16651…\n$ hogar                    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, …\n$ idrph                    &lt;dbl&gt; 2938399, 5615533, 5841234, 5930196, 6201344, …\n$ nro_linea                &lt;dbl&gt; 1, 1, 3, 3, 7, 4, 2, 1, 2, 1, 1, 1, 2, 1, 1, …\n$ proveedor                &lt;dbl+lbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,…\n$ parentesco               &lt;dbl+lbl&gt;  3,  2,  1,  4, 10,  7,  4,  1,  6,  3,  …\n$ sexo                     &lt;dbl+lbl&gt; 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2,…\n$ edad                     &lt;dbl&gt; 60, 69, 54, 23, 22, 59, 17, 63, 16, 45, 39, 2…\n$ est_conyugal             &lt;dbl+lbl&gt; 2, 1, 2, 3, 3, 4, 3, 5, 3, 2, 1, 2, 3, 3,…\n$ mig1                     &lt;dbl+lbl&gt; 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1,…\n$ mig2_cod                 &lt;dbl+lbl&gt;    NA,    NA,    NA,    NA,    NA,    NA,…\n$ mig3_cod                 &lt;dbl+lbl&gt;  NA,  NA,  NA,  NA, 862,  NA,  NA,  NA,  …\n$ mig4                     &lt;dbl+lbl&gt; 2, 2, 2, 1, 3, 1, 1, 1, 1, 1, 2, 2, 3, 1,…\n$ mig5_cod                 &lt;dbl+lbl&gt;  9111, 13123,  9105,    NA,    NA,    NA,…\n$ mig6_cod                 &lt;dbl+lbl&gt;  NA,  NA,  NA,  NA, 862,  NA,  NA,  NA,  …\n$ nacionalidad             &lt;dbl+lbl&gt; 152, 152, 152, 152, 862, 152, 152, 152, 1…\n$ orig1                    &lt;dbl+lbl&gt; 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1,…\n$ orig2                    &lt;dbl+lbl&gt;  1, NA,  1, NA, NA, NA, NA, NA,  7,  7, N…\n$ orig3                    &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ curso                    &lt;dbl+lbl&gt; 5, 6, 4, 3, 4, 3, 3, 8, 1, 3, 2, 5, 6, 5,…\n$ nivel                    &lt;dbl+lbl&gt; 3, 9, 4, 9, 5, 4, 4, 3, 4, 8, 9, 9, 3, 9,…\n$ termino_nivel            &lt;dbl+lbl&gt;  2,  1,  1,  2,  1,  2,  2,  1,  2,  1,  …\n$ estudia_actual           &lt;dbl+lbl&gt; 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2,…\n$ edu1                     &lt;dbl+lbl&gt; 5, 6, 4, 3, 4, 3, 3, 8, 1, 3, 2, 5, 6, 5,…\n$ edu2                     &lt;dbl+lbl&gt;  6, 13,  8, 13,  9,  8,  8,  6,  8, 12, 1…\n$ edu3                     &lt;dbl+lbl&gt;  2,  1,  1,  2,  1,  2,  2,  1,  2,  1,  …\n$ edu4                     &lt;dbl+lbl&gt; 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2,…\n$ a1                       &lt;dbl+lbl&gt;  2,  2,  1,  2,  1,  2,  2,  1,  2,  1,  …\n$ a2                       &lt;dbl+lbl&gt;  2,  2, NA,  2, NA,  2,  2, NA,  2, NA,  …\n$ a3                       &lt;dbl+lbl&gt; NA, NA,  1, NA,  1, NA, NA,  1, NA,  1, N…\n$ a4                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ a5                       &lt;dbl+lbl&gt;  2,  2, NA,  2, NA,  2,  2, NA,  2, NA,  …\n$ a6                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ a6_otro                  &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ a7                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ a8                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ b1                       &lt;dbl+lbl&gt; NA, NA,  6, NA,  9, NA, NA,  6, NA,  5, N…\n$ b2                       &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  1, NA,  1, N…\n$ b3                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ b4                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  2, NA,  2, N…\n$ b5                       &lt;chr&gt; \".\", \".\", \"2\", \".\", \"2\", \".\", \".\", \".\", \".\", …\n$ b6                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ b7a_1                    &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ b7a_2                    &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ b7a_3                    &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ b7b_1                    &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ b7b_2                    &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ b7b_3                    &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ b7b_4                    &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ b8                       &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ b9                       &lt;dbl+lbl&gt; NA, NA,  2, NA,  1, NA, NA, NA, NA, NA, N…\n$ b10                      &lt;dbl+lbl&gt; NA, NA, NA, NA,  2, NA, NA, NA, NA, NA, N…\n$ b11_proxy                &lt;dbl+lbl&gt; NA, NA,  1, NA,  1, NA, NA,  2, NA,  2, N…\n$ b12                      &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ b13_rev4cl_caenes        &lt;dbl+lbl&gt; NA, NA, NA, NA,  6, NA, NA, NA, NA, NA, N…\n$ b14_rev4cl_caenes        &lt;dbl+lbl&gt; NA, NA, 19, NA,  6, NA, NA,  1, NA,  3, N…\n$ b15_1                    &lt;dbl+lbl&gt; NA, NA,  4, NA,  2, NA, NA,  1, NA,  1, N…\n$ b15_2                    &lt;dbl+lbl&gt; NA, NA, NA, NA,  5, NA, NA,  1, NA,  1, N…\n$ b16                      &lt;dbl+lbl&gt; NA, NA,  1, NA,  7, NA, NA,  4, NA,  3, N…\n$ b16_otro                 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ b17_mes                  &lt;dbl+lbl&gt; NA, NA,  1, NA,  4, NA, NA,  7, NA,  1, N…\n$ b17_ano                  &lt;dbl+lbl&gt;   NA,   NA, 2022,   NA, 2023,   NA,   NA,…\n$ b18_region               &lt;dbl+lbl&gt; NA, NA,  9, NA, 11, NA, NA,  4, NA,  3, N…\n$ b18_codigo               &lt;dbl+lbl&gt;    NA,    NA,  9101,    NA, 11402,    NA,…\n$ b18_varias               &lt;dbl+lbl&gt; NA, NA,  1, NA,  1, NA, NA,  1, NA,  1, N…\n$ ocup_honorarios          &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ plataformas_digitales    &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  1, N…\n$ pd_especifique           &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"FACEBOOK…\n$ b19                      &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ dependencia_segunda      &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ sda_pd                   &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ sda_pd_especifique       &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ i1                       &lt;dbl+lbl&gt; NA, NA,  1, NA,  1, NA, NA, NA, NA, NA, N…\n$ i2                       &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ i3                       &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA, NA, NA, NA, N…\n$ i3_v                     &lt;dbl+lbl&gt; NA, NA,  0, NA,  0, NA, NA, NA, NA, NA, N…\n$ i4                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  2, NA,  1, N…\n$ i5                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA,  2, N…\n$ i6                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  4, NA,  1, N…\n$ i7                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA,  1, N…\n$ f7a                      &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA,  2, NA,  2, N…\n$ f7b                      &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ f7c                      &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ f7d                      &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ f7e                      &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ turno                    &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ turno_d                  &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ turno_de                 &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ turno_h                  &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ turno_t                  &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ c2_1_1                   &lt;dbl+lbl&gt;  NA,  NA, 888,  NA,   8,  NA,  NA,   6,  …\n$ c2_1_2                   &lt;dbl+lbl&gt; NA, NA,  5, NA,  6, NA, NA,  7, NA,  6, N…\n$ c2_1_3                   &lt;dbl+lbl&gt; NA, NA, 44, NA, 48, NA, NA, 42, NA, 42, N…\n$ c2_2_1                   &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ c2_2_2                   &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ c2_2_3                   &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ c3_1                     &lt;dbl+lbl&gt;  NA,  NA, 888,  NA,   8,  NA,  NA,  NA,  …\n$ c3_2                     &lt;dbl+lbl&gt; NA, NA,  5, NA,  6, NA, NA, NA, NA, NA, N…\n$ c3_3                     &lt;dbl+lbl&gt; NA, NA, 44, NA, 48, NA, NA, NA, NA, NA, N…\n$ turno_cont_d             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ turno_cont_de            &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ turno_cont_h             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ turno_cont_t             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ c4                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ c5                       &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ c6                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ c7                       &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  1, N…\n$ c8                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA,  7, N…\n$ c9                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA,  1, N…\n$ c9_otro                  &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ adicionales_h            &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  4, NA,  3, N…\n$ adicionales_d            &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  7, NA,  5, N…\n$ adicionales_t            &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, 28, NA, 15, N…\n$ c10                      &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  1, NA,  1, N…\n$ c11                      &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  1, NA,  1, N…\n$ c12                      &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  1, NA,  2, N…\n$ e2                       &lt;dbl+lbl&gt;  2,  2,  2,  1,  2,  2,  2,  2,  2,  2,  …\n$ e3_1                     &lt;dbl+lbl&gt; NA, NA, NA,  1, NA, NA, NA, NA, NA, NA, N…\n$ e3_2                     &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_3                     &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_4                     &lt;dbl+lbl&gt; NA, NA, NA,  1, NA, NA, NA, NA, NA, NA,  …\n$ e3_5                     &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_6                     &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_7                     &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_8                     &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_9                     &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_10                    &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_11                    &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_12                    &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e3_total                 &lt;dbl&gt; NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, 1, NA,…\n$ e4                       &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ e5                       &lt;dbl+lbl&gt; NA, NA, NA,  1, NA, NA, NA, NA, NA, NA,  …\n$ e5_dia                   &lt;dbl+lbl&gt; NA, NA, NA, 20, NA, NA, NA, NA, NA, NA, 1…\n$ e5_sem                   &lt;dbl+lbl&gt; NA, NA, NA,  4, NA, NA, NA, NA, NA, NA,  …\n$ e5_mes                   &lt;dbl+lbl&gt; NA, NA, NA, 12, NA, NA, NA, NA, NA, NA, 1…\n$ e5_ano                   &lt;dbl+lbl&gt;   NA,   NA,   NA, 2024,   NA,   NA,   NA,…\n$ e6_mes                   &lt;dbl+lbl&gt; NA, NA, NA, 11, NA, NA, NA, NA, NA, NA, 1…\n$ e6_ano                   &lt;dbl+lbl&gt;   NA,   NA,   NA, 2024,   NA,   NA,   NA,…\n$ e7                       &lt;dbl+lbl&gt; NA, NA, NA,  2, NA, NA, NA, NA, NA, NA,  …\n$ e9                       &lt;dbl+lbl&gt;  3,  3, NA, NA, NA,  8,  4, NA,  4, NA, N…\n$ e9_otro                  &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ e10                      &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ deseo_trabajar           &lt;dbl+lbl&gt;  2,  2, NA, NA, NA,  2,  2, NA,  2, NA, N…\n$ e11                      &lt;dbl+lbl&gt;  2,  2, NA,  1, NA,  2,  2, NA,  2, NA,  …\n$ e12                      &lt;dbl+lbl&gt;  5,  4, NA, NA, NA,  8,  3, NA,  3, NA,  …\n$ e12_otro                 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ e13                      &lt;dbl+lbl&gt;  1,  1, NA,  2, NA,  1,  2, NA,  2, NA,  …\n$ e21_mes                  &lt;dbl+lbl&gt; 12, 99, NA, NA, NA, 12, NA, NA, NA, NA, 8…\n$ e21_ano                  &lt;dbl+lbl&gt; 2013, 2018,   NA,   NA,   NA, 2014,   NA,…\n$ e21_tramo                &lt;dbl+lbl&gt;  4,  3, NA, NA, NA,  4, NA, NA, NA, NA,  …\n$ e22                      &lt;dbl+lbl&gt;  3,  3, NA, NA, NA,  2, NA, NA, NA, NA,  …\n$ e23                      &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,  …\n$ e23_otro                 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ e24                      &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, 10, NA, NA, NA, NA, N…\n$ e24_otro                 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"PROBLEMAS CON EL ALCOHOL…\n$ tramo_edad               &lt;dbl+lbl&gt; 10, 11,  8,  2,  2,  9,  1, 10,  1,  7,  …\n$ cine97                   &lt;dbl+lbl&gt; 0, 4, 3, 3, 3, 2, 2, 2, 2, 4, 3, 4, 1, 4,…\n$ cine11_1d                &lt;dbl+lbl&gt; 0, 4, 2, 2, 2, 1, 1, 1, 1, 3, 2, 4, 1, 4,…\n$ cine11_2d                &lt;dbl+lbl&gt;  3, 46, 24, 24, 25, 14, 14, 14, 14, 35, 2…\n$ ina_cal_edu              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  3, N…\n$ activ                    &lt;dbl+lbl&gt;  3,  3,  1,  2,  1,  3,  3,  1,  3,  1,  …\n$ cae_general              &lt;dbl+lbl&gt; 9, 9, 1, 5, 1, 9, 9, 1, 9, 1, 7, 1, 1, 1,…\n$ cae_especifico           &lt;dbl+lbl&gt; 13, 13,  1,  9,  1, 21, 15,  1, 15,  1, 1…\n$ categoria_ocupacion      &lt;dbl+lbl&gt; 0, 0, 3, 0, 3, 0, 0, 2, 0, 2, 0, 2, 3, 3,…\n$ habituales               &lt;dbl+lbl&gt; NA, NA, 44, NA, 48, NA, NA, 42, NA, 42, N…\n$ efectivas                &lt;dbl+lbl&gt; NA, NA, 44, NA, 48, NA, NA, 42, NA, 35, N…\n$ tpi                      &lt;dbl+lbl&gt; NA, NA,  0, NA,  0, NA, NA,  0, NA,  0, N…\n$ ocup_form                &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA,  2, NA,  1, N…\n$ sector                   &lt;dbl+lbl&gt; NA, NA,  1, NA,  1, NA, NA,  2, NA,  1, N…\n$ r_p_rev4cl_caenes        &lt;dbl+lbl&gt; NA, NA, 19, NA,  6, NA, NA,  1, NA,  3, N…\n$ ftp                      &lt;dbl+lbl&gt;  0,  0, NA, NA, NA,  0,  0, NA,  0, NA,  …\n$ obe                      &lt;dbl+lbl&gt; NA, NA,  0, NA,  0, NA, NA,  0, NA,  0, N…\n$ id                       &lt;dbl+lbl&gt;  0,  0, NA, NA, NA,  0,  0, NA,  0, NA,  …\n$ asocia                   &lt;dbl+lbl&gt; NA, NA,  1, NA,  2, NA, NA,  2, NA,  2, N…\n$ fact_cal                 &lt;dbl&gt; 181.04995, 321.63792, 379.93380, 263.15276, 5…\n$ d1_opcion                &lt;dbl+lbl&gt; NA, NA,  1, NA,  1, NA, NA, NA, NA, NA, N…\n$ d1_opcionb               &lt;dbl+lbl&gt; NA, NA,  1, NA,  1, NA, NA, NA, NA, NA, N…\n$ d1_monto                 &lt;dbl&gt; NA, NA, 630000.0, NA, 504874.9, NA, NA, NA, N…\n$ d2_1_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d2_1_opcionb             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_1_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_1_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_1_opcionc             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_2_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d2_2_opcionb             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_2_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_2_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_2_opcionc             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_3_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d2_3_opcionb             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_3_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_3_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_3_opcionc             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_4_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d2_4_opcionb             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_4_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_4_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_4_opcionc             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_5_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d2_5_opcionb             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_5_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_5_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d2_5_opcionc             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_1_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  1, NA, NA, NA, NA, NA, N…\n$ d3_1_opcion2             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_1_monto               &lt;dbl&gt; NA, NA, NA, NA, 201950, NA, NA, NA, NA, NA, N…\n$ d3_1_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_2_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d3_2_opcion2             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_2_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_2_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_3_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d3_3_opcion2             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_3_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_3_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_4_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d3_4_opcion2             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_4_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_4_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_5_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d3_5_opcion2             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_5_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_5_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_6_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d3_6_opcion2             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_6_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_6_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_7_opcion              &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA, NA, NA, NA, N…\n$ d3_7_otro                &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ d3_7_opcion2             &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_7_monto               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d3_7_porcentaje          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d4_dias                  &lt;dbl+lbl&gt; NA, NA, 22, NA, 22, NA, NA, NA, NA, NA, N…\n$ d4_horas                 &lt;dbl+lbl&gt; NA, NA,  8, NA,  8, NA, NA, NA, NA, NA, N…\n$ d5_opcion                &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  1, NA,  1, N…\n$ d5_opcionb               &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  1, NA,  1, N…\n$ d5_monto                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 353412.5, NA, 120…\n$ d5_promedio              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1…\n$ d6_1_opcion              &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  2, NA,  1, N…\n$ d6_2_opcion              &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  2, NA,  2, N…\n$ d7_opcion                &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  1, NA,  2, N…\n$ d7_monto                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 7068.249, NA, NA,…\n$ d7_promedio              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d8_opcion                &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA,  1, NA,  2, N…\n$ d8_monto                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 201950, NA, NA, N…\n$ d9_opcion                &lt;dbl+lbl&gt; NA, NA,  2, NA,  2, NA, NA,  2, NA,  2, N…\n$ d9_monto                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d9_promedio              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d9_opcionb               &lt;dbl+lbl&gt;  2,  2, NA,  2, NA,  2,  2, NA,  2, NA,  …\n$ d9_montob                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ d9_promediob             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fact_cal_esi             &lt;dbl&gt; 218.58396, 354.06516, 380.26878, 273.40298, 4…\n$ imp_d1_monto             &lt;dbl+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ imp_d4                   &lt;dbl+lbl&gt; NA, NA,  0, NA,  0, NA, NA, NA, NA, NA, N…\n$ imp_d5_monto             &lt;dbl+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ss_t                     &lt;dbl&gt; 0.0, 0.0, 630000.0, 0.0, 504874.9, 0.0, 0.0, …\n$ svar_t                   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ reg_t                    &lt;dbl&gt; 0, 0, 0, 0, 201950, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ gan_t                    &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 353412.5, …\n$ autoconsumo_t            &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.0…\n$ ahorroimp_t              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 201950, 0, 0, 0, 0, 0, 0…\n$ ing_ot                   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ing_t_d                  &lt;dbl&gt; 0.0, 0.0, 630000.0, 0.0, 706824.9, 0.0, 0.0, …\n$ ing_t_i                  &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 360480.7, …\n$ ing_t_i_ai               &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 158530.7, …\n$ ing_t_p                  &lt;dbl&gt; 0.0, 0.0, 630000.0, 0.0, 706824.9, 0.0, 0.0, …\n$ ing_t_t                  &lt;dbl&gt; 0.0, 0.0, 630000.0, 0.0, 706824.9, 0.0, 0.0, …\n$ ing_t_t_ai               &lt;dbl&gt; 0.0, 0.0, 630000.0, 0.0, 706824.9, 0.0, 0.0, …\n$ ocup_ref                 &lt;dbl+lbl&gt; NA, NA,  1, NA,  1, NA, NA,  1, NA,  1, N…\n$ tim                      &lt;dbl+lbl&gt; 1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 2, 2,…\n$ conglomerado_correlativo &lt;dbl&gt; 621, 4034, 4815, 1075, 375, 1601, 3729, 457, …\n$ id_mediana               &lt;dbl&gt; 54895, 69967, 71649, 63052, 3402, 77423, 4659…\n\n\nComo pueden observar, la base contiene 85.172 observaciones y 282 variables. Para este ejercicio, trabajaremos con un subconjunto de variables que nos permitirán realizar análisis descriptivos básicos.\n\n\nSelección y preparación de variables\nPara facilitar nuestro trabajo, seleccionaremos y renombraremos algunas variables clave. Adicionalmente, filtraremos la base de datos para observaciones que cumplan con 1) estar ocupados y 2) tener ingreso totales del trabajo. Finalmente, re-escribiremos sobre la base de datos, algo que no es recomendable, pero dado que no volveremos a usar esi2024 no habrá problemas en este caso.\n\n# Seleccionar y preparar variables de interés\nesi2024 &lt;- esi2024 |&gt; \n  select(\n    sexo,           # Sexo de la persona\n    edad,           # Edad en años cumplidos\n    nivel,          # Nivel educacional más alto alcanzado\n    ing_t_t,        # Ingreso total del trabajo\n    activ,          # Condición de actividad\n    region          # Región de residencia\n  ) |&gt; \n  # Filtrar solo personas ocupadas con ingresos válidos\n  filter(\n    activ == 1,           # Solo ocupados\n    !is.na(ing_t_t),      # Con dato de ingreso\n    ing_t_t &gt; 0           # Ingresos positivos\n  ) |&gt; \n  # Crear etiquetas descriptivas\n  mutate(\n    # Etiqueta para sexo\n    sexo_etiq = case_when(\n      sexo == 1 ~ \"Hombre\",\n      sexo == 2 ~ \"Mujer\",\n      TRUE ~ \"Otro\"\n    ),\n    # Recodificar nivel educacional en categorías agregadas\n    nivel_etiq = case_when(\n      nivel == 0 ~ \"Sin educación\",\n      nivel %in% c(1, 2, 3) ~ \"Secundaria incompleta\",\n      nivel %in% c(4, 5, 6) ~ \"Secundaria completa\",\n      nivel %in% c(7, 8, 9) ~ \"Superior\",\n      nivel %in% c(10, 11, 12) ~ \"Postgrado\",\n      TRUE ~ \"Otros\"\n    ),\n    nivel_etiq = factor(nivel_etiq, levels = c(\n      \"Sin educación\", \"Secundaria incompleta\", \"Secundaria completa\",\n      \"Superior\", \"Postgrado\", \"Otros\"\n    ))\n  )\n\n# Verificar dimensiones de la base filtrada\ndim(esi2024)\n\n[1] 34827     8\n\n\n\n\n\n\n\n\nNota sobre el filtrado\n\n\n\nHemos filtrado la base para trabajar solo con personas ocupadas (activ == 1) que reportan ingresos del trabajo válidos. Esto es importante porque:\n\nLos ingresos del trabajo solo aplican a personas que trabajan\nLos valores NA o cero en ingresos podrían indicar no respuesta o situaciones especiales\nPara análisis de brechas salariales, necesitamos comparar personas que efectivamente están en el mercado laboral"
  },
  {
    "objectID": "lectures/01-intro.html#estadística-descriptiva-medidas-de-tendencia-central",
    "href": "lectures/01-intro.html#estadística-descriptiva-medidas-de-tendencia-central",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "5. Estadística Descriptiva: Medidas de Tendencia Central",
    "text": "5. Estadística Descriptiva: Medidas de Tendencia Central\nLa estadística descriptiva nos permite resumir y organizar grandes volúmenes de datos en medidas que facilitan su comprensión. Comenzaremos con las medidas de tendencia central, que nos indican dónde se “centra” la distribución de nuestros datos.\n\n5.1 La Media (Promedio)\nLa media aritmética es la medida de tendencia central más utilizada. Se calcula sumando todos los valores y dividiendo por el número de observaciones:\n\\[\n\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n\\]\nEn R, la función mean() nos permite calcularla fácilmente:\n\n# Ingreso promedio mensual\ningreso_promedio &lt;- mean(esi2024$ing_t_t, na.rm = TRUE)\n\n# Mostrar con formato\npaste(\"El ingreso promedio mensual es:\", \n      scales::dollar(ingreso_promedio, big.mark = \".\", \n                     decimal.mark = \",\", prefix = \"$\"))\n\n[1] \"El ingreso promedio mensual es: $774.622\"\n\n\nLa media es útil porque usa toda la información disponible (cada observación contribuye al cálculo). Sin embargo, tiene una limitación importante: es sensible a valores extremos (outliers).\n\n\n5.2 La Mediana\nLa mediana es el valor que divide la distribución en dos mitades iguales: 50% de las observaciones están por debajo y 50% por encima. Es más robusta a valores extremos que la media.\n\n# Ingreso mediano mensual\ningreso_mediano &lt;- median(esi2024$ing_t_t, na.rm = TRUE)\n\npaste(\"El ingreso mediano mensual es:\", \n      scales::dollar(ingreso_mediano, big.mark = \".\", \n                     decimal.mark = \",\", prefix = \"$\"))\n\n[1] \"El ingreso mediano mensual es: $575.557\"\n\n\n\n\n5.3 Comparación: Media vs Mediana\nComparemos ambas medidas:\n\n# Crear tabla comparativa\ntibble(\n  Medida = c(\"Media\", \"Mediana\", \"Diferencia\", \"% Diferencia\"),\n  Valor = c(\n    scales::dollar(ingreso_promedio, big.mark = \".\", \n                   decimal.mark = \",\", prefix = \"$\"),\n    scales::dollar(ingreso_mediano, big.mark = \".\", \n                   decimal.mark = \",\", prefix = \"$\"),\n    scales::dollar(ingreso_promedio - ingreso_mediano, \n                   big.mark = \".\", decimal.mark = \",\", \n                   prefix = \"$\"),\n    paste0(round(((ingreso_promedio - ingreso_mediano)/ingreso_mediano)*100, \n                 1), \"%\")\n  )\n) |&gt; \n  kable(caption = \"Comparación entre media y mediana de ingresos\")\n\n\nComparación entre media y mediana de ingresos\n\n\nMedida\nValor\n\n\n\n\nMedia\n$774.622\n\n\nMediana\n$575.557\n\n\nDiferencia\n$199.065\n\n\n% Diferencia\n34.6%\n\n\n\n\n\nInterpretación: La diferencia entre media y mediana nos indica que la distribución de ingresos está sesgada hacia la derecha (positivamente). Esto significa que hay algunas personas con ingresos muy altos que “arrastran” la media hacia arriba, mientras que la mediana nos da una mejor idea del ingreso “típico” de una persona en Chile. En cualquier caso, conviene comparar ambas medidas, pues nos entrega información sobre la distribución de nuestra variable.\n\n\n\n\n\n\n¿Cuándo usar media o mediana?\n\n\n\n\nUsa la media cuando:\n\nLa distribución es aproximadamente simétrica\nNo hay valores extremos (outliers)\nNecesitas usar toda la información disponible (ej: calcular promedios)\n\nUsa la mediana cuando:\n\nLa distribución tiene sesgo (asimétrica)\nHay valores extremos que pueden distorsionar la media\nQuieres saber el valor “típico” (ej: salario mediano)\n\n\n\n\nEn la siguiente sesión veremos más medidas títpicas de la estadística descriptiva. Pero, por ahora, quedemonos con estas dos y veamos qué podemos hacer con ellas en R.\n\n\n5.4 Visualizando media y mediana\nUn histograma nos ayuda a visualizar esta diferencia:\n\n# Crear histograma con líneas de tendencia central\nesi2024 |&gt; \n  ggplot(aes(x = ing_t_t)) +\n  geom_histogram(bins = 50, fill = \"#2A5783\", alpha = 0.7, color = \"white\") +\n  geom_vline(aes(xintercept = ingreso_promedio, color = \"Media\"), \n             linewidth = 1.2, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = ingreso_mediano, color = \"Mediana\"), \n             linewidth = 1.2, linetype = \"dashed\") +\n  scale_x_continuous(\n    labels = scales::dollar_format(big.mark = \".\", decimal.mark = \",\", prefix = \"$\"),\n    limits = c(0, 3000000)  # Limitar eje x para mejor visualización\n  ) +\n  scale_color_manual(\n    name = \"Medidas de\\ntendencia central\",\n    values = c(\"Media\" = \"#9C0824\", \"Mediana\" = \"#09622A\")\n  ) +\n  labs(\n    title = \"Distribución de Ingresos del Trabajo en Chile (ESI 2024)\",\n    subtitle = \"Solo personas ocupadas con ingresos reportados\",\n    x = \"Ingreso mensual del trabajo\",\n    y = \"Frecuencia (número de personas)\",\n    caption = \"Fuente: INE, Encuesta Suplementaria de Ingresos 2024\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    legend.position = \"right\"\n  )\n\n\n\n\n\n\n\nFigure 1: Distribución de ingresos del trabajo con media y mediana\n\n\n\n\n\nObservaciones del gráfico: - La mayoría de las personas se concentra en ingresos más bajos - La distribución tiene una “cola” hacia la derecha (ingresos altos) - La mediana (línea verde) está más cerca del centro de la concentración de personas - La media (línea roja) está desplazada hacia la derecha por efecto de los ingresos altos"
  },
  {
    "objectID": "lectures/01-intro.html#análisis-por-grupos-estadística-descriptiva-bivariada",
    "href": "lectures/01-intro.html#análisis-por-grupos-estadística-descriptiva-bivariada",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "6. Análisis por grupos: Estadística descriptiva bivariada",
    "text": "6. Análisis por grupos: Estadística descriptiva bivariada\nUna de las aplicaciones más útiles de la estadística descriptiva es comparar grupos. Por ejemplo, ¿existen diferencias en los ingresos según el sexo de las personas? ¿O según su nivel educacional?\n\n6.1 Ingresos por sexo\nCalculemos las medidas de tendencia central separadas por sexo:\n\n# Estadísticas por sexo\nesi2024 |&gt; \n  group_by(sexo_etiq) |&gt; \n  summarise(\n    n = n(),\n    Media = mean(ing_t_t, na.rm = TRUE),\n    Mediana = median(ing_t_t, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    Media = scales::dollar(Media, big.mark = \".\", \n                           decimal.mark = \",\", prefix = \"$\"),\n    Mediana = scales::dollar(Mediana, big.mark = \".\", decimal.mark = \",\", prefix = \"$\")\n  ) |&gt; \n  kable(\n    caption = \"Ingresos del trabajo por sexo\",\n    col.names = c(\"Sexo\", \"N\", \"Ingreso Promedio\", \"Ingreso Mediano\")\n  )\n\n\nIngresos del trabajo por sexo\n\n\nSexo\nN\nIngreso Promedio\nIngreso Mediano\n\n\n\n\nHombre\n19344\n$857.137\n$600.000\n\n\nMujer\n15483\n$671.531\n$504.875\n\n\n\n\n\n\n\n\n\n\n\nBrecha salarial de género\n\n\n\nLos datos muestran una diferencia significativa en los ingresos entre hombres y mujeres. Esta es la llamada brecha salarial de género, un fenómeno persistente en Chile y el mundo que tiene múltiples causas (segregación ocupacional, discriminación, interrupciones en trayectorias laborales, etc.).\n\n\n\n\n6.2 Visualización de la brecha\nPodemos visualizar esta diferencia con un boxplot:\n\nesi2024 |&gt; \n  ggplot(aes(x = sexo_etiq, y = ing_t_t, fill = sexo_etiq)) +\n  geom_boxplot(alpha = 0.7, outlier.alpha = 0.3) +\n  scale_y_continuous(\n    labels = scales::dollar_format(big.mark = \".\", \n                                   decimal.mark = \",\", prefix = \"$\"),\n    limits = c(0, 2500000)\n  ) +\n  scale_fill_manual(values = c(\"Hombre\" = \"#4292c6\", \"Mujer\" = \"#ef3b2c\")) +\n  labs(\n    title = \"Distribución de Ingresos del Trabajo por Sexo\",\n    subtitle = \"Chile, 2024\",\n    x = NULL,\n    y = \"Ingreso mensual del trabajo\",\n    caption = \"Fuente: INE, ESI 2024\\nNota: Se excluyen outliers extremos para mejor visualización\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 14)\n  )\n\n\n\n\n\n\n\nFigure 2: Distribución de ingresos por sexo\n\n\n\n\n\nLectura del boxplot:\n\nLa línea horizontal dentro de la caja es la mediana\nLos bordes de la caja representan el 25% y 75% de los datos (rango intercuartílico)\nLos “bigotes” se extienden hasta aproximadamente 1.5 veces el rango intercuartílico\nLos puntos son valores atípicos (outliers)"
  },
  {
    "objectID": "lectures/01-intro.html#tablas-de-frecuencia-con-datos-reales",
    "href": "lectures/01-intro.html#tablas-de-frecuencia-con-datos-reales",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "7. Tablas de frecuencia con datos reales",
    "text": "7. Tablas de frecuencia con datos reales\nLas tablas de frecuencia son fundamentales para resumir variables categóricas. Veamos algunos ejemplos con la ESI.\n\n7.1 Distribución por nivel educacional\n\n# Tabla de frecuencias\ntabla_educ &lt;- esi2024 |&gt; \n  count(nivel_etiq, name = \"Frecuencia\") |&gt; \n  mutate(\n    Porcentaje = round((Frecuencia / sum(Frecuencia)) * 100, 1),\n    `Porcentaje acumulado` = cumsum(Porcentaje)\n  )\n\ntabla_educ |&gt; \n  kable(\n    caption = \"Distribución de personas ocupadas por nivel educacional\",\n    col.names = c(\"Nivel Educacional\", \"Frecuencia\", \"Porcentaje\", \"% Acumulado\")\n  )\n\n\nDistribución de personas ocupadas por nivel educacional\n\n\nNivel Educacional\nFrecuencia\nPorcentaje\n% Acumulado\n\n\n\n\nSin educación\n166\n0.5\n0.5\n\n\nSecundaria incompleta\n5461\n15.7\n16.2\n\n\nSecundaria completa\n15066\n43.3\n59.5\n\n\nSuperior\n12981\n37.3\n96.8\n\n\nPostgrado\n1100\n3.2\n100.0\n\n\nOtros\n53\n0.2\n100.2\n\n\n\n\n\n\n\n7.2 Visualización de la distribución educacional\n\nesi2024 |&gt; \n  filter(!is.na(nivel_etiq)) |&gt; \n  count(nivel_etiq) |&gt; \n  mutate(\n    porcentaje = (n / sum(n)) * 100,\n    nivel_etiq = fct_reorder(nivel_etiq, n)\n  ) |&gt; \n  ggplot(aes(x = nivel_etiq, y = porcentaje)) +\n  geom_col(fill = \"#E9C6EF\", alpha = 0.8) +\n  geom_text(aes(label = paste0(round(porcentaje, 1), \"%\")), \n            hjust = -0.2, size = 3.5) +\n  coord_flip() +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +  # Deja espacio para etiquetas\n  labs(\n    title = \"Distribución de Personas Ocupadas por Nivel Educacional\",\n    subtitle = \"Chile, 2024\",\n    x = NULL,\n    y = \"Porcentaje\",\n    caption = \"Fuente: INE, ESI 2024\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    panel.grid.major.y = element_blank()\n  )\n\n\n\n\n\n\n\nFigure 3: Distribución de nivel educacional\n\n\n\n\n\n\n\n7.3 Tabla de contingencia: Sexo x Nivel educacional\nLas tablas de contingencia (o tablas cruzadas) nos permiten analizar la relación entre dos variables categóricas:\n\n# Tabla de contingencia\ntabla_sexo_educ &lt;- esi2024 |&gt; \n  filter(!is.na(nivel_etiq)) |&gt; \n  count(sexo_etiq, nivel_etiq) |&gt; \n  pivot_wider(names_from = sexo_etiq, values_from = n, values_fill = 0)\n\ntabla_sexo_educ |&gt; \n  kable(caption = \"Distribución de nivel educacional por sexo\")\n\n\nDistribución de nivel educacional por sexo\n\n\nnivel_etiq\nHombre\nMujer\n\n\n\n\nSin educación\n109\n57\n\n\nSecundaria incompleta\n3565\n1896\n\n\nSecundaria completa\n8838\n6228\n\n\nSuperior\n6249\n6732\n\n\nPostgrado\n550\n550\n\n\nOtros\n33\n20\n\n\n\n\n\nPodemos también ver las proporciones por fila (qué % de cada nivel educacional es hombre/mujer):\n\n# Proporciones por fila\nesi2024 |&gt; \n  filter(!is.na(nivel_etiq)) |&gt; \n  count(nivel_etiq, sexo_etiq) |&gt; \n  group_by(nivel_etiq) |&gt; \n  mutate(\n    prop = n / sum(n) * 100\n  ) |&gt; \n  select(-n) |&gt; \n  pivot_wider(names_from = sexo_etiq, values_from = prop, values_fill = 0) |&gt; \n  mutate(across(where(is.numeric), ~round(.x, 1))) |&gt; \n  kable(\n    caption = \"Distribución porcentual por sexo dentro de cada nivel educacional\",\n    col.names = c(\"Nivel Educacional\", \"% Hombres\", \"% Mujeres\")\n  )\n\n\nDistribución porcentual por sexo dentro de cada nivel educacional\n\n\nNivel Educacional\n% Hombres\n% Mujeres\n\n\n\n\nSin educación\n65.7\n34.3\n\n\nSecundaria incompleta\n65.3\n34.7\n\n\nSecundaria completa\n58.7\n41.3\n\n\nSuperior\n48.1\n51.9\n\n\nPostgrado\n50.0\n50.0\n\n\nOtros\n62.3\n37.7"
  },
  {
    "objectID": "lectures/01-intro.html#ingresos-por-nivel-educacional",
    "href": "lectures/01-intro.html#ingresos-por-nivel-educacional",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "8. Ingresos por nivel educacional",
    "text": "8. Ingresos por nivel educacional\nUn análisis clásico en economía laboral es examinar cómo los ingresos varían según el nivel educacional (el retorno a la educación):\n\n# Ingresos promedio por nivel educacional\nesi2024 |&gt; \n  filter(!is.na(nivel_etiq)) |&gt; \n  group_by(nivel_etiq) |&gt; \n  summarise(\n    n = n(),\n    Ingreso_Promedio = mean(ing_t_t, na.rm = TRUE),\n    Ingreso_Mediano = median(ing_t_t, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    Ingreso_Promedio = scales::dollar(Ingreso_Promedio,\n                                      big.mark = \".\", \n                                      decimal.mark = \",\", \n                                      prefix = \"$\"),\n    Ingreso_Mediano = scales::dollar(Ingreso_Mediano, \n                                     big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"$\")\n  ) |&gt; \n  kable(\n    caption = \"Ingresos del trabajo por nivel educacional\",\n    col.names = c(\"Nivel Educacional\", \"N\", \n                  \"Ingreso Promedio\", \"Ingreso Mediano\")\n  )\n\n\nIngresos del trabajo por nivel educacional\n\n\nNivel Educacional\nN\nIngreso Promedio\nIngreso Mediano\n\n\n\n\nSin educación\n166\n$319.337\n$314.601\n\n\nSecundaria incompleta\n5461\n$441.101\n$450.000\n\n\nSecundaria completa\n15066\n$578.974\n$504.875\n\n\nSuperior\n12981\n$1.035.382\n$798.005\n\n\nPostgrado\n1100\n$2.121.641\n$1.700.000\n\n\nOtros\n53\n$357.957\n$370.000\n\n\n\n\n\n\nVisualización: Ingresos por educación\n\nesi2024 |&gt; \n  filter(!is.na(nivel_etiq)) |&gt; \n  group_by(nivel_etiq) |&gt; \n  summarise(\n    ingreso_mediano = median(ing_t_t, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(nivel_etiq = fct_reorder(nivel_etiq, ingreso_mediano)) |&gt; \n  ggplot(aes(x = nivel_etiq, y = ingreso_mediano)) +\n  geom_col(fill = \"#69000C\", alpha = 0.7) +\n  geom_text(\n    aes(label = scales::dollar(ingreso_mediano, \n                               big.mark = \".\", \n                               prefix = \"$\", accuracy = 1)),\n    hjust = -0.1, size = 3\n  ) +\n  coord_flip() +\n  scale_y_continuous(\n    labels = scales::dollar_format(big.mark = \".\", prefix = \"$\"),\n    limits = c(0, max(esi2024 |&gt; \n                        filter(!is.na(nivel_etiq)) |&gt; \n                        group_by(nivel_etiq) |&gt; \n                        summarise(med = median(ing_t_t, na.rm = TRUE)) |&gt; \n                        pull(med)) * 1.15),\n    expand = c(0, 0)\n  ) +\n  labs(\n    title = \"Ingreso Mediano del Trabajo por Nivel Educacional\",\n    subtitle = \"Chile, 2024\",\n    x = NULL,\n    y = \"Ingreso mediano mensual\",\n    caption = \"Fuente: INE, ESI 2024\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    panel.grid.major.y = element_blank()\n  )\n\n\n\n\n\n\n\nFigure 4: Ingresos medianos por nivel educacional\n\n\n\n\n\n\n\n\n\n\n\nInterpretación\n\n\n\nObservamos una clara relación positiva entre nivel educacional e ingresos: a mayor educación, mayores ingresos medianos. Este es uno de los hallazgos más robustos en economía laboral y justifica (en parte) la inversión en educación como una forma de movilidad social.\nSin embargo, noten que el “salto” más grande está en los niveles más altos de educación (de media completa a superior y de superior a postgrado). ¿Por qué se produce este salto? ¿Es solo por un aumento lineal (exponencial en rigor) en el ingreso en función de los años estudiando, o bien hay algo que impacta en el salario y no se puede ver en el gráfico?"
  },
  {
    "objectID": "lectures/01-intro.html#ejercicios-prácticos",
    "href": "lectures/01-intro.html#ejercicios-prácticos",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "9. Ejercicios prácticos",
    "text": "9. Ejercicios prácticos\nAhora es tu turno de practicar con el dataframe simulado encuesta. Estos ejercicios te ayudarán a consolidar los conceptos aprendidos.\nPrimero, creemos el dataframe de práctica:\n\n# Simular datos de encuesta para ejercicios\nset.seed(123)  # Para reproducibilidad\n\nencuesta &lt;- data.frame(\n  id = 1:100,\n  edad = sample(18:65, 100, replace = TRUE),\n  sexo = sample(c(\"Mujer\", \"Hombre\"), 100, \n                replace = TRUE, prob = c(0.52, 0.48)),\n  educacion = sample(c(\"Básica\", \"Media\", \"Técnica\", \"Universitaria\", \"Postgrado\"), \n                     100, replace = TRUE, \n                     prob = c(0.10, 0.30, 0.25, 0.30, 0.05)),\n  satisfaccion = sample(1:7, 100, replace = TRUE),\n  ingreso = round(rnorm(100, mean = 800000, sd = 300000), -3)\n)\n\n# Vista previa\nhead(encuesta, 10)\n\n   id edad   sexo     educacion satisfaccion ingreso\n1   1   48 Hombre        Básica            2  790000\n2   2   32 Hombre       Técnica            4  503000\n3   3   31 Hombre Universitaria            2  864000\n4   4   20 Hombre Universitaria            1  508000\n5   5   59 Hombre         Media            5  965000\n6   6   60 Hombre         Media            5  485000\n7   7   54 Hombre Universitaria            1  935000\n8   8   31 Hombre         Media            7  684000\n9   9   42 Hombre       Técnica            1  329000\n10 10   43 Hombre         Media            5 1168000\n\n\n\n\n\n\n\n\n\nEjercicio 1: Calcular estadísticos básicos\n\n\n\nUsando los datos de encuesta:\n\nCalcula la edad promedio y mediana\nCalcula el ingreso promedio y mediano\n¿Cuál es la satisfacción promedio?\nInterpreta: ¿La distribución de ingresos está sesgada? ¿Cómo lo sabes?\n\nPista: Usa las funciones mean() y median(). Compara los resultados.\n\n\n\n\nCode\n# a) Edad\nmean(encuesta$edad)\nmedian(encuesta$edad)\n\n# b) Ingreso\n\n\n# c) Satisfacción\n\n\n# d) Interpretación\n# Escribe tu respuesta aquí\n\n\n\n\n\n\n\n\nSolución Ejercicio 1\n\n\n\n\n\n\n# a) Edad promedio y mediana\ncat(\"Edad promedio:\", round(mean(encuesta$edad), 1), \"años\\n\")\n\nEdad promedio: 41.7 años\n\ncat(\"Edad mediana:\", median(encuesta$edad), \"años\\n\\n\")\n\nEdad mediana: 42.5 años\n\n# b) Ingreso promedio y mediano\ncat(\"Ingreso promedio:\", scales::dollar(mean(encuesta$ingreso), prefix = \"$\", big.mark = \".\"), \"\\n\")\n\nIngreso promedio: $782.700 \n\ncat(\"Ingreso mediano:\", scales::dollar(median(encuesta$ingreso), prefix = \"$\", big.mark = \".\"), \"\\n\\n\")\n\nIngreso mediano: $798.000 \n\n# c) Satisfacción promedio\ncat(\"Satisfacción promedio:\", round(mean(encuesta$satisfaccion), 2), \"(escala 1-7)\\n\\n\")\n\nSatisfacción promedio: 3.92 (escala 1-7)\n\n# d) Interpretación\ncat(\"Interpretación:\\n\")\n\nInterpretación:\n\ncat(\"Media:\", scales::dollar(mean(encuesta$ingreso), prefix = \"$\", big.mark = \".\"), \"\\n\")\n\nMedia: $782.700 \n\ncat(\"Mediana:\", scales::dollar(median(encuesta$ingreso), prefix = \"$\", big.mark = \".\"), \"\\n\")\n\nMediana: $798.000 \n\ncat(\"\\nLa media es\", \n    ifelse(mean(encuesta$ingreso) &gt; median(encuesta$ingreso), \"mayor\", \"menor\"),\n    \"que la mediana, lo que sugiere un sesgo\",\n    ifelse(mean(encuesta$ingreso) &gt; median(encuesta$ingreso), \"positivo (hacia la derecha)\", \"negativo (hacia la izquierda)\"),\n    \"en la distribución de ingresos.\")\n\n\nLa media es menor que la mediana, lo que sugiere un sesgo negativo (hacia la izquierda) en la distribución de ingresos.\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 2: Tabla de frecuencias\n\n\n\nCrea una tabla de frecuencias para la variable educacion que incluya: - Frecuencia absoluta - Frecuencia relativa (porcentaje) - Porcentaje acumulado\nPista: Usa table(), prop.table() y cumsum()\n\n\n\n\nCode\n# Tu código aquí\n# 1. Crear tabla de frecuencias absolutas\n\n\n# 2. Calcular porcentajes\n\n\n# 3. Agregar porcentaje acumulado\n\n\n# 4. Presentar en formato tabla (usa kable)\n\n\n\n\n\n\n\n\nSolución Ejercicio 2\n\n\n\n\n\n\n# Crear tabla de frecuencias completa\ntabla_educ &lt;- as.data.frame(table(encuesta$educacion))\ncolnames(tabla_educ) &lt;- c(\"Nivel_Educacional\", \"Frecuencia\")\n\ntabla_educ &lt;- tabla_educ |&gt; \n  mutate(\n    Porcentaje = round((Frecuencia / sum(Frecuencia)) * 100, 1),\n    Porcentaje_Acumulado = cumsum(Porcentaje)\n  )\n\n# Mostrar con kable\nkable(\n  tabla_educ,\n  caption = \"Distribución de nivel educacional\",\n  col.names = c(\"Nivel Educacional\", \"Frecuencia\", \"Porcentaje (%)\", \"% Acumulado\")\n)\n\n\nDistribución de nivel educacional\n\n\nNivel Educacional\nFrecuencia\nPorcentaje (%)\n% Acumulado\n\n\n\n\nBásica\n8\n8\n8\n\n\nMedia\n35\n35\n43\n\n\nPostgrado\n6\n6\n49\n\n\nTécnica\n25\n25\n74\n\n\nUniversitaria\n26\n26\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 3: Tabla de contingencia\n\n\n\nCrea una tabla de contingencia entre sexo y educacion.\n\n¿Cuántos hombres tienen educación universitaria?\n¿Cuántas mujeres tienen educación media?\nCalcula las proporciones por fila (% dentro de cada sexo)\n¿Qué porcentaje de las mujeres tiene educación universitaria?\n\nPista: Usa table() y prop.table() con margin = 1 para proporciones por fila\n\n\n\n\nCode\n# a) y b) Crear tabla de contingencia\n\n\n# c) Proporciones por fila\n\n\n# d) Interpretación\n\n\n\n\n\n\n\n\nSolución Ejercicio 3\n\n\n\n\n\n\n# a) y b) Tabla de contingencia\ntabla_sexo_educ &lt;- table(encuesta$sexo, encuesta$educacion)\nprint(\"Tabla de contingencia: Sexo x Educación\")\n\n[1] \"Tabla de contingencia: Sexo x Educación\"\n\ntabla_sexo_educ\n\n        \n         Básica Media Postgrado Técnica Universitaria\n  Hombre      4    19         0      14            11\n  Mujer       4    16         6      11            15\n\ncat(\"\\na) Hombres con educación universitaria:\", tabla_sexo_educ[\"Hombre\", \"Universitaria\"], \"\\n\")\n\n\na) Hombres con educación universitaria: 11 \n\ncat(\"b) Mujeres con educación media:\", tabla_sexo_educ[\"Mujer\", \"Media\"], \"\\n\\n\")\n\nb) Mujeres con educación media: 16 \n\n# c) Proporciones por fila (% dentro de cada sexo)\nprop_fila &lt;- prop.table(tabla_sexo_educ, margin = 1) * 100\nprint(\"Porcentajes por sexo:\")\n\n[1] \"Porcentajes por sexo:\"\n\nround(prop_fila, 1)\n\n        \n         Básica Media Postgrado Técnica Universitaria\n  Hombre    8.3  39.6       0.0    29.2          22.9\n  Mujer     7.7  30.8      11.5    21.2          28.8\n\n# d) Porcentaje de mujeres con educación universitaria\ncat(\"\\nd) Porcentaje de mujeres con educación universitaria:\", \n    round(prop_fila[\"Mujer\", \"Universitaria\"], 1), \"%\")\n\n\nd) Porcentaje de mujeres con educación universitaria: 28.8 %"
  },
  {
    "objectID": "lectures/01-intro.html#ejercicio-4-análisis-de-ingresos-por-grupo",
    "href": "lectures/01-intro.html#ejercicio-4-análisis-de-ingresos-por-grupo",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "Ejercicio 4: Análisis de ingresos por grupo",
    "text": "Ejercicio 4: Análisis de ingresos por grupo\nAhora realizaremos un análisis más complejo, comparando ingresos entre diferentes grupos.\n\n\n\n\n\n\nEjercicio 4: Ingresos por sexo y educación\n\n\n\nUsando el dataframe encuesta:\n\nCalcula el ingreso promedio y mediano por sexo\nCalcula el ingreso promedio por nivel educacional\nCrea un gráfico de boxplot comparando ingresos entre hombres y mujeres\nInterpreta: ¿Existe una brecha salarial en estos datos simulados?\n\nPista: Usa group_by() y summarise() de dplyr, y ggplot() para el gráfico\n\n\n\n\nCode\n# a) Ingresos por sexo\nencuesta |&gt; \n  group_by(sexo) |&gt; \n  summarise(\n    # completar aquí\n  )\n\n# b) Ingresos por educación\n\n\n# c) Boxplot\n\n\n# d) Interpretación\n# Escribe tu análisis aquí\n\n\n\n\n\n\n\n\nSolución Ejercicio 4\n\n\n\n\n\n\n# a) Ingresos por sexo\ncat(\"=== Ingresos por sexo ===\\n\\n\")\n\n=== Ingresos por sexo ===\n\nresumen_sexo &lt;- encuesta |&gt; \n  group_by(sexo) |&gt; \n  summarise(\n    n = n(),\n    Ingreso_Promedio = mean(ingreso, na.rm = TRUE),\n    Ingreso_Mediano = median(ingreso, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    Ingreso_Promedio = scales::dollar(Ingreso_Promedio, prefix = \"$\", big.mark = \".\"),\n    Ingreso_Mediano = scales::dollar(Ingreso_Mediano, prefix = \"$\", big.mark = \".\")\n  )\n\nkable(resumen_sexo, \n      caption = \"Ingresos por sexo\",\n      col.names = c(\"Sexo\", \"N\", \"Ingreso Promedio\", \"Ingreso Mediano\"))\n\n\nIngresos por sexo\n\n\nSexo\nN\nIngreso Promedio\nIngreso Mediano\n\n\n\n\nHombre\n48\n$754.229\n$806.000\n\n\nMujer\n52\n$808.981\n$798.000\n\n\n\n\n# b) Ingresos por educación\ncat(\"\\n=== Ingresos por nivel educacional ===\\n\\n\")\n\n\n=== Ingresos por nivel educacional ===\n\nresumen_educ &lt;- encuesta |&gt; \n  group_by(educacion) |&gt; \n  summarise(\n    n = n(),\n    Ingreso_Promedio = mean(ingreso, na.rm = TRUE),\n    Ingreso_Mediano = median(ingreso, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n  arrange(desc(Ingreso_Mediano)) |&gt; \n  mutate(\n    Ingreso_Promedio = scales::dollar(Ingreso_Promedio, prefix = \"$\", big.mark = \".\"),\n    Ingreso_Mediano = scales::dollar(Ingreso_Mediano, prefix = \"$\", big.mark = \".\")\n  )\n\nkable(resumen_educ,\n      caption = \"Ingresos por nivel educacional\",\n      col.names = c(\"Educación\", \"N\", \"Ingreso Promedio\", \"Ingreso Mediano\"))\n\n\nIngresos por nivel educacional\n\n\nEducación\nN\nIngreso Promedio\nIngreso Mediano\n\n\n\n\nPostgrado\n6\n$922.500\n$977.500\n\n\nUniversitaria\n26\n$836.269\n$899.500\n\n\nMedia\n35\n$804.800\n$866.000\n\n\nBásica\n8\n$764.500\n$854.500\n\n\nTécnica\n25\n$668.320\n$696.000\n\n\n\n\n\n\n# c) Boxplot de ingresos por sexo\nggplot(encuesta, aes(x = sexo, y = ingreso, fill = sexo)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_y_continuous(\n    labels = scales::dollar_format(prefix = \"$\", big.mark = \".\")\n  ) +\n  scale_fill_manual(values = c(\"Hombre\" = \"#4292c6\", \"Mujer\" = \"#ef3b2c\")) +\n  labs(\n    title = \"Distribución de Ingresos por Sexo\",\n    subtitle = \"Datos simulados de encuesta\",\n    x = NULL,\n    y = \"Ingreso mensual\",\n    caption = \"Fuente: Datos simulados para ejercicio\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 13)\n  )\n\n\n\n\nComparación de ingresos por sexo\n\n\n\n# d) Interpretación\ncat(\"\\n=== Interpretación ===\\n\\n\")\n\n\n=== Interpretación ===\n\nmedia_h &lt;- mean(encuesta$ingreso[encuesta$sexo == \"Hombre\"])\nmedia_m &lt;- mean(encuesta$ingreso[encuesta$sexo == \"Mujer\"])\nbrecha &lt;- ((media_h - media_m) / media_h) * 100\n\ncat(\"En estos datos simulados:\\n\")\n\nEn estos datos simulados:\n\ncat(\"- Ingreso promedio hombres:\", scales::dollar(media_h, prefix = \"$\", big.mark = \".\"), \"\\n\")\n\n- Ingreso promedio hombres: $754.229 \n\ncat(\"- Ingreso promedio mujeres:\", scales::dollar(media_m, prefix = \"$\", big.mark = \".\"), \"\\n\")\n\n- Ingreso promedio mujeres: $808.981 \n\ncat(\"- Brecha salarial:\", round(brecha, 1), \"%\\n\\n\")\n\n- Brecha salarial: -7.3 %\n\nif (brecha &gt; 5) {\n  cat(\"Existe una brecha salarial favorable a los hombres del\", round(brecha, 1), \"%.\\n\")\n  cat(\"Esto significa que, en promedio, las mujeres ganan\", \n      round(100 - (media_m/media_h * 100), 1), \n      \"% menos que los hombres en esta muestra simulada.\")\n} else if (brecha &lt; -5) {\n  cat(\"Existe una brecha salarial favorable a las mujeres del\", round(abs(brecha), 1), \"%.\")\n} else {\n  cat(\"No se observa una brecha salarial significativa (diferencia menor al 5%).\")\n}\n\nExiste una brecha salarial favorable a las mujeres del 7.3 %.\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 5: Visualización avanzada\n\n\n\nCrea un gráfico que muestre la distribución de edad por nivel educacional.\nPuedes elegir entre: - Un histograma facetado por educación - Un boxplot con educación en el eje X y edad en el eje Y - Un gráfico de violín\nBonus: Agrega títulos, etiquetas y personaliza los colores.\n\n\n\n\nCode\n# Tu código aquí\n# Crea el gráfico que prefieras usando ggplot()\n\n\n\n\n\n\n\n\nSolución Ejercicio 5\n\n\n\n\n\n\n# Opción 1: Boxplot\nggplot(encuesta, aes(x = educacion, y = edad, fill = educacion)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.3, size = 0.8) +  # Agregar puntos individuales\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(\n    title = \"Distribución de Edad según Nivel Educacional\",\n    subtitle = \"Datos simulados de encuesta (N=100)\",\n    x = \"Nivel Educacional\",\n    y = \"Edad (años)\",\n    caption = \"Fuente: Datos simulados para ejercicio\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 13),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\nDistribución de edad por nivel educacional (boxplot)\n\n\n\n\n\n# Opción 2: Gráfico de violín\nggplot(encuesta, aes(x = educacion, y = edad, fill = educacion)) +\n  geom_violin(alpha = 0.6, trim = FALSE) +\n  geom_boxplot(width = 0.1, alpha = 0.8, outlier.alpha = 0) +\n  scale_fill_viridis_d(option = \"plasma\") +\n  labs(\n    title = \"Distribución de Edad según Nivel Educacional\",\n    subtitle = \"Gráfico de violín con boxplot incorporado\",\n    x = \"Nivel Educacional\",\n    y = \"Edad (años)\",\n    caption = \"Fuente: Datos simulados para ejercicio\\nEl ancho del violín representa la densidad de datos\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 13),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\nDistribución de edad por nivel educacional (violín)\n\n\n\n\n\n# Opción 3: Histogramas facetados\nggplot(encuesta, aes(x = edad, fill = educacion)) +\n  geom_histogram(bins = 15, alpha = 0.8, color = \"white\") +\n  facet_wrap(~educacion, ncol = 3) +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(\n    title = \"Distribución de Edad por Nivel Educacional\",\n    subtitle = \"Histogramas separados para cada categoría\",\n    x = \"Edad (años)\",\n    y = \"Frecuencia\",\n    caption = \"Fuente: Datos simulados para ejercicio\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 13),\n    strip.text = element_text(face = \"bold\", size = 10)\n  )\n\n\n\n\nHistogramas de edad por nivel educacional"
  },
  {
    "objectID": "lectures/01-intro.html#resumen-de-la-sesión",
    "href": "lectures/01-intro.html#resumen-de-la-sesión",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "10. Resumen de la sesión",
    "text": "10. Resumen de la sesión\nEn esta primera sesión hemos cubierto aspectos fundamentales tanto de R como de estadística descriptiva:\n\n✅ Conceptos de R aprendidos\n\nInterfaz de RStudio: Navegación entre paneles (Editor, Consola, Environment, Files/Plots)\nOperaciones básicas: R como calculadora avanzada\nCreación de objetos: Vectores, matrices y dataframes\nOperaciones vectoriales y matriciales: Incluyendo álgebra lineal\nImportación de datos: Archivos CSV y Stata (.dta)\nManipulación de datos con dplyr:\n\nselect(): Seleccionar columnas\nfilter(): Filtrar filas\nmutate(): Crear/modificar variables\ngroup_by() y summarise(): Agrupar y resumir\nOperador pipe |&gt;: Encadenar operaciones\n\nExploración de datos: glimpse(), head(), str(), dim()\nVisualización con ggplot2: Histogramas, boxplots, gráficos de barras\n\n\n\n✅ Conceptos estadísticos aprendidos\n\nMedidas de tendencia central:\n\nMedia: Promedio aritmético, sensible a valores extremos\nMediana: Valor central, robusta a outliers\nCuándo usar cada una según la distribución de los datos\n\nDistribuciones asimétricas: Interpretación de sesgo positivo/negativo comparando media y mediana\nTablas de frecuencia:\n\nFrecuencias absolutas y relativas\nFrecuencias acumuladas\nTablas de contingencia (cruce de dos variables)\nProporciones por fila y columna\n\nAnálisis bivariado descriptivo:\n\nComparación de estadísticos entre grupos\nIdentificación de brechas (ej: brecha salarial de género)\nVisualización de diferencias entre grupos\n\nInterpretación de gráficos:\n\nHistogramas: Forma de la distribución\nBoxplots: Mediana, rango intercuartílico, outliers\nGráficos de barras: Frecuencias y proporciones\n\n\n\n\n🎯 Aplicaciones prácticas\nTrabajamos con dos bases de datos reales: 1. ENE (Encuesta Nacional de Empleo): Cálculo de tasas de ocupación 2. ESI (Encuesta Suplementaria de Ingresos): Análisis de ingresos, brechas salariales, y retornos a la educación\nEstos análisis nos permitieron ver cómo la estadística descriptiva es fundamental para: - Caracterizar poblaciones y muestras - Identificar patrones y tendencias - Comparar grupos (género, educación, edad) - Comunicar hallazgos de manera efectiva"
  },
  {
    "objectID": "lectures/01-intro.html#recursos-adicionales",
    "href": "lectures/01-intro.html#recursos-adicionales",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "11. Recursos adicionales",
    "text": "11. Recursos adicionales\n\n📚 Lecturas recomendadas\nSobre R: - Wickham, H., & Grolemund, G. (2023). R para Ciencia de Datos. Capítulos 1-5 y 9-11. - Fernández-Avilés, G., & Montero, J.M. (2024). Ciencia de Datos en R. Capítulos 1-3. - Wickham, H. (2019). Advanced R. Para profundizar en programación orientada a objetos.\nSobre Estadística Descriptiva: - Navarro, D. (2015). Learning Statistics with R. Capítulos 3-5. - Verzani, J. (2014). Using R for Introductory Statistics. Capítulos 1-4.\nDocumentación oficial: - Documentación de dplyr - Documentación de ggplot2 - RStudio Cheatsheets (especialmente Data Transformation y Data Visualization)\n\n\n🎥 Videos recomendados\n\nIntroducción a RStudio (10 min)\nR para principiantes - Tutorial completo\nVisualización de datos con ggplot2\n\n\n\n💻 Práctica interactiva\n\nSwirl - Learn R, in R - Tutorial interactivo dentro de R\nR for Data Science - Ejercicios\nDataCamp - Introduction to R (gratis)\n\n\n\n🔗 Bases de datos para practicar\n\nEncuesta Nacional de Empleo (ENE) - INE Chile\nEncuesta Suplementaria de Ingresos (ESI) - INE Chile\nCASEN - Ministerio de Desarrollo Social\nDatasets incluidos en R"
  },
  {
    "objectID": "lectures/01-intro.html#preparación-para-la-próxima-sesión",
    "href": "lectures/01-intro.html#preparación-para-la-próxima-sesión",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "12. Preparación para la próxima sesión",
    "text": "12. Preparación para la próxima sesión\nEn la Sesión 2 continuaremos con estadística descriptiva, enfocándonos en:\n\nMedidas de dispersión:\n\nRango, varianza, desviación estándar\nRango intercuartílico\nCoeficiente de variación\n\nMedidas de posición:\n\nCuartiles, deciles, percentiles\nInterpretación y aplicaciones\n\nIntroducción a pruebas de hipótesis:\n\nConceptos básicos de inferencia estadística\nDistribución normal\nIntervalos de confianza\n\n\n\n📝 Tarea para la próxima sesión\n\n\n\n\n\n\nTarea obligatoria\n\n\n\nElige una de las siguientes bases de datos y realiza un análisis descriptivo básico:\nOpción 1: ENE (Encuesta Nacional de Empleo) - Descarga: ENE más reciente - Analiza: Tasas de participación laboral por región y sexo\nOpción 2: ESI (Encuesta Suplementaria de Ingresos) - Ya usamos esta base en clase - Analiza: Ingresos por región y sector económico\nOpción 3: Base de datos propia - Si tienes datos de tu investigación de magíster, úsalos - Realiza análisis descriptivo básico\nEntregables (documento .Rmd o .qmd):\n\nBreve descripción de la base de datos (origen, año, n° observaciones)\nSelección de 3-4 variables de interés\nAnálisis descriptivo que incluya:\n\nTablas de frecuencia para variables categóricas\nMedidas de tendencia central para variables numéricas\nAl menos 2 visualizaciones (gráficos)\n\nInterpretación de los resultados (2-3 párrafos)\n\nFormato de entrega: - Archivo .Rmd o .qmd con código y texto - Renderizado a HTML o PDF - Fecha límite: Antes de la Sesión 2\n\n\n\n\n💡 Consejos para la tarea\n\nRevisa el código de esta sesión como referencia\nUsa comentarios (#) para explicar tu código\nSigue las buenas prácticas: nombres descriptivos de objetos, código indentado\nSi tienes dudas, consulta la documentación: ?nombre_funcion\nPractica el flujo: importar → explorar → limpiar → analizar → visualizar"
  },
  {
    "objectID": "lectures/01-intro.html#código-completo-de-la-sesión",
    "href": "lectures/01-intro.html#código-completo-de-la-sesión",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "13. Código completo de la sesión",
    "text": "13. Código completo de la sesión\nSi quieres replicar todo el análisis de esta sesión, aquí está el código completo:\n\n\nVer código completo de la sesión\n# ============================================\n# SESIÓN 1: CÓDIGO COMPLETO\n# Taller de Métodos y Técnicas de Investigación I\n# ============================================\n\n# 1. PREPARACIÓN ----\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(sjmisc)\nlibrary(haven)\noptions(scipen = 999)\n\n# 2. CARGAR ENE ----\ndatos &lt;- read.csv(\"data-sesiones/ene-2025-07-jja.csv\",\n                  sep = \";\",\n                  encoding = \"Latin-1\",\n                  stringsAsFactors = FALSE)\n\n# Explorar\nglimpse(datos)\nfrq(datos$activ)\n\n# Calcular tasa de ocupación (muestral)\ntoc_muestra &lt;- datos |&gt;\n  mutate(\n    oc = activ == 1,\n    may15 = edad &gt;= 15\n  ) |&gt;\n  filter(may15, !is.na(activ)) |&gt;\n  summarise(toc = mean(oc)) |&gt;\n  pull(toc)\n\ncat(\"Tasa de ocupación muestral:\", round(toc_muestra * 100, 2), \"%\\n\")\n\n# 3. CARGAR ESI ----\nesi2024 &lt;- haven::read_dta(\"https://www.ine.gob.cl/docs/default-source/encuesta-suplementaria-de-ingresos/bbdd/stata_esi/2024/esi_2024.dta?sfvrsn=627c0f59_4&download=true\")\n\n# Preparar datos\nesi_trabajo &lt;- esi2024 |&gt;\n  select(sexo, edad, nivel, ing_t_t, activ, region) |&gt;\n  filter(activ == 1, !is.na(ing_t_t), ing_t_t &gt; 0) |&gt;\n  mutate(\n    sexo_etiq = case_when(\n      sexo == 1 ~ \"Hombre\",\n      sexo == 2 ~ \"Mujer\",\n      TRUE ~ \"Otro\"\n    ),\n    nivel_etiq = case_when(\n      nivel == 1 ~ \"Sin educación\",\n      nivel == 2 ~ \"Básica incompleta\",\n      nivel == 3 ~ \"Básica completa\",\n      nivel == 4 ~ \"Media incompleta\",\n      nivel == 5 ~ \"Media completa\",\n      nivel == 6 ~ \"Técnica incompleta\",\n      nivel == 7 ~ \"Técnica completa\",\n      nivel == 8 ~ \"Universitaria incompleta\",\n      nivel == 9 ~ \"Universitaria completa\",\n      nivel == 10 ~ \"Postgrado\",\n      TRUE ~ \"Sin información\"\n    )\n  )\n\n# 4. ESTADÍSTICA DESCRIPTIVA ----\n\n# Media y mediana de ingresos\nmean(esi_trabajo$ing_t_t)\nmedian(esi_trabajo$ing_t_t)\n\n# Por sexo\nesi_trabajo |&gt;\n  group_by(sexo_etiq) |&gt;\n  summarise(\n    n = n(),\n    Media = mean(ing_t_t),\n    Mediana = median(ing_t_t)\n  )\n\n# 5. VISUALIZACIONES ----\n\n# Histograma con media y mediana\nggplot(esi_trabajo, aes(x = ing_t_t)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(aes(xintercept = mean(ing_t_t), color = \"Media\"),\n             linewidth = 1.2, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = median(ing_t_t), color = \"Mediana\"),\n             linewidth = 1.2, linetype = \"dashed\") +\n  scale_x_continuous(limits = c(0, 3000000)) +\n  theme_minimal()\n\n# Boxplot por sexo\nggplot(esi_trabajo, aes(x = sexo_etiq, y = ing_t_t, fill = sexo_etiq)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_y_continuous(limits = c(0, 2500000)) +\n  theme_minimal()\n\n# 6. TABLAS DE FRECUENCIA ----\n\n# Tabla educación\ntable(esi_trabajo$nivel_etiq)\nprop.table(table(esi_trabajo$nivel_etiq)) * 100\n\n# Tabla de contingencia\ntable(esi_trabajo$sexo_etiq, esi_trabajo$nivel_etiq)\n\n# 7. EJERCICIOS CON DATOS SIMULADOS ----\nset.seed(123)\nencuesta &lt;- data.frame(\n  id = 1:100,\n  edad = sample(18:65, 100, replace = TRUE),\n  sexo = sample(c(\"Mujer\", \"Hombre\"), 100, replace = TRUE, prob = c(0.52, 0.48)),\n  educacion = sample(c(\"Básica\", \"Media\", \"Técnica\", \"Universitaria\", \"Postgrado\"),\n                     100, replace = TRUE, prob = c(0.10, 0.30, 0.25, 0.30, 0.05)),\n  satisfaccion = sample(1:7, 100, replace = TRUE),\n  ingreso = round(rnorm(100, mean = 800000, sd = 300000), -3)\n)\n\n# Análisis básico\nsummary(encuesta)\ntable(encuesta$educacion)\n\n\n\n\n\n\n\n\n\nNota final\n\n\n\nEsta sesión establece las bases para todo el curso. Es fundamental que te sientas cómodo/a con: - La lógica de programación en R - La manipulación básica de datos - El cálculo e interpretación de estadísticos descriptivos - La creación de visualizaciones\nSi algún concepto no quedó claro, no dudes en consultar. Los contenidos son acumulativos y necesitarás estas herramientas en todas las sesiones siguientes.\n¡Nos vemos en la Sesión 2! 🚀"
  },
  {
    "objectID": "lectures/01-intro.html#footnotes",
    "href": "lectures/01-intro.html#footnotes",
    "title": "Sesión 1: Introducción a R y Estadística Descriptiva (I)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLa expresión \\(\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y\\) se puede demostrar, pero no es objeto de esta clase (ni curso)↩︎"
  },
  {
    "objectID": "lectures/04-corr-regression.html",
    "href": "lectures/04-corr-regression.html",
    "title": "Sesión 4: Correlación Bivariada y Regresión Lineal Simple",
    "section": "",
    "text": "En construcción\n\n\n\nContenido en desarrollo. Disponible próximamente."
  },
  {
    "objectID": "lectures/04-corr-regression.html#objetivos-de-la-sesión",
    "href": "lectures/04-corr-regression.html#objetivos-de-la-sesión",
    "title": "Sesión 4: Correlación Bivariada y Regresión Lineal Simple",
    "section": "Objetivos de la sesión",
    "text": "Objetivos de la sesión\n\nCalcular correlaciones de Pearson y Spearman\nCrear matrices de correlación\nAjustar modelos de regresión simple\nInterpretar coeficientes de regresión\n\n\nÚltima actualización: [Fecha]"
  },
  {
    "objectID": "lectures/template-clase.html",
    "href": "lectures/template-clase.html",
    "title": "Sesión X: [Título de la sesión]",
    "section": "",
    "text": "Al finalizar esta sesión serás capaz de:\n\nObjetivo 1\nObjetivo 2\nObjetivo 3"
  },
  {
    "objectID": "lectures/template-clase.html#objetivos-de-la-sesión",
    "href": "lectures/template-clase.html#objetivos-de-la-sesión",
    "title": "Sesión X: [Título de la sesión]",
    "section": "",
    "text": "Al finalizar esta sesión serás capaz de:\n\nObjetivo 1\nObjetivo 2\nObjetivo 3"
  },
  {
    "objectID": "lectures/template-clase.html#preparación",
    "href": "lectures/template-clase.html#preparación",
    "title": "Sesión X: [Título de la sesión]",
    "section": "Preparación",
    "text": "Preparación\n\nPaquetes necesarios\n\n# Cargar librerías\nlibrary(tidyverse)\n\n# Configuración general\noptions(scipen = 999) # Evitar notación científica\n\n\n\nDatos\nPara esta sesión utilizaremos [descripción del dataset]:\n\n# Cargar datos\ndatos &lt;- read.csv(\"../data/ene-2025-07-jja.csv\")\n\n# Vista previa\nhead(datos)\n\n                                                                                                                                                                                                                                                                                                                                                                                                                      ano_trimestre.mes_central.ano_encuesta.mes_encuesta.region.provincia.tipo.r_p_c.estrato.conglomerado.id_identificacion.hogar.idrph.nro_linea.proveedor.parentesco.sexo.edad.est_conyugal.mig1.mig2_cod.mig3_cod.mig4.mig5_cod.mig6_cod.nacionalidad.orig1. ...\n2025;7;2025;6;8;81;1;8111;8100212;35395;188791;1;853676467929;1;1;1;1;57;3;1;;;1;;;152;2;;;3;9;2;2;3;13;2;2;1;;1;;;;;;;7;2;;;2;;2;2;2;1;2;2;2;2;2;;1;1;;7;1;2;1;;88;2011;8;8111;1;2;2;;2;;;;1;1;2;0;;;;;2;2;2;2;2;2;;;;;8;5;40;;;;8;5;40;;;;;;2;;2;;;;;;;2;;;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;9;3;2;24;2;1;1;1;3;40;40;0;2;1;7;;0;;2;130                                                                                                                                                                                                                                                                                                                         126164801805\n2025;7;2025;6;8;81;1;8111;8100212;35395;188792;1;69857573301;2;0;4;1;23;2;1;;;1;;;152;2;;;4;4;1;2;4;8;1;2;1;;1;;;;;;;9;1;;2;;;;;;;;;;;;;2;;;19;1;1;5;;6;2024;8;8111;1;2;1;FACEBOOK;2;;;;;;;;2;;4;;2;2;2;2;2;2;;;;;8;4;32;;;;;;;;;;;;1;3;;;16;;3;5;15;1;1;2;1;0;0;0;1;0;0;0;0;0;0;0;;1;1;;;;;;;;3;;;;;;;;;;;;;;;;;2;3;2;24;2;1;1;1;2;32;35;0;2;2;19;;1;;2;120                                                                                                                                                                                                                                                                                                            770034305589\n2025;7;2025;6;8;81;1;8111;8100212;35395;188792;1;733202104071;4;1;1;2;54;2;1;;;1;;;152;2;;;5;5;1;2;5;9;1;2;1;;1;;;;;;;5;2;;;2;;1;1;1;1;1;1;88;1;2;;1;1;;7;2;9;1;;88;2010;8;8111;1;2;2;;2;;;;1;1;1;0;;;;;2;2;2;2;2;2;;;;;888;6;44;;;;888;6;44;;;;;;2;;2;;;;;;;2;;;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;8;3;2;25;2;1;1;1;3;44;44;0;1;1;7;;0;;2;117                                                                                                                                                                                                                                                                                                                     699995068579\n2025;7;2025;6;8;81;1;8111;8100212;35395;188792;1;974021027494;3;0;4;2;21;2;1;;;1;;;152;2;;;2;7;2;1;2;12;2;1;2;2;;;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;2;;;;;;;;;;;;;;;;;;;;;;;4;;;2;2;3;;1;12;2024;5;3;;;;;2;3;2;24;;3;9;15;0;;;;;;;0;;0;;120                                                                                                                                                                                                                                                                                                                                                                         145638363174\n2025;7;2025;6;8;81;1;8111;8100212;35395;188792;1;408193222712;1;0;3;1;55;2;2;7406;;1;;;152;2;;;2;4;2;2;2;8;2;2;2;2;;;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;2;;;;;;;;;;;;;;;;;;;;;;;22;NO PUDO RENOVAR LA LICENCIA DE CONDUCIR;;1;2;13;PARA RENOVAR LICENCIA DE CONDUCIR LE EXIGEN PAGAR LA PENSION DE ALIMENTOS;1;88;2024;1;1;6;;;;9;2;1;14;;3;9;28;0;;;;;;;0;;0;;130                                                                                                                                                                                                                                                   126164801805\n2025;7;2025;6;8;81;1;8111;8100212;35395;188793;1;439623161927;1;0;3;2;30;2;1;;;1;;;152;2;;;5;9;1;2;5;13;1;2;1;;1;;;;;;;2;2;;;1;;1;1;1;2;1;1;1;1;1;5;1;1;;16;5;;1;;9;2024;8;8111;1;2;2;;2;;;;1;1;1;0;;;;;1;2;2;2;2;2;;;;;888;5;36;;;;888;5;36;;;;;;2;;2;;;;2;2;4;1;1;1;2;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;4;4;4;46;2;1;1;1;4;36;36;0;1;1;16;;0;;1;141                                                                                                                                                                                                                                                                                                               845401035688"
  },
  {
    "objectID": "lectures/template-clase.html#concepto-teórico-principal",
    "href": "lectures/template-clase.html#concepto-teórico-principal",
    "title": "Sesión X: [Título de la sesión]",
    "section": "1. Concepto teórico principal",
    "text": "1. Concepto teórico principal\nBreve explicación del concepto estadístico.\n\n\n\n\n\n\nDefinición\n\n\n\nAquí va una definición formal o importante.\n\n\n\nSubtema 1.1\nExplicación más detallada con ejemplos conceptuales."
  },
  {
    "objectID": "lectures/template-clase.html#aplicación-en-r",
    "href": "lectures/template-clase.html#aplicación-en-r",
    "title": "Sesión X: [Título de la sesión]",
    "section": "2. Aplicación en R",
    "text": "2. Aplicación en R\n\n2.1 Primer ejemplo\nDescripción de lo que vamos a hacer:\n# Código comentado paso a paso\nresultado &lt;- funcion(datos)\n\n# Mostrar resultado\nresultado\nInterpretación: Aquí explicas qué significa el resultado.\n\n\n2.2 Segundo ejemplo\n\n# Otro ejemplo más complejo"
  },
  {
    "objectID": "lectures/template-clase.html#visualización",
    "href": "lectures/template-clase.html#visualización",
    "title": "Sesión X: [Título de la sesión]",
    "section": "3. Visualización",
    "text": "3. Visualización\nLas visualizaciones ayudan a entender mejor los resultados:\n#| label: fig-grafico1\n#| fig-cap: \"Descripción del gráfico\"\n#| fig-width: 8\n#| fig-height: 6\n\n# Código para generar gráfico\nggplot(datos, aes(x = variable_x, y = variable_y)) +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Título del gráfico\",\n       x = \"Eje X\",\n       y = \"Eje Y\")"
  },
  {
    "objectID": "lectures/template-clase.html#ejercicios-prácticos",
    "href": "lectures/template-clase.html#ejercicios-prácticos",
    "title": "Sesión X: [Título de la sesión]",
    "section": "4. Ejercicios prácticos",
    "text": "4. Ejercicios prácticos\n\n\n\n\n\n\nEjercicio 1\n\n\n\nTarea: Describe qué deben hacer.\nPista: Una ayuda para empezar.\n\n\n\n# Espacio para que los estudiantes completen el código\n\n\n\n\n\n\n\nSolución Ejercicio 1\n\n\n\n\n\n\n# Código de la solución\n\nExplicación: Por qué esta es la solución correcta."
  },
  {
    "objectID": "lectures/template-clase.html#resumen",
    "href": "lectures/template-clase.html#resumen",
    "title": "Sesión X: [Título de la sesión]",
    "section": "Resumen",
    "text": "Resumen\nEn esta sesión aprendimos:\n\nPunto clave 1\nPunto clave 2\nPunto clave 3"
  },
  {
    "objectID": "lectures/template-clase.html#recursos-adicionales",
    "href": "lectures/template-clase.html#recursos-adicionales",
    "title": "Sesión X: [Título de la sesión]",
    "section": "Recursos adicionales",
    "text": "Recursos adicionales\n\nLecturas recomendadas\n\nAutor (año). Título del libro. Páginas X-Y.\nArtículo online\n\n\n\nVideos\n\nTutorial en YouTube\n\n\n\nPráctica adicional\n\nEjercicios complementarios"
  },
  {
    "objectID": "lectures/template-clase.html#para-la-próxima-sesión",
    "href": "lectures/template-clase.html#para-la-próxima-sesión",
    "title": "Sesión X: [Título de la sesión]",
    "section": "Para la próxima sesión",
    "text": "Para la próxima sesión\n\n\n\n\n\n\nTareas\n\n\n\n\nCompletar ejercicios de esta sesión\nLeer capítulo X\nTraer dudas para resolver"
  },
  {
    "objectID": "recursos.html",
    "href": "recursos.html",
    "title": "Recursos",
    "section": "",
    "text": "Para este curso necesitas instalar:\n\nR\n\nDescarga desde: https://cran.r-project.org/\nSelecciona tu sistema operativo y sigue las instrucciones\n\nRStudio (IDE recomendado)\n\nDescarga desde: https://posit.co/download/rstudio-desktop/\nVersión gratuita (Desktop) es suficiente\nSi quieren otro IDE, pueden usar Positron, que es un nuevo IDE que combina Python y R en un interfaz amable. O si vienen del mundo más ligado a la ciencia de datos “pura”, también pueden usar VS Code. Pero el lenguaje de programación será siempre R.\n\n\n\n\n\n\n\n\nVideo tutoriales de instalación\n\n\n\n\nInstalar R y RStudio en Windows\nInstalar R y RStudio en Mac\nInstalar R y RStudio en Linux\n\n(Pueden usar cualquier tutorial que deseen, lo de arriba solo son referencias rápidas. De cualquier manera, es bastante intuitivo)\n\n\n\n\n\nDurante el curso usaremos principalmente estos paquetes. Puedes instalarlos copiando este código en tu consola de R:\n# Paquetes para manipulación y limpieza de datos\ninstall.packages(\"tidyverse\")   # dplyr, ggplot2, tidyr, readr, etc.\ninstall.packages(\"haven\")       # Importar SPSS, Stata, SAS\ninstall.packages(\"readxl\")      # Leer Excel\ninstall.packages(\"rio\")         # Import/export flexible\ninstall.packages(\"janitor\")     # Limpiar datos y tablas\ninstall.packages(\"labelled\")    # Etiquetas de variables.\n\n# Paquetes para estadística descriptiva e inferencial básica\ninstall.packages(\"psych\")       # Descriptivos\ninstall.packages(\"DescTools\")   # Medidas y tests clásicos\ninstall.packages(\"summarytools\")# Tablas descriptivas rápidas\n\n# Paquetes para test de hipótesis y modelos lineales\ninstall.packages(\"car\")         # Regresión, ANOVA, supuestos\ninstall.packages(\"lmtest\")      # Tests para modelos lineales\ninstall.packages(\"sandwich\")    # Errores robustos (White, HC)\ninstall.packages(\"estimatr\")    # Regresión con errores robustos fáciles\ninstall.packages(\"margins\")     # Efectos marginales\n\n\n# Paquetes para tablas y reportes\ninstall.packages(\"broom\")       # Convertir modelos a dataframes\ninstall.packages(\"stargazer\")   # Tablas de regresión (LaTeX, html, texto)\ninstall.packages(\"modelsummary\")# Alternativa moderna a stargazer\ninstall.packages(\"knitr\")       \ninstall.packages(\"kableExtra\")\ninstall.packages(\"gt\")\n\n# Paquetes para visualización\ninstall.packages(\"ggplot2\")     # (ya incluido en tidyverse)\ninstall.packages(\"patchwork\")   # Combinar gráficos\ninstall.packages(\"ggpubr\")      # Gráficos “estadísticos” fáciles\n\n# Paquetes útiles para la investigación social\ninstall.packages(\"survey\")      # Si trabajaran con datos muestrales\ninstall.packages(\"srvyr\")       # Survey pero con lenguaje dplyr\ninstall.packages(\"Hmisc\")       # Recodificación, descriptivos avanzados"
  },
  {
    "objectID": "recursos.html#lenguaje-de-programación",
    "href": "recursos.html#lenguaje-de-programación",
    "title": "Recursos",
    "section": "",
    "text": "Para este curso necesitas instalar:\n\nR\n\nDescarga desde: https://cran.r-project.org/\nSelecciona tu sistema operativo y sigue las instrucciones\n\nRStudio (IDE recomendado)\n\nDescarga desde: https://posit.co/download/rstudio-desktop/\nVersión gratuita (Desktop) es suficiente\nSi quieren otro IDE, pueden usar Positron, que es un nuevo IDE que combina Python y R en un interfaz amable. O si vienen del mundo más ligado a la ciencia de datos “pura”, también pueden usar VS Code. Pero el lenguaje de programación será siempre R.\n\n\n\n\n\n\n\n\nVideo tutoriales de instalación\n\n\n\n\nInstalar R y RStudio en Windows\nInstalar R y RStudio en Mac\nInstalar R y RStudio en Linux\n\n(Pueden usar cualquier tutorial que deseen, lo de arriba solo son referencias rápidas. De cualquier manera, es bastante intuitivo)\n\n\n\n\n\nDurante el curso usaremos principalmente estos paquetes. Puedes instalarlos copiando este código en tu consola de R:\n# Paquetes para manipulación y limpieza de datos\ninstall.packages(\"tidyverse\")   # dplyr, ggplot2, tidyr, readr, etc.\ninstall.packages(\"haven\")       # Importar SPSS, Stata, SAS\ninstall.packages(\"readxl\")      # Leer Excel\ninstall.packages(\"rio\")         # Import/export flexible\ninstall.packages(\"janitor\")     # Limpiar datos y tablas\ninstall.packages(\"labelled\")    # Etiquetas de variables.\n\n# Paquetes para estadística descriptiva e inferencial básica\ninstall.packages(\"psych\")       # Descriptivos\ninstall.packages(\"DescTools\")   # Medidas y tests clásicos\ninstall.packages(\"summarytools\")# Tablas descriptivas rápidas\n\n# Paquetes para test de hipótesis y modelos lineales\ninstall.packages(\"car\")         # Regresión, ANOVA, supuestos\ninstall.packages(\"lmtest\")      # Tests para modelos lineales\ninstall.packages(\"sandwich\")    # Errores robustos (White, HC)\ninstall.packages(\"estimatr\")    # Regresión con errores robustos fáciles\ninstall.packages(\"margins\")     # Efectos marginales\n\n\n# Paquetes para tablas y reportes\ninstall.packages(\"broom\")       # Convertir modelos a dataframes\ninstall.packages(\"stargazer\")   # Tablas de regresión (LaTeX, html, texto)\ninstall.packages(\"modelsummary\")# Alternativa moderna a stargazer\ninstall.packages(\"knitr\")       \ninstall.packages(\"kableExtra\")\ninstall.packages(\"gt\")\n\n# Paquetes para visualización\ninstall.packages(\"ggplot2\")     # (ya incluido en tidyverse)\ninstall.packages(\"patchwork\")   # Combinar gráficos\ninstall.packages(\"ggpubr\")      # Gráficos “estadísticos” fáciles\n\n# Paquetes útiles para la investigación social\ninstall.packages(\"survey\")      # Si trabajaran con datos muestrales\ninstall.packages(\"srvyr\")       # Survey pero con lenguaje dplyr\ninstall.packages(\"Hmisc\")       # Recodificación, descriptivos avanzados"
  },
  {
    "objectID": "recursos.html#guías-y-tutoriales",
    "href": "recursos.html#guías-y-tutoriales",
    "title": "Recursos",
    "section": "Guías y Tutoriales",
    "text": "Guías y Tutoriales\n\nR\n\nR para Ciencia de Datos (en español) - Wickham & Grolemund\nFundamentos de ciencia de datos con R - (Eds.) Fernández-Avilés y Montero\nIntroducción a R - RStudio Education\nswirl: Learn R, in R - Tutoriales interactivos\n\n\n\nEstadística en R\n\nLearning Statistics with R - Danielle Navarro (libro completo gratis)\nIntroduction to Econometrics with R - Hanck, Arnold, Gerber y Schmelzer (de mis favoritos)\nQuick-R - Referencia rápida de métodos estadísticos\nUCLA Statistical Consulting - Excelentes tutoriales por método estadístico\n\n\n\nVisualización de Datos\n\nggplot2: Elegant Graphics for Data Analysis\nR Graphics Cookbook\nFundamentals of Data Visualization - Claus Wilke\n\n\n\nQuarto/R Markdown\n\nQuarto Documentation\nR Markdown: The Definitive Guide\nR Markdown Cookbook"
  },
  {
    "objectID": "recursos.html#datos-para-práctica",
    "href": "recursos.html#datos-para-práctica",
    "title": "Recursos",
    "section": "Datos para Práctica",
    "text": "Datos para Práctica\n\nDatasets del Curso\nLos datasets utilizados en clases están disponibles en la carpeta data/ de este sitio web (en el repositorio de GitHub):\n\nejemplo.csv - Dataset ejemplo para Sesión XX\nPor ejemplo, para la sesión 1, usaremos data/ene-2025-jja.csv, que es la última base de datos de la Encuesta Nacional de Empleo realizada mensualmente (agregada por trimestres (en este caso, jja es junio, julio y agosto))\n\n\n\nRepositorios de Datos Sociales\nChile: - CASEN - Encuesta de Caracterización Socioeconómica Nacional - ENUT - Encuesta Nacional sobre el Uso del Tiempo - ENE - Encuesta Nacional de Empleo\nInternacional: - World Bank Open Data - OECD Data - Gapminder - Our World in Data\nRepositorios generales: - Kaggle Datasets - UCI Machine Learning Repository - Data.gov"
  },
  {
    "objectID": "recursos.html#hojas-de-referencia-cheatsheets",
    "href": "recursos.html#hojas-de-referencia-cheatsheets",
    "title": "Recursos",
    "section": "Hojas de Referencia (Cheatsheets)",
    "text": "Hojas de Referencia (Cheatsheets)\nDescarga estas guías de referencia rápida:\n\nRStudio IDE Cheatsheet\nData Transformation with dplyr\nData Visualization with ggplot2\nR Markdown\n\nTodas las cheatsheets de RStudio: https://posit.co/resources/cheatsheets/"
  },
  {
    "objectID": "recursos.html#comunidades-y-ayuda",
    "href": "recursos.html#comunidades-y-ayuda",
    "title": "Recursos",
    "section": "Comunidades y Ayuda",
    "text": "Comunidades y Ayuda\n\nForos y Comunidades\n\nStack Overflow (tag: r) - Preguntas técnicas\nRStudio Community - Comunidad oficial\nr/rstats (Reddit) - Discusiones y noticias\n\n\n\nCanales de YouTube (en español)\n\nOmar Bello (Estadística, Fisiología Humana y Metodología de la Investigación). Muy útil para R y Python\nCódigo Máquina (Data Science). Más enfocado a Data Science y Python, pero útil\nEconometría Virtual. Cursos de econometría de la UBA en R.\n-Esteban Gomez - TidyveRso. Muy útil !\n\n\n\nBlogs y Tutoriales\n\nR-bloggers - Agregador de blogs sobre R\nTowards Data Science - Artículos técnicos"
  },
  {
    "objectID": "recursos.html#consejos-para-aprender-r",
    "href": "recursos.html#consejos-para-aprender-r",
    "title": "Recursos",
    "section": "Consejos para Aprender R",
    "text": "Consejos para Aprender R\n\n\n\n\n\n\nHaz clic para expandir consejos\n\n\n\n\n\n\n1. Practica regularmente\nNo basta con ver código, hay que escribirlo. Dedica tiempo cada semana a practicar.\n\n\n2. Aprende a buscar ayuda\n\nUsa ?funcion o help(funcion) en R\nBusca en Google: “how to [tarea] in R”\nLee los mensajes de error con calma\n\n\n\n3. No memorices, entiende\nEs mejor entender la lógica que memorizar código. Usa las cheatsheets como apoyo.\n\n\n4. Comenta tu código\nTu yo del futuro te lo agradecerá. Explica qué hace cada sección.\n\n\n5. Empieza simple\nNo trates de hacer visualizaciones complejas desde el inicio. Domina lo básico primero.\n\n\n6. Aprende de ejemplos\nEstudia código de otros, modifícalo, entiéndelo.\n\n\n7. Sé paciente\nTodos los programadores cometen errores constantemente. Es parte del proceso."
  },
  {
    "objectID": "recursos.html#material-complementario",
    "href": "recursos.html#material-complementario",
    "title": "Recursos",
    "section": "Material Complementario",
    "text": "Material Complementario\n\nLibros Avanzados (para profundizar)\n\nAdvanced R - Hadley Wickham\nHands-On Programming with R\nText Mining with R\n\n\n\nCursos Online\n\nCoursera: R Programming\nDataCamp: Introduction to R\nedX: Data Science: R Basics"
  },
  {
    "objectID": "recursos.html#contacto",
    "href": "recursos.html#contacto",
    "title": "Recursos",
    "section": "Contacto",
    "text": "Contacto\n¿Tienes sugerencias de recursos que deberían estar aquí? Escríbeme a [email] o abre un issue en el repositorio de GitHub."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa del Curso",
    "section": "",
    "text": "Curso: Taller de Métodos y Técnicas de Investigación I\n\nPrograma: Magíster en Sociología\n\nProfesor/a: Carolina Aguilera\n\nAyudante: Fran Sofía Núñez Rebolledo\nCréditos y carácter: 5 créditos y de carácter obligatorio\nHoras cronológicas de dedicación:\n\nDocencia directa: 42 hrs.\nTrabajo autónomo: 135 hrs."
  },
  {
    "objectID": "syllabus.html#información-general",
    "href": "syllabus.html#información-general",
    "title": "Programa del Curso",
    "section": "",
    "text": "Curso: Taller de Métodos y Técnicas de Investigación I\n\nPrograma: Magíster en Sociología\n\nProfesor/a: Carolina Aguilera\n\nAyudante: Fran Sofía Núñez Rebolledo\nCréditos y carácter: 5 créditos y de carácter obligatorio\nHoras cronológicas de dedicación:\n\nDocencia directa: 42 hrs.\nTrabajo autónomo: 135 hrs."
  },
  {
    "objectID": "syllabus.html#descripción",
    "href": "syllabus.html#descripción",
    "title": "Programa del Curso",
    "section": "Descripción",
    "text": "Descripción\nEste taller proporciona formación práctica en el uso de R para análisis estadístico en ciencias sociales. El curso enfatiza la aplicación de técnicas estadísticas fundamentales, desde estadística descriptiva hasta modelos de regresión múltiple, utilizando datos reales de investigación social."
  },
  {
    "objectID": "syllabus.html#objetivos-de-aprendizaje",
    "href": "syllabus.html#objetivos-de-aprendizaje",
    "title": "Programa del Curso",
    "section": "Objetivos de Aprendizaje",
    "text": "Objetivos de Aprendizaje\nAl finalizar el curso, las y los estudiantes serán capaces de:\n\nManipular y preparar datos para análisis estadístico en R\nRealizar análisis estadísticos descriptivos e inferenciales\nAplicar pruebas de hipótesis apropiadas según el tipo de datos\nEjecutar y interpretar análisis de correlación y regresión\nComunicar resultados estadísticos de manera clara y profesional"
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa del Curso",
    "section": "Metodología",
    "text": "Metodología\nEl curso se estructura en sesiones prácticas donde se combinan:\n\nExposiciones teóricas breves sobre los conceptos estadísticos\nDemostraciones en vivo de código en R\nEjercicios prácticos guiados\nTrabajo autónomo con datos reales\n\nSe espera que las y los estudiantes tengan un computador con R y RStudio instalados a cada sesión. Los contenido por sesión son los de la ayudantía. Los de las cátedra los pueden encontrar en el programa del curso."
  },
  {
    "objectID": "syllabus.html#contenidos-por-sesión",
    "href": "syllabus.html#contenidos-por-sesión",
    "title": "Programa del Curso",
    "section": "Contenidos por Sesión",
    "text": "Contenidos por Sesión\n\nSesión 1: Introducción a R y Estadística Descriptiva (I)\nFecha: 21 de octubre, 2025.\n\nInterfaz de RStudio y flujo de trabajo\nTipos de objetos en R (vectores, dataframes, listas)\nImportación de datos\nMedidas de tendencia central\nTablas de frecuencia y contingencia\n\n\nLecturas\n\nFernández-Avilés, G. y Montero, J-M. (Eds.). (2024). Fundamentos de ciencia de datos con R. McGraw-Hill Interamericana de España\nCano, E. L. En Fernández-Avilés, G. y Montero, J-M. (Eds.). (2024). R para ciencia de datos. McGraw-Hill Interamericana de España\nWickham, H. y Grolemund, G. (2023). R Para Ciencia de Datos (traducción). O’Reilly Media\nWickham, H. (2019). Advanced R. Second Edition: CRC Press y Taylor & Francis Group\n\n\n\n\n\nSesión 2: Estadística Descriptiva (II) y Prueba de Hipótesis (I)\nFecha: [Fecha]\n\nMedidas de dispersión y posición\nVisualización de datos (histogramas, boxplots, gráficos de barras)\nIntroducción a la inferencia estadística\nPrueba t para una muestra\nPrueba t para muestras independientes\n\n\nLecturas\n\nWackerly, Dennis D. and William, Mendenhall and Scheaffer, Richard L. S. (2010). Estadística matemática con aplicaciones. Cengage Learning Editores\nDeGroot, Morris and Schervish, Mark. (2014). Probability and Statistics. Pearson Education Limited\nBlitzstein, Joseph K. and Hwang, Jessica. (2019). Introduction to Probability. Second Edition: Taylor & Francis Group\nCanavos, George C. (1988). Probabilidad y Estadística. Aplicaciones y métodos. McGraw-Hill\n\n\n\n\n\nSesión 3: Prueba de Hipótesis (II) y ANOVA\nFecha: [Fecha]\n\nPrueba t para muestras pareadas\nPruebas no paramétricas (Wilcoxon, Mann-Whitney)\nANOVA de un factor\nComparaciones post-hoc (Tukey, Bonferroni)\nSupuestos y diagnósticos\n\nLecturas: - [Referencias]\n\n\n\nSesión 4: Correlación Bivariada y Regresión Lineal Simple\nFecha: [Fecha]\n\nCorrelación de Pearson y Spearman\nMatrices de correlación\nIntroducción a la regresión lineal simple\nEstimación e interpretación de coeficientes\nR² y bondad de ajuste\n\nLecturas: - [Referencias]\n\n\n\nSesión 5: Regresión Lineal Múltiple\nFecha: [Fecha]\n\nRegresión lineal múltiple\nInterpretación de coeficientes con múltiples predictores\nVariables dummy y categóricas\nDiagnóstico de regresión (residuos, multicolinealidad)\nPresentación de resultados\n\nLecturas: - [Referencias]"
  },
  {
    "objectID": "syllabus.html#bibliografía-básica-del-curso",
    "href": "syllabus.html#bibliografía-básica-del-curso",
    "title": "Programa del Curso",
    "section": "Bibliografía Básica del curso",
    "text": "Bibliografía Básica del curso\n\nAldás, Joaquín y Uriel, Ezequiel (2017). Análisis multivariante aplicado con R. Ediciones Parainfo.\nMoore, D. (2005). Estadística básica aplicada. Barcelona: Antonio Bosch Editor\nPardo, Ruiz y San Martín. (2015). Análisis de Datos en Ciencias Sociales y de la Salud I. Editorial Síntesis: Madrid\nRitchey, F. (2002). Estadísticas para las Ciencias Sociales: El potencial de la imaginación estadística. México: Mc Graw Hill.\nWooldrige, J. (2010). Introducción a la econometría: un enfoque moderno. 4ta edición. Mexico: Cengage Learning."
  },
  {
    "objectID": "syllabus.html#bibliografía-complementaria-de-r",
    "href": "syllabus.html#bibliografía-complementaria-de-r",
    "title": "Programa del Curso",
    "section": "Bibliografía Complementaria de R",
    "text": "Bibliografía Complementaria de R\n\nChristoph Hanck, Martin Arnold, Alexander Gerber, and Martin Schmelzer (2025). Introduction to Econometrics with R. Libro web Disponible en https://www.econometrics-with-r.org/.\n\nGema Fernández-Avilés y José-María Montero (Eds.) (2024). Fundamentos de ciencia de datos con R. McGrawHiil. Libro web disponible en https://cdr-book.github.io/index.html."
  },
  {
    "objectID": "syllabus.html#políticas-del-curso",
    "href": "syllabus.html#políticas-del-curso",
    "title": "Programa del Curso",
    "section": "Políticas del Curso",
    "text": "Políticas del Curso\n\nAsistencia\nSe requiere [X%] de asistencia para aprobar el curso. Las inasistencias deben ser justificadas.\n\n\nIntegridad Académica\nSe espera honestidad académica en todos los trabajos. El plagio o copia resultará en la reprobación del curso según el reglamento de la universidad.\n\n\nUso de IA y Herramientas\n[Define tu política sobre el uso de ChatGPT, Claude, u otras herramientas de IA para resolver ejercicios]"
  }
]